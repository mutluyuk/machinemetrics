<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Error | Causal MachineMetrics</title>
  <meta name="description" content="Chapter 5 Error | Causal MachineMetrics" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Error | Causal MachineMetrics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/png/MachineMetrics.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Error | Causal MachineMetrics" />
  
  
  <meta name="twitter:image" content="/png/MachineMetrics.png" />

<meta name="author" content="Yigit Aydede and Mutlu Yuksel" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="learning.html"/>
<link rel="next" href="bias-variance-trade-off.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">.</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-book-is-different"><i class="fa fa-check"></i>Why this book is different?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-manuscript"><i class="fa fa-check"></i>Structure of Manuscript:</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-can-use-this-book"><i class="fa fa-check"></i>Who Can Use This Book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction:</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#prediction-vs.-estimation"><i class="fa fa-check"></i><b>1.1</b> Prediction vs. Estimation:</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#where-can-you-use-the-covered-topics-in-social-sciences"><i class="fa fa-check"></i><b>1.2</b> Where can you use the covered topics in Social Sciences?:</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#translation-of-concepts-different-terminology"><i class="fa fa-check"></i><b>1.3</b> Translation of Concepts: Different Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#is-machine-learning-better"><i class="fa fa-check"></i><b>1.4</b> Is Machine Learning Better?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html"><i class="fa fa-check"></i><b>2</b> Spectrum of Data Modeling:</a>
<ul>
<li class="chapter" data-level="2.1" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html#statistical-vs.-machine-learning-approaches"><i class="fa fa-check"></i><b>2.1</b> Statistical vs. Machine Learning Approaches:</a></li>
<li class="chapter" data-level="2.2" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html#parametric-and-nonparametric-models"><i class="fa fa-check"></i><b>2.2</b> Parametric and Nonparametric Models:</a></li>
<li class="chapter" data-level="2.3" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html#predictive-vs.-causal-models"><i class="fa fa-check"></i><b>2.3</b> Predictive vs. Causal Models:</a></li>
<li class="chapter" data-level="2.4" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html#model-selection"><i class="fa fa-check"></i><b>2.4</b> Model Selection:</a></li>
<li class="chapter" data-level="2.5" data-path="spectrum-of-data-modeling.html"><a href="spectrum-of-data-modeling.html#simulation"><i class="fa fa-check"></i><b>2.5</b> Simulation:</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>3</b> Counterfactual:</a>
<ul>
<li class="chapter" data-level="3.1" data-path="counterfactual.html"><a href="counterfactual.html#qualitative-and-quantitative-research-methods"><i class="fa fa-check"></i><b>3.1</b> Qualitative and Quantitative research methods:</a></li>
<li class="chapter" data-level="3.2" data-path="counterfactual.html"><a href="counterfactual.html#quantitative---research-methods"><i class="fa fa-check"></i><b>3.2</b> Quantitative - Research methods :</a></li>
<li class="chapter" data-level="3.3" data-path="counterfactual.html"><a href="counterfactual.html#data-and-visualization"><i class="fa fa-check"></i><b>3.3</b> Data and visualization</a></li>
<li class="chapter" data-level="3.4" data-path="counterfactual.html"><a href="counterfactual.html#correlation"><i class="fa fa-check"></i><b>3.4</b> Correlation</a></li>
<li class="chapter" data-level="3.5" data-path="counterfactual.html"><a href="counterfactual.html#effect-of-x-on-y-regression"><i class="fa fa-check"></i><b>3.5</b> Effect of X on Y / Regression</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="counterfactual.html"><a href="counterfactual.html#how-can-we-estimate-the-population-parameters-beta_0-and-beta_1"><i class="fa fa-check"></i><b>3.5.1</b> How can we estimate the population parameters, <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>?</a></li>
<li class="chapter" data-level="3.5.2" data-path="counterfactual.html"><a href="counterfactual.html#predicting-y"><i class="fa fa-check"></i><b>3.5.2</b> Predicting <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="counterfactual.html"><a href="counterfactual.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>3.5.3</b> Maximum Likelihood Estimation (MLE)}</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="counterfactual.html"><a href="counterfactual.html#causal-effect"><i class="fa fa-check"></i><b>3.6</b> Causal Effect</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="counterfactual.html"><a href="counterfactual.html#average-treatment-effectate"><i class="fa fa-check"></i><b>3.6.1</b> Average Treatment Effect(ATE)</a></li>
<li class="chapter" data-level="3.6.2" data-path="counterfactual.html"><a href="counterfactual.html#additional-treatment-effects"><i class="fa fa-check"></i><b>3.6.2</b> Additional Treatment Effects</a></li>
<li class="chapter" data-level="3.6.3" data-path="counterfactual.html"><a href="counterfactual.html#selection-bias-and-heteregeneous-treatment-effect-bias"><i class="fa fa-check"></i><b>3.6.3</b> Selection Bias and Heteregeneous Treatment Effect Bias:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning.html"><a href="learning.html"><i class="fa fa-check"></i><b>4</b> Learning</a>
<ul>
<li class="chapter" data-level="" data-path="learning.html"><a href="learning.html#learning-systems"><i class="fa fa-check"></i>Learning Systems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>5</b> Error</a>
<ul>
<li class="chapter" data-level="5.1" data-path="error.html"><a href="error.html#estimation-error"><i class="fa fa-check"></i><b>5.1</b> Estimation error</a></li>
<li class="chapter" data-level="5.2" data-path="error.html"><a href="error.html#efficiency"><i class="fa fa-check"></i><b>5.2</b> Efficiency</a></li>
<li class="chapter" data-level="5.3" data-path="error.html"><a href="error.html#mean-square-error"><i class="fa fa-check"></i><b>5.3</b> Mean Square Error</a></li>
<li class="chapter" data-level="5.4" data-path="error.html"><a href="error.html#prediction-error--mspe"><i class="fa fa-check"></i><b>5.4</b> Prediction error- MSPE</a></li>
<li class="chapter" data-level="5.5" data-path="error.html"><a href="error.html#technical-points-and-proofs"><i class="fa fa-check"></i><b>5.5</b> Technical points and proofs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html"><i class="fa fa-check"></i><b>6</b> Bias-Variance Trade-off</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html#formal-definition"><i class="fa fa-check"></i><b>6.1</b> Formal Definition</a></li>
<li class="chapter" data-level="6.2" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html#simulated-breakdown-of-the-mspe"><i class="fa fa-check"></i><b>6.2</b> Simulated Breakdown of the MSPE</a></li>
<li class="chapter" data-level="6.3" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html#biased-estimator-as-a-predictor"><i class="fa fa-check"></i><b>6.3</b> Biased estimator as a predictor</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>7</b> Overfitting</a></li>
<li class="chapter" data-level="8" data-path="regression-v.s.-classification.html"><a href="regression-v.s.-classification.html"><i class="fa fa-check"></i><b>8</b> Regression v.s. Classification</a></li>
<li class="chapter" data-level="9" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html"><i class="fa fa-check"></i><b>9</b> Parametric Estimations - Basics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#the-dichotomy-of-statistical-modeling-data-versus-algorithmic-approaches"><i class="fa fa-check"></i><b>9.1</b> The Dichotomy of Statistical Modeling: Data versus Algorithmic Approaches:</a></li>
<li class="chapter" data-level="9.2" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#parametric-estimations"><i class="fa fa-check"></i><b>9.2</b> Parametric Estimations</a></li>
<li class="chapter" data-level="9.3" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#lpm"><i class="fa fa-check"></i><b>9.3</b> LPM</a></li>
<li class="chapter" data-level="9.4" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#logistic-regression"><i class="fa fa-check"></i><b>9.4</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html"><i class="fa fa-check"></i><b>10</b> Nonparametric Estimations - Basics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#density-estimations"><i class="fa fa-check"></i><b>10.1</b> Density estimations</a></li>
<li class="chapter" data-level="10.2" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#kernel-regression"><i class="fa fa-check"></i><b>10.2</b> Kernel regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html"><i class="fa fa-check"></i><b>11</b> Hyperparameter Tuning</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#training-and-validation"><i class="fa fa-check"></i><b>11.1</b> Training and Validation</a></li>
<li class="chapter" data-level="11.2" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#splitting-the-data-randomly"><i class="fa fa-check"></i><b>11.2</b> Splitting the data randomly</a></li>
<li class="chapter" data-level="11.3" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>11.3</b> k-fold cross validation</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html"><i class="fa fa-check"></i><b>12</b> Optimization Algorithms - Basics</a>
<ul>
<li class="chapter" data-level="12.1" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#brute-force-optimization"><i class="fa fa-check"></i><b>12.1</b> Brute-force optimization</a></li>
<li class="chapter" data-level="12.2" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#derivative-based-methods"><i class="fa fa-check"></i><b>12.2</b> Derivative-based methods</a></li>
<li class="chapter" data-level="12.3" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#ml-estimation-with-logistic-regression"><i class="fa fa-check"></i><b>12.3</b> ML Estimation with logistic regression</a></li>
<li class="chapter" data-level="12.4" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#gradient-descent-algorithm"><i class="fa fa-check"></i><b>12.4</b> Gradient Descent Algorithm</a></li>
<li class="chapter" data-level="12.5" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#optimization-with-r"><i class="fa fa-check"></i><b>12.5</b> Optimization with R</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="prediction-intervals.html"><a href="prediction-intervals.html"><i class="fa fa-check"></i><b>13</b> Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.1" data-path="prediction-intervals.html"><a href="prediction-intervals.html#prediction-interval-for-unbiased-ols-predictor"><i class="fa fa-check"></i><b>13.1</b> Prediction interval for unbiased OLS predictor</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>14</b> Interpretability</a>
<ul>
<li class="chapter" data-level="14.1" data-path="interpretability.html"><a href="interpretability.html#interpretable-vs-noninterpretable-models"><i class="fa fa-check"></i><b>14.1</b> Interpretable vs NonInterpretable Models</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="shrinkage-models.html"><a href="shrinkage-models.html"><i class="fa fa-check"></i><b>15</b> Shrinkage Models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="shrinkage-models.html"><a href="shrinkage-models.html#ridge"><i class="fa fa-check"></i><b>15.1</b> Ridge</a></li>
<li class="chapter" data-level="15.2" data-path="shrinkage-models.html"><a href="shrinkage-models.html#lasso"><i class="fa fa-check"></i><b>15.2</b> Lasso</a></li>
<li class="chapter" data-level="15.3" data-path="shrinkage-models.html"><a href="shrinkage-models.html#adaptive-lasso"><i class="fa fa-check"></i><b>15.3</b> Adaptive Lasso</a></li>
<li class="chapter" data-level="15.4" data-path="shrinkage-models.html"><a href="shrinkage-models.html#sparsity"><i class="fa fa-check"></i><b>15.4</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>16</b> Regression Trees</a>
<ul>
<li class="chapter" data-level="16.1" data-path="regression-trees.html"><a href="regression-trees.html#cart---classification-tree"><i class="fa fa-check"></i><b>16.1</b> CART - Classification Tree</a></li>
<li class="chapter" data-level="16.2" data-path="regression-trees.html"><a href="regression-trees.html#pruning"><i class="fa fa-check"></i><b>16.2</b> Pruning</a></li>
<li class="chapter" data-level="16.3" data-path="regression-trees.html"><a href="regression-trees.html#regression-tree"><i class="fa fa-check"></i><b>16.3</b> Regression Tree</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>17</b> Ensemble Methods</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>17.1</b> Bagging</a></li>
<li class="chapter" data-level="17.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting"><i class="fa fa-check"></i><b>17.2</b> Boosting</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#adaboost"><i class="fa fa-check"></i><b>17.2.1</b> AdaBoost</a></li>
<li class="chapter" data-level="17.2.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#xgboost"><i class="fa fa-check"></i><b>17.2.2</b> XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#ensemble-applications"><i class="fa fa-check"></i><b>17.3</b> Ensemble Applications</a></li>
<li class="chapter" data-level="17.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification"><i class="fa fa-check"></i><b>17.4</b> Classification</a></li>
<li class="chapter" data-level="17.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#regression"><i class="fa fa-check"></i><b>17.5</b> Regression</a></li>
<li class="chapter" data-level="17.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#exploration"><i class="fa fa-check"></i><b>17.6</b> Exploration</a></li>
<li class="chapter" data-level="17.7" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-applications"><i class="fa fa-check"></i><b>17.7</b> Boosting Applications</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-search-with-parallel-processing"><i class="fa fa-check"></i><b>17.7.1</b> Random search with parallel processing</a></li>
<li class="chapter" data-level="17.7.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-vs.-others"><i class="fa fa-check"></i><b>17.7.2</b> Boosting vs. Others</a></li>
<li class="chapter" data-level="17.7.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification-with-xgboost"><i class="fa fa-check"></i><b>17.7.3</b> Classification with XGBoost</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="causal-effect-1.html"><a href="causal-effect-1.html"><i class="fa fa-check"></i><b>18</b> Causal Effect</a>
<ul>
<li class="chapter" data-level="18.1" data-path="causal-effect-1.html"><a href="causal-effect-1.html#random-experiment"><i class="fa fa-check"></i><b>18.1</b> Random experiment</a></li>
<li class="chapter" data-level="18.2" data-path="causal-effect-1.html"><a href="causal-effect-1.html#iv"><i class="fa fa-check"></i><b>18.2</b> IV</a></li>
<li class="chapter" data-level="18.3" data-path="causal-effect-1.html"><a href="causal-effect-1.html#diffd"><i class="fa fa-check"></i><b>18.3</b> DiffD</a></li>
<li class="chapter" data-level="18.4" data-path="causal-effect-1.html"><a href="causal-effect-1.html#rd"><i class="fa fa-check"></i><b>18.4</b> RD</a></li>
<li class="chapter" data-level="18.5" data-path="causal-effect-1.html"><a href="causal-effect-1.html#synthetic-control"><i class="fa fa-check"></i><b>18.5</b> Synthetic control</a></li>
<li class="chapter" data-level="18.6" data-path="causal-effect-1.html"><a href="causal-effect-1.html#doubledebiased-lassomethods"><i class="fa fa-check"></i><b>18.6</b> Double/Debiased Lasso/Methods</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html"><i class="fa fa-check"></i><b>19</b> Heterogeneous Treatment Effects</a>
<ul>
<li class="chapter" data-level="19.1" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html#causal-tree"><i class="fa fa-check"></i><b>19.1</b> Causal Tree</a></li>
<li class="chapter" data-level="19.2" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html#causal-forest"><i class="fa fa-check"></i><b>19.2</b> Causal Forest</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html"><i class="fa fa-check"></i><b>20</b> Model selection and Sparsity</a>
<ul>
<li class="chapter" data-level="20.1" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#model-selection-1"><i class="fa fa-check"></i><b>20.1</b> Model selection</a></li>
<li class="chapter" data-level="20.2" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#dropping-a-variable-in-a-regression"><i class="fa fa-check"></i><b>20.2</b> Dropping a variable in a regression</a></li>
<li class="chapter" data-level="20.3" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#sparsity-1"><i class="fa fa-check"></i><b>20.3</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="classification-1.html"><a href="classification-1.html"><i class="fa fa-check"></i><b>21</b> Classification</a>
<ul>
<li class="chapter" data-level="21.1" data-path="classification-1.html"><a href="classification-1.html#nonparametric-classifier---knn"><i class="fa fa-check"></i><b>21.1</b> Nonparametric Classifier - kNN</a></li>
<li class="chapter" data-level="21.2" data-path="classification-1.html"><a href="classification-1.html#linear-classifiers"><i class="fa fa-check"></i><b>21.2</b> Linear classifiers</a></li>
<li class="chapter" data-level="21.3" data-path="classification-1.html"><a href="classification-1.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>21.3</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="21.4" data-path="classification-1.html"><a href="classification-1.html#tuning-in-classification"><i class="fa fa-check"></i><b>21.4</b> Tuning in Classification</a></li>
<li class="chapter" data-level="21.5" data-path="classification-1.html"><a href="classification-1.html#confusion-matrix"><i class="fa fa-check"></i><b>21.5</b> Confusion matrix</a></li>
<li class="chapter" data-level="21.6" data-path="classification-1.html"><a href="classification-1.html#performance-measures"><i class="fa fa-check"></i><b>21.6</b> Performance measures</a></li>
<li class="chapter" data-level="21.7" data-path="classification-1.html"><a href="classification-1.html#roc-curve"><i class="fa fa-check"></i><b>21.7</b> ROC Curve</a></li>
<li class="chapter" data-level="21.8" data-path="classification-1.html"><a href="classification-1.html#auc---area-under-the-curve"><i class="fa fa-check"></i><b>21.8</b> AUC - Area Under the Curve</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html"><i class="fa fa-check"></i><b>22</b> Causal Inference for Time Series</a>
<ul>
<li class="chapter" data-level="22.1" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#arima-models"><i class="fa fa-check"></i><b>22.1</b> ARIMA models</a></li>
<li class="chapter" data-level="22.2" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#hyndman-khandakar-algorithm"><i class="fa fa-check"></i><b>22.2</b> Hyndman-Khandakar algorithm</a></li>
<li class="chapter" data-level="22.3" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#ts-plots"><i class="fa fa-check"></i><b>22.3</b> TS Plots</a></li>
<li class="chapter" data-level="22.4" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#box-cox-transformation"><i class="fa fa-check"></i><b>22.4</b> Box-Cox transformation</a></li>
<li class="chapter" data-level="22.5" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#modeling-arima"><i class="fa fa-check"></i><b>22.5</b> Modeling ARIMA</a></li>
<li class="chapter" data-level="22.6" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#grid-search-for-arima"><i class="fa fa-check"></i><b>22.6</b> Grid search for ARIMA</a></li>
<li class="chapter" data-level="22.7" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#hyperparameter-tuning-with-time-series-data"><i class="fa fa-check"></i><b>22.7</b> Hyperparameter tuning with time-series data:</a></li>
<li class="chapter" data-level="22.8" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#speed"><i class="fa fa-check"></i><b>22.8</b> Speed</a></li>
<li class="chapter" data-level="22.9" data-path="causal-inference-for-time-series.html"><a href="causal-inference-for-time-series.html#ci-for-ts"><i class="fa fa-check"></i><b>22.9</b> CI for TS</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="causal-forecasting.html"><a href="causal-forecasting.html"><i class="fa fa-check"></i><b>23</b> Causal Forecasting</a>
<ul>
<li class="chapter" data-level="23.1" data-path="causal-forecasting.html"><a href="causal-forecasting.html#time-series-embedding"><i class="fa fa-check"></i><b>23.1</b> Time Series Embedding</a></li>
<li class="chapter" data-level="23.2" data-path="causal-forecasting.html"><a href="causal-forecasting.html#var-for-recursive-forecasting"><i class="fa fa-check"></i><b>23.2</b> VAR for Recursive Forecasting</a></li>
<li class="chapter" data-level="23.3" data-path="causal-forecasting.html"><a href="causal-forecasting.html#embedding-for-direct-forecast"><i class="fa fa-check"></i><b>23.3</b> Embedding for Direct Forecast</a></li>
<li class="chapter" data-level="23.4" data-path="causal-forecasting.html"><a href="causal-forecasting.html#random-forest"><i class="fa fa-check"></i><b>23.4</b> Random Forest</a></li>
<li class="chapter" data-level="23.5" data-path="causal-forecasting.html"><a href="causal-forecasting.html#rolling-and-expanding-windows"><i class="fa fa-check"></i><b>23.5</b> Rolling and expanding windows</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="ate-with-support-vector-machine.html"><a href="ate-with-support-vector-machine.html"><i class="fa fa-check"></i><b>24</b> ATE with Support Vector Machine</a>
<ul>
<li class="chapter" data-level="24.1" data-path="ate-with-support-vector-machine.html"><a href="ate-with-support-vector-machine.html#support-vector-machine"><i class="fa fa-check"></i><b>24.1</b> Support Vector Machine</a></li>
<li class="chapter" data-level="24.2" data-path="ate-with-support-vector-machine.html"><a href="ate-with-support-vector-machine.html#ate-with-svm"><i class="fa fa-check"></i><b>24.2</b> ATE with SVM</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>25</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="25.1" data-path="neural-networks.html"><a href="neural-networks.html#neural-network---the-idea"><i class="fa fa-check"></i><b>25.1</b> Neural Network - the idea</a></li>
<li class="chapter" data-level="25.2" data-path="neural-networks.html"><a href="neural-networks.html#backpropagation"><i class="fa fa-check"></i><b>25.2</b> Backpropagation</a></li>
<li class="chapter" data-level="25.3" data-path="neural-networks.html"><a href="neural-networks.html#neural-network---more-inputs"><i class="fa fa-check"></i><b>25.3</b> Neural Network - More inputs</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>26</b> Deep Learning</a></li>
<li class="chapter" data-level="27" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html"><i class="fa fa-check"></i><b>27</b> Graphical Network Analysis</a>
<ul>
<li class="chapter" data-level="27.1" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#fundementals"><i class="fa fa-check"></i><b>27.1</b> Fundementals</a></li>
<li class="chapter" data-level="27.2" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#covariance"><i class="fa fa-check"></i><b>27.2</b> Covariance</a></li>
<li class="chapter" data-level="27.3" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#correlation-1"><i class="fa fa-check"></i><b>27.3</b> Correlation</a></li>
<li class="chapter" data-level="27.4" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#semi-partial-correlation"><i class="fa fa-check"></i><b>27.4</b> Semi-partial Correlation</a></li>
<li class="chapter" data-level="27.5" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#regularized-covariance-matrix"><i class="fa fa-check"></i><b>27.5</b> Regularized Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="decompositions.html"><a href="decompositions.html"><i class="fa fa-check"></i><b>28</b> Decompositions</a>
<ul>
<li class="chapter" data-level="28.1" data-path="decompositions.html"><a href="decompositions.html#matrix-decomposition"><i class="fa fa-check"></i><b>28.1</b> Matrix Decomposition</a></li>
<li class="chapter" data-level="28.2" data-path="decompositions.html"><a href="decompositions.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>28.2</b> Eigenvectors and eigenvalues</a></li>
<li class="chapter" data-level="28.3" data-path="decompositions.html"><a href="decompositions.html#singular-value-decomposition"><i class="fa fa-check"></i><b>28.3</b> Singular Value Decomposition</a></li>
<li class="chapter" data-level="28.4" data-path="decompositions.html"><a href="decompositions.html#moore-penrose-inverse"><i class="fa fa-check"></i><b>28.4</b> Moore-Penrose inverse</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="causal-component-analysis.html"><a href="causal-component-analysis.html"><i class="fa fa-check"></i><b>29</b> Causal Component Analysis</a>
<ul>
<li class="chapter" data-level="29.1" data-path="causal-component-analysis.html"><a href="causal-component-analysis.html#pca-principle-component-analysis"><i class="fa fa-check"></i><b>29.1</b> PCA (Principle Component Analysis)</a></li>
<li class="chapter" data-level="29.2" data-path="causal-component-analysis.html"><a href="causal-component-analysis.html#factor-analysis"><i class="fa fa-check"></i><b>29.2</b> Factor Analysis</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>30</b> Smoothing</a>
<ul>
<li class="chapter" data-level="30.1" data-path="smoothing.html"><a href="smoothing.html#smooth-spline-regression"><i class="fa fa-check"></i><b>30.1</b> Smooth Spline Regression</a></li>
<li class="chapter" data-level="30.2" data-path="smoothing.html"><a href="smoothing.html#multivariate-loess"><i class="fa fa-check"></i><b>30.2</b> Multivariate Loess</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="imbalanced-data.html"><a href="imbalanced-data.html"><i class="fa fa-check"></i><b>31</b> Imbalanced Data</a></li>
<li class="chapter" data-level="32" data-path="text-based-causal-inference.html"><a href="text-based-causal-inference.html"><i class="fa fa-check"></i><b>32</b> Text-based Causal Inference</a></li>
<li class="chapter" data-level="33" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html"><i class="fa fa-check"></i><b>33</b> Other Nonparametric Estimation methods</a>
<ul>
<li class="chapter" data-level="33.1" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#regression-splines"><i class="fa fa-check"></i><b>33.1</b> Regression splines</a></li>
<li class="chapter" data-level="33.2" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#mars"><i class="fa fa-check"></i><b>33.2</b> MARS</a></li>
<li class="chapter" data-level="33.3" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#gam"><i class="fa fa-check"></i><b>33.3</b> GAM</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/mutluyuksel/machinemetrics" target="blank">2023 Initial Draft</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Causal MachineMetrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="error" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Error<a href="error.html#error" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Many inquiries in economics, social sciences, and health sciences are centered around gaining insights about a population. ‘Population’ in this context refers to the complete set of individuals, events, or objects of interest in a study, encompassing all members or occurrences that meet specified criteria. The process of learning from this population can broadly be divided into two categories: estimation and hypothesis testing. Estimation involves determining the value of various population parameters, including the average (mean), variance, standard deviation, median, proportion, range, skewness, and kurtosis. Additionally, estimation also encompasses the calculation of correlation, covariance, and model coefficients. These are crucial for quantifying the relationships between different variables in a model. On the other hand, hypothesis testing is a statistical method used to assess the strength of evidence against a null hypothesis, typically comparing it with an alternative hypothesis. It involves statistically determining whether the observed data deviates significantly from what would be expected under the null hypothesis, thereby providing insights into the likelihood of the occurrence of a specific event or characteristic within the population. This process is fundamental in validating or challenging existing theories and assumptions about the population’s characteristics and behaviors. While hypothesis testing and estimation provide foundational methods for understanding populations, it’s equally vital to consider the role of error in these processes, as it significantly influences the accuracy and reliability of our statistical and machine learning models.</p>
<p>In statistics and machine learning, <strong>error</strong> refers to the discrepancy between a calculated, estimated, or predicted value and the true or actual value. This encompasses estimation error, where estimations deviate from reality due to model limitations or assumptions; measurement errors, arising from inaccuracies in data collection; sampling errors, due to discrepancies between a sample and the overall population; and Type I and II errors in hypothesis testing, which are false positives and false negatives, respectively. In statistics, errors are often part of the model itself, such as the error term in a linear regression model, representing the part of the data that can’t be explained by the estimation model. Sampling error arises because the sample may not perfectly represent the population’s attributes, leading to differences between the true population’s unknown parameters and the observed sample statistics. In machine learning, prediction error is the difference between a model’s predicted values and the actual values. Prediction error is crucial for evaluating model performance, encompassing two types: training error, which occurs on the training dataset and reflects the model’s learning accuracy; and generalization error (or test error), which is observed on new, unseen data, indicating the model’s effectiveness in applying its learning to different scenarios. Minimizing both types of error is key to developing accurate and reliable machine learning models. Model error is the discrepancy between the model’s assumptions and the real-world data it is trying to represent. Model error can occur due to incorrect model assumptions, oversimplification, or failure to capture complex relationships in the data. Algorithmic error arises due to the limitations or biases in the algorithms used for data processing and analysis. Additionally, errors in statistical and machine learning models are often categorized into irreducible and reducible errors. Irreducible error, inherent in any dataset, is the noise that cannot be eliminated by any model, while reducible error is due to the model’s inability to capture the true underlying pattern and can be minimized with better modeling techniques. Understanding and minimizing these errors, if possible, is crucial for effective and ethical decision-making based on data analytics, statistics, and machine learning. Throughout this book, we will explore all these various types of errors fundamental to statistics and machine learning. In this chapter, we’ll focus on estimation error, a cornerstone of statistical analysis, and prediction error, particularly in in-sample or training data, which forms the basis of machine learning.</p>
<p>Assume you’re interested in determining the average years of schooling among residents in your city and also understanding the effect of schooling on income. Collecting this data directly from every individual who constitutes the population of the city is often impractical. A more feasible approach is to gather data from a subset of people, say those passing through a main street, and use this as a sample to estimate the average years of schooling (using method of moments estimators) and estimating the effect of education on income (using OLS to estimate coefficient). For simplicity, assume the subset of people you gather information, your sample, is random and representative of the population. The estimated average, derived from your sample, i.e. realized data,represents an attempt to infer a population parameter - in this case, the mean years of schooling. Using the data from your sample, you can find the the correlation between education and income as well as analyze how schooling effects income by estimating the coefficient in an ordinary linear regression model (with the assumptions we will discuss below). In this specific example, you can estimate the average years of schooling, as well as the correlation between education and income, and the regression coefficient of education on income.</p>
<p>The process of deriving any of these method of moment and coefficient estimates involves selecting an estimator - a statistical method or rule for estimating the unknown population parameter. While the estimator remains unchanged regardless of the sample obtained, and ideally needs to be specified before any sampling carried out, the specific estimate varies with each different sample collected. The ideal scenario is when the estimate from your sample aligns perfectly with the true, but unknown, population parameter. Since the actual parameter is never truly known, statistical properties are used to justify the assumption that your estimate nearly equal to this parameter. Main assumption/requirement of this process is obtaining a representative sample and identifying an unbiased estimator. Even among unbiased estimators, questions arise about which is the ‘best’. This leads us to the concept of estimation error. For instance, the difference between the estimated average schooling and the actual average schooling of the population, or the coefficient which indicates the return of schooling on income. Estimation error is a key aspect of statistical analysis in trying to approximate a population parameter.</p>
<p>Similarly, when using the gathered data to predict an individual’s or a group’s years of schooling, the process will inevitably include some level of prediction error. This error reflects the discrepancy between the predicted value and the actual outcome. It’s easy to assume that we would encounter prediction error primarily in models with limited variables, like those predicting a single parameter such as mean of years of schooling from a sample. However, even in models with large datasets includes numerous variables, prediction error remains an inherent challenge, as we will see in the following example.</p>
<p>Let’s consider a different scenario to more effectively illustrate prediction error. Imagine you are developing a model to predict an individual’s income based on factors like education level, profession, work experience, and any other factors you think might impact income. You use your sample data to train this predictive model. Initially, the model makes predictions about the income of these individuals within the training data. There will be a difference between the predicted income and the actual income for the individuals in your sample. This difference is known as in-sample prediction error and reflects the model’s accuracy in predicting outcomes using the data it was trained on. Despite the model’s sophistication, it cannot perfectly account for every variable influencing future income, such as changes in the state of the economy, individual career preferences, misreporting, or factors that are difficult to quantify numerically, like ability or chance. Moreover, when you apply this model to predict the income of a new set of individuals, outside the training dataset, there will likely be some discrepancy between the model’s predictions and the actual incomes of these new individuals. This discrepancy, known as out-of-sample prediction error, is critical in assessing how well the model generalizes to new, unseen data. Both in-sample and out-of-sample prediction errors are crucial for understanding the model’s effectiveness. Minimizing these prediction errors, especially the out-of-sample error, is a major focus in the field of machine learning, where the emphasis is often on the model’s ability to accurately predict outcomes for new, unseen data.</p>
<p>Recognizing the shift from traditional statistical methods, which concentrate on precise parameter estimation, we will now transition to discussing the concepts of estimation error and mean squared error (MSE). Following this, we will discuss the prediction error and Mean Squared Prediction Error (MSPE), highlighting their importance in the context of statistical and machine learning techniques.</p>
<div id="estimation-error" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Estimation error<a href="error.html#estimation-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we show the concept of estimation error, using a simulation to understand how different estimators can be applied to estimate population parameters like the average years of schooling. We explore various estimators, examine their unbiasedness, and discuss the importance of efficiency and mean square error (MSE) in choosing the best estimator for accurate population parameter estimation. This simulation also highlights the balance between unbiasedness and variance in statistical estimation.</p>
<p>Our main objective is to estimate an unknown population parameter, symbolized as <span class="math inline">\(\theta\)</span>. This parameter, <span class="math inline">\(\theta\)</span>, could be the simple mean of a variable (or feature), <span class="math inline">\(\mu_x\)</span>, or a slope coefficient, <span class="math inline">\(\beta_{1}\)</span>, from OLS estimation (for instance, the OLS regression coefficient of education on income). We use estimator to estimate <span class="math inline">\(\theta\)</span>. Our data comes from a random sample, yet, it may not perfectly represent the entire population, potentially due to sampling or measurement errors, or some other reasons. As a result, our estimate, denoted as <span class="math inline">\(\hat{\theta}\)</span>, might not exactly match the true parameter, <span class="math inline">\(\theta\)</span>. The difference between both is known as estimation error (i.e. <span class="math inline">\(\text{error}=\hat{\theta} - \theta\)</span>). Also, note that when we say we have random samples, we imply that these samples are independent and identically distributed from our population as well.</p>
<p>Let’s simulate the scenario we discussed above, aiming to estimate the average years of schooling of residents in our city. Since collecting data from everyone is impractical, we decide to gather 10 representative samples instead. In this simulation, people report 9 years of education if they’ve completed only compulsory schooling, 12 years if they graduated from high school, or 16 years if they’re college graduates. We’ll assume that reported years of schooling can be any discrete number between 9 and 16. Each of our 10 different representative samples will consist of 5000 individuals.</p>
<p>As previously discussed, estimating a parameter, denoted as <span class="math inline">\(\theta\)</span>, requires choosing an estimator. Estimator is a statistical method or rule used to estimate an unknown population parameter. For estimating population mean, <span class="math inline">\(\mu_x\)</span>, in this simulation, which represents our specific parameter <span class="math inline">\(\theta\)</span>, we can use one of three different estimators.</p>
<p>First, we could use the average of years of schooling (sample mean) for everyone who reported it as an estimator. The average is a straightforward and commonly used estimator because it utilizes all available data points.</p>
<p><span class="math display">\[
\bar{X}=\frac{1}{n} \sum_{i=1}^{n} x_{i}
\]</span>
or alternatively, we can just take the half of the first person’s and last person’s years of schooling. This estimator is simpler and less computationally intensive. It takes into account the variability in the data by considering the extremes (the first and last data points). Although it doesn’t use all data points, it can be a quick and effective estimator when the data is expected to be uniformly. distributed.</p>
<p><span class="math display">\[
\hat{X}=0.5 x_{1}+0.5x_{n}
\]</span>
or as a third alternative, we can just use weighted average of first person and the last person’s years of schooling. This estimator allows for a more nuanced estimation than the equal weighting in the previous method. By adjusting the weights (0.25 for the first person and 0.75 for the last person), this estimator can be tuned to reflect certain assumptions about the distribution of the data, potentially providing a more accurate estimate under specific conditions. As a note, you can find unbiased estimator when you assign any positive values for weights as long as the sum is 1.</p>
<p><span class="math display">\[
  \tilde{X}=0.25 x_{1}+0.75x_{2}
\]</span></p>
<p>In addition to these three estimators, other alternatives for estimating average years of schooling in our simulation may include using the <strong>mode of the sample</strong>, which identifies the most frequently reported years of schooling. Another option is the <strong>trimmed mean</strong>, which calculates the average after excluding extreme values at both ends of the spectrum, reducing the impact of outliers. Lastly, selecting a <strong>single value</strong> at random from the sample as the estimator. While this last method might seems overly simplistic and is subject to high variance, it could be useful in scenarios where a quick, single data-driven decision point is needed.</p>
<p>Therefore, we need to define <strong>what makes an estimator the “best” among others</strong>.</p>
<p>Let’s say we have drawn various random samples that represent the population. For each sample, we find a single value for each parameter, such as the mean or variance of the sample. All these single means of samples will generate a distribution, thus forming the sampling distribution of sample means, or sampling distribution of sample variances. The sampling distribution is a statistical term that refers to the distribution of a parameter (like a mean, variance, or coefficient) across a large number of samples drawn from a specific population. In simpler terms, it represents the likelihood of the various outcomes (probability distribution) of an estimator calculated from multiple random samples of a population. Analyzing this distribution for a parameter estimate, using any of the estimators mentioned above, aids in developing the main criteria that guide us in choosing the ‘best’ estimator. Initially, we need to discuss the expected means and variances of this distribution, which help establish certain principles leading to the development of the main criteria.</p>
<p>The first and most important criteria should be that the expected value, i.e., the mean, of all estimates obtained from various random samples, should be equal to the unknown population parameter, <span class="math inline">\(\theta\)</span>. An estimator that satisfies this condition is referred to as an <strong>unbiased estimator</strong> , (i.e. <span class="math inline">\(\operatorname{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta = 0\)</span> so <span class="math inline">\(\mathbb{E}[\hat{\theta}] = \theta\)</span>. While an unbiased estimator doesn’t ensure that the estimate from a particular sample will exactly match the population parameter, it implies that averaging the estimates from repeatedly drawn random samples, each calculated using the same estimator, will closely approximate the actual population parameter. We showed the therotical proof in the last section. It’s also important to remember that this concept is theoretical, as in practical scenarios we typically work with a single random sample and rely on asymptotic (large sample) properties, which we will explore later.</p>
<p>Numerous econometrics textbooks, including outs in the last section of this chapter, do provide algebraic proofs to demonstrate that estimators for statistical parameters, including the average, variance, correlation, and Ordinary Least Squares (OLS) regression coefficients (both for single-variable and multiple-variable models), are unbiased under certain conditions. These proofs typically rely on assumptions such as linearity, independence, and normality of error terms, among others. However, in this case, we will demonstrate that all three estimators are unbiased through simulation. This approach can offer a clearer understanding of the concept, as visualizing it step-by-step in a simulation often makes it easier to grasp.Through this simulation, one can visually and numerically verify the fundamental statistical properties of i.i.d and unbiased estimators.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="error.html#cb25-1" tabindex="-1"></a><span class="co"># Here is our population</span></span>
<span id="cb25-2"><a href="error.html#cb25-2" tabindex="-1"></a>populationX <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">14</span>,<span class="dv">15</span>,<span class="dv">16</span>)</span>
<span id="cb25-3"><a href="error.html#cb25-3" tabindex="-1"></a></span>
<span id="cb25-4"><a href="error.html#cb25-4" tabindex="-1"></a><span class="co">#Let&#39;s have a containers to have repeated samples (5000)</span></span>
<span id="cb25-5"><a href="error.html#cb25-5" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">5000</span>, <span class="dv">10</span>)</span>
<span id="cb25-6"><a href="error.html#cb25-6" tabindex="-1"></a><span class="fu">colnames</span>(samples) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;X1&quot;</span>, <span class="st">&quot;X2&quot;</span>, <span class="st">&quot;X3&quot;</span>, <span class="st">&quot;X4&quot;</span>, <span class="st">&quot;X5&quot;</span>, <span class="st">&quot;X6&quot;</span>, <span class="st">&quot;X7&quot;</span>, <span class="st">&quot;X8&quot;</span>, <span class="st">&quot;X9&quot;</span>, <span class="st">&quot;X10&quot;</span>)</span>
<span id="cb25-7"><a href="error.html#cb25-7" tabindex="-1"></a></span>
<span id="cb25-8"><a href="error.html#cb25-8" tabindex="-1"></a><span class="co"># Let&#39;s have samples (with replacement always)</span></span>
<span id="cb25-9"><a href="error.html#cb25-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb25-10"><a href="error.html#cb25-10" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(samples)) {</span>
<span id="cb25-11"><a href="error.html#cb25-11" tabindex="-1"></a>  samples[i,] <span class="ot">&lt;-</span> <span class="fu">sample</span>(populationX, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-12"><a href="error.html#cb25-12" tabindex="-1"></a>}</span>
<span id="cb25-13"><a href="error.html#cb25-13" tabindex="-1"></a><span class="fu">head</span>(samples)</span></code></pre></div>
<pre><code>##      X1 X2 X3 X4 X5 X6 X7 X8 X9 X10
## [1,] 15 15 11 14 11 10 10 14 11  13
## [2,] 12 14 14  9 10 11 16 13 11  11
## [3,]  9 12  9  9 13 11 16 10 15  10
## [4,]  9 14 11 12 14  9 11 15 13  12
## [5,] 15 16 10 13 15  9  9 10 15  11
## [6,] 12 13 15 13 11 16 14  9 10  13</code></pre>
<p>We define a population where years of schooling range from 9 to 16. Imagine this as a population where an equal number of individuals have each year of schooling, from 9 years up to 16. Consequently, the average years of schooling in this population, denoted as <span class="math inline">\(\mu_x\)</span>, is known to be 12.5. This average is calculated as the mean of the range of schooling years (9 to 16).</p>
<p>We generate 10 random samples, each consisting of 5000 observations. These observations are created by randomly selecting from the defined population. Below we display the first six rows out of the 5,000 samples, where each row represents a different sample and each column represents a data point within that sample.</p>
<p>We can test the following points:</p>
<ol style="list-style-type: decimal">
<li>Is <span class="math inline">\(X\)</span> independently and identically distributed (i.i.d)?</li>
</ol>
<p>We need to verify that the mean and variance are consistent across different data points within the samples. In another words, an identical distribution requires <span class="math inline">\(\operatorname{E}(x_1)=\operatorname{E}(x_2)=\ldots=\operatorname{E}(x_{10})\)</span> and <span class="math inline">\(\operatorname{Var}(x_1)=\operatorname{Var}(x_2)=\ldots=\operatorname{Var}(x_{10})\)</span>. In addition, independence is further confirmed by ensuring that the correlation (<span class="math inline">\(\operatorname{Corr}\)</span>) between any two different data points is zero, <span class="math inline">\(\operatorname{Corr}(x_i, x_j)=0\)</span> where <span class="math inline">\(i \neq j\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>Are the three estimators, <span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(\hat{X}\)</span>, and <span class="math inline">\(\tilde{X}\)</span>, unbiased?</li>
</ol>
<p>An estimator is considered unbiased if its expected value—the average of the values of the parameters obtained from different samples—equals the true population mean, <span class="math inline">\(\mu_x\)</span> , which in this case is 12.5. This value is known in simulation but unknown in reality.</p>
<p>Let’s see:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="error.html#cb27-1" tabindex="-1"></a><span class="co"># Check if E(x_1)=E(x_2)=...=E(x_10), rounded to 2 decimal places</span></span>
<span id="cb27-2"><a href="error.html#cb27-2" tabindex="-1"></a>colMeans <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">colMeans</span>(samples), <span class="dv">2</span>)</span>
<span id="cb27-3"><a href="error.html#cb27-3" tabindex="-1"></a><span class="fu">print</span>(colMeans)</span></code></pre></div>
<pre><code>##    X1    X2    X3    X4    X5    X6    X7    X8    X9   X10 
## 12.48 12.51 12.48 12.57 12.54 12.51 12.45 12.50 12.51 12.45</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="error.html#cb29-1" tabindex="-1"></a><span class="co"># Check if Var(x_1)=Var(x_2)=...=Var(x_10), rounded to 2 decimal places</span></span>
<span id="cb29-2"><a href="error.html#cb29-2" tabindex="-1"></a>variances <span class="ot">&lt;-</span> <span class="fu">apply</span>(samples, <span class="dv">2</span>, var)</span>
<span id="cb29-3"><a href="error.html#cb29-3" tabindex="-1"></a>variances <span class="ot">&lt;-</span> <span class="fu">round</span>(variances, <span class="dv">2</span>)</span>
<span id="cb29-4"><a href="error.html#cb29-4" tabindex="-1"></a><span class="fu">print</span>(variances)</span></code></pre></div>
<pre><code>##   X1   X2   X3   X4   X5   X6   X7   X8   X9  X10 
## 5.22 5.17 5.28 5.30 5.18 5.31 5.21 5.20 5.27 5.31</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="error.html#cb31-1" tabindex="-1"></a><span class="co"># Check correlation, rounded to 2 decimal places</span></span>
<span id="cb31-2"><a href="error.html#cb31-2" tabindex="-1"></a>correlations <span class="ot">&lt;-</span> <span class="fu">cor</span>(samples)</span>
<span id="cb31-3"><a href="error.html#cb31-3" tabindex="-1"></a>correlations <span class="ot">&lt;-</span> <span class="fu">round</span>(correlations, <span class="dv">2</span>)</span>
<span id="cb31-4"><a href="error.html#cb31-4" tabindex="-1"></a><span class="fu">print</span>(correlations)</span></code></pre></div>
<pre><code>##        X1    X2    X3    X4    X5    X6    X7    X8    X9   X10
## X1   1.00  0.02  0.00  0.00  0.01  0.00 -0.01  0.00  0.00 -0.02
## X2   0.02  1.00  0.01  0.02  0.00  0.00  0.01 -0.01  0.01 -0.02
## X3   0.00  0.01  1.00  0.01  0.01  0.00 -0.02  0.02 -0.01  0.00
## X4   0.00  0.02  0.01  1.00 -0.02  0.00  0.00  0.02  0.01 -0.01
## X5   0.01  0.00  0.01 -0.02  1.00 -0.01  0.00  0.01  0.00  0.01
## X6   0.00  0.00  0.00  0.00 -0.01  1.00  0.01  0.02 -0.02 -0.01
## X7  -0.01  0.01 -0.02  0.00  0.00  0.01  1.00 -0.01  0.01  0.00
## X8   0.00 -0.01  0.02  0.02  0.01  0.02 -0.01  1.00  0.01  0.06
## X9   0.00  0.01 -0.01  0.01  0.00 -0.02  0.01  0.01  1.00  0.01
## X10 -0.02 -0.02  0.00 -0.01  0.01 -0.01  0.00  0.06  0.01  1.00</code></pre>
<p>Note that if you use only unique set of samples, you can get exact results using following commands</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="error.html#cb33-1" tabindex="-1"></a>uniqsam <span class="ot">&lt;-</span> <span class="fu">unique</span>(samples)</span>
<span id="cb33-2"><a href="error.html#cb33-2" tabindex="-1"></a><span class="fu">colMeans</span>(uniqsam)</span>
<span id="cb33-3"><a href="error.html#cb33-3" tabindex="-1"></a><span class="fu">apply</span>(uniqsam, <span class="dv">2</span>, var)</span>
<span id="cb33-4"><a href="error.html#cb33-4" tabindex="-1"></a><span class="fu">cor</span>(uniqsam)</span></code></pre></div>
<p>The observed expected value (mean) and variance of each random sample are nearly equal. It’s worth noting that increasing the number of observations in each sample from 5000 to a larger number would likely result in these means and variances becoming even more similar. Additionally, the correlations between each sample are nearly zero. Thus, we can conclude that the condition of independence and identical distribution (i.i.d) is satisfied.</p>
<p>The next step involves determining if all three estimators are unbiased. For this, we apply each estimator to the random samples to estimate the population parameter. The code below is used to calculate the average value for a variable across multiple samples and then computes the overall average of these averages for each of the three estimators separately.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="error.html#cb34-1" tabindex="-1"></a><span class="co"># First Xbar : sample mean</span></span>
<span id="cb34-2"><a href="error.html#cb34-2" tabindex="-1"></a>X_bar <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">nrow</span>(samples)) <span class="co">#Container to have all Xbars</span></span>
<span id="cb34-3"><a href="error.html#cb34-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(samples)){</span>
<span id="cb34-4"><a href="error.html#cb34-4" tabindex="-1"></a>  X_bar[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(samples[i,])<span class="sc">/</span><span class="fu">ncol</span>(samples)</span>
<span id="cb34-5"><a href="error.html#cb34-5" tabindex="-1"></a>}</span>
<span id="cb34-6"><a href="error.html#cb34-6" tabindex="-1"></a></span>
<span id="cb34-7"><a href="error.html#cb34-7" tabindex="-1"></a>EX_bar <span class="ot">&lt;-</span> <span class="fu">sum</span>(X_bar)<span class="sc">/</span><span class="fu">length</span>(X_bar)</span>
<span id="cb34-8"><a href="error.html#cb34-8" tabindex="-1"></a>EX_bar</span></code></pre></div>
<pre><code>## [1] 12.49894</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="error.html#cb36-1" tabindex="-1"></a><span class="co"># Xhat: the half of the first person&#39;s and last person&#39;s years of schooling</span></span>
<span id="cb36-2"><a href="error.html#cb36-2" tabindex="-1"></a>X_hat <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">nrow</span>(samples))</span>
<span id="cb36-3"><a href="error.html#cb36-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(samples)){</span>
<span id="cb36-4"><a href="error.html#cb36-4" tabindex="-1"></a>  X_hat[i] <span class="ot">&lt;-</span> <span class="fl">0.5</span><span class="sc">*</span>samples[i,<span class="dv">1</span>] <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>samples[i,<span class="dv">10</span>]</span>
<span id="cb36-5"><a href="error.html#cb36-5" tabindex="-1"></a>}</span>
<span id="cb36-6"><a href="error.html#cb36-6" tabindex="-1"></a></span>
<span id="cb36-7"><a href="error.html#cb36-7" tabindex="-1"></a>EX_hat <span class="ot">&lt;-</span> <span class="fu">sum</span>(X_hat)<span class="sc">/</span><span class="fu">length</span>(X_hat)</span>
<span id="cb36-8"><a href="error.html#cb36-8" tabindex="-1"></a>EX_hat</span></code></pre></div>
<pre><code>## [1] 12.466</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="error.html#cb38-1" tabindex="-1"></a><span class="co"># Xtilde: weighted average of first person and the last person&#39;s years of schooling</span></span>
<span id="cb38-2"><a href="error.html#cb38-2" tabindex="-1"></a>X_tilde <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">nrow</span>(samples))</span>
<span id="cb38-3"><a href="error.html#cb38-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(samples)){</span>
<span id="cb38-4"><a href="error.html#cb38-4" tabindex="-1"></a>  X_tilde[i] <span class="ot">&lt;-</span> <span class="fl">0.25</span><span class="sc">*</span>samples[i,<span class="dv">1</span>] <span class="sc">+</span> <span class="fl">0.75</span><span class="sc">*</span>samples[i,<span class="dv">2</span>]</span>
<span id="cb38-5"><a href="error.html#cb38-5" tabindex="-1"></a>}</span>
<span id="cb38-6"><a href="error.html#cb38-6" tabindex="-1"></a></span>
<span id="cb38-7"><a href="error.html#cb38-7" tabindex="-1"></a>EX_tilde <span class="ot">&lt;-</span> <span class="fu">sum</span>(X_tilde)<span class="sc">/</span><span class="fu">length</span>(X_tilde)</span>
<span id="cb38-8"><a href="error.html#cb38-8" tabindex="-1"></a>EX_tilde</span></code></pre></div>
<pre><code>## [1] 12.503</code></pre>
<p>We can conclude all these three estimators are unbiased as <span class="math inline">\(\mathbf{E}(\bar{X})\approx \mathbf{E}(\hat{X}) \approx \mathbf{E}(\tilde{X}) \approx \mu_x \approx 12.5\)</span>.</p>
<p>Increasing the number of observations in each sample, as well as the number of random samples, tends to bring these expected values closer to 12.5, the known population mean. However, it’s important to note that these sample averages are not exactly the same as the population average. The discrepancy between the estimated value (from the sample) and the actual value (from the population) is known as <strong>error</strong>. Ideally, we aim for this error to be zero. As the number of observations in our sample approaches the size of the entire population, this error tends to diminish. Since we can never fully ascertain the exact characteristics of the entire population, we operate under the assumption that this error gets closer to zero as our sample size increases.</p>
</div>
<div id="efficiency" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Efficiency<a href="error.html#efficiency" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Up to this point, we have demonstrated that all three estimators provide unbiased estimates. This means that unbiasedness cannot be the sole criterion for determining the “best” estimator. We seek an estimator that closely approximates the population parameter with a higher likelihood, making the second criterion the choice of a relatively efficient estimator. In other words, the estimator’s probability density function should be concentrated around the true unknown population parameter, indicating that the estimator is <strong>efficient</strong>.</p>
<p>Before discussing efficiency, it’s important to remind the difference between sample mean and variance, and sampling mean and sampling variance.</p>
<p>Let’s say we have drawn various random samples that represent the population. For each sample, we find a single value for each parameter, such as the mean or variance of the sample. We previously defined a <strong>sample mean</strong> as <span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{i=1}^{n} x_{i}=\mu_x\)</span>, and showed as unbiased estimator of unknown population mean, <span class="math inline">\(\mu_x\)</span>. The formula <span class="math inline">\(\hat{\sigma_{X}}^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_{i} - \bar{X})^2\)</span> is the estimator for the unknown population variance <span class="math inline">\(Var(X)=\sigma^2_x\)</span>, which is also unbiased (we show this in the last section). This is known as the <strong>sample variance</strong>, calculated by averaging the squared differences of each observation from the sample mean. We use n-1 in the denominator instead of n to provide an unbiased estimate of the unknown population variance, <span class="math inline">\(\sigma^2_x\)</span>.</p>
<p>All these single sample parameters generate a distribution. One of the most important parameters we analyze is the mean. The collection of these means, when derived from a sufficient number of random samples, forms what is known as the sampling distribution of the sample mean. This distribution is a probability distribution of all possible means that could be obtained from sets of samples of the same size drawn from the same population. It plays a crucial role in statistical hypothesis testing and in constructing confidence intervals. The sampling distribution of the sample means has a mean and variance; hence, the mean of the sampling distribution of sample means is called the <strong>sampling mean</strong>, and the variance of the sampling distribution of sample means is called the <strong>sampling variance</strong>.</p>
<p>The sampling distribution refers to the distribution of a parameter (like a mean, variance, or coefficient) across many samples drawn from a specific population. This distribution of outcomes from an estimator features a sampling mean (which is used to check unbiasedness) and a sampling variance (which is used to check efficiency). The standard deviation of the sampling distribution, also known as the standard error, is the square root of the sampling variance and decreases as the sample size increases.</p>
<p>When each random sample with a mean <span class="math inline">\(\mu_x\)</span> and variance <span class="math inline">\(\sigma_{X}^2\)</span> is denoted as <span class="math inline">\(X_{i}\)</span>, then the sampling mean is <span class="math inline">\(E(\bar{X})=\frac{1}{n} \sum_{i=1}^{n} \bar{X_{i}}=\mu_x\)</span>, and the sampling variance is <span class="math inline">\(Var(\bar{X}) = \frac{1}{n} \sum_{i=1}^{n} (\bar{X_{i}} - \mu_x)^2=\frac{\sigma^2_x}{n}\)</span>. (check the derivation in the last section).</p>
<p>In summary, when we have various random samples drawn from a population with mean <span class="math inline">\(\mu_x\)</span> and variance <span class="math inline">\(Var(X)=\sigma^2_x\)</span>, the sampling mean mirrors the population mean. However, the sampling variance equals the population variance, <span class="math inline">\(\sigma^2_x\)</span>, divided by the sample size, <span class="math inline">\(n\)</span>. Therefore, as the sample size increases, the sampling variance approaches zero which is called <em>consistency</em>.</p>
<p>Generally, an estimator’s variance tends to decrease as the sample size increases (Law of Large Numbers). However, we cannot claim one estimator is more efficient than another solely based on a smaller variance if the variances are calculated from different sample sizes. When comparing two unbiased estimators of a parameter, the one with the smaller variance is considered relatively more efficient. Among all unbiased estimators, the one with the smallest variance is deemed the “best”. If an estimator is linear, unbiased, and has the smallest variance among all unbiased linear estimators for a given dataset then it is called the Best Linear Unbiased Estimator (BLUE).</p>
<p>The term “relative efficiency” should be used when comparing different estimators that utilize the same information, meaning they are based on the same data and the same sample size. It’s not applicable when comparing variances of the same estimator derived from different sample sizes.</p>
<p>Therefore, <em>the unbiased estimator with the smallest variance is the best estimate for unknown population parameter</em>. However, it’s important to note that while an unbiased estimator may be more efficient than another, this doesn’t guarantee it will always provide a more accurate estimate. It simply means that it’s more likely to be accurate than the less efficient one.(check the next figure)</p>
<p>Let’s examine our simulation to determine which of the three unbiased estimators has the smallest variance.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="error.html#cb40-1" tabindex="-1"></a><span class="fu">var</span>(X_bar)</span></code></pre></div>
<pre><code>## [1] 0.5385286</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="error.html#cb42-1" tabindex="-1"></a><span class="fu">var</span>(X_hat)</span></code></pre></div>
<pre><code>## [1] 2.590462</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="error.html#cb44-1" tabindex="-1"></a><span class="fu">var</span>(X_tilde)</span></code></pre></div>
<pre><code>## [1] 3.27012</code></pre>
<p>As seen comparing variances, the <span class="math inline">\(\bar{X}\)</span>, the sample mean, has the smallest variance.
We showed the sample average is the most efficient of the all unbiased estimators.</p>
</div>
<div id="mean-square-error" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Mean Square Error<a href="error.html#mean-square-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The Mean Squared Error (MSE) is a fundamental measure for comparing the efficiency of different estimators. It encapsulates both the variance of the estimator and any bias it might introduce. This dual consideration is critical because it addresses the trade-off between precision and accuracy, making MSE a comprehensive criterion for estimator comparison.</p>
<p>Before proceeding, it is important to clarify the terminology used in this context. While some sources may use MSE interchangeably for both estimators and predictors, we will distinguish between these terms to avoid confusion. In this text, MSE refers exclusively to an estimator’s performance measure. In the following section, we will introduce the Mean Squared Prediction Error (MSPE), which, although conceptually and mathematically distinct from MSE, is sometimes conflated with it in other sources. By maintaining this distinction, we aim to enhance clarity and precision in our discussion.</p>
<p><strong>How do we evaluate and compare different estimators when they are not all unbiased?</strong></p>
<p>An unbiased estimator with high variance isn’t always preferable, simply because it’s unbiased, compared to a biased estimator with low variance. When comparing estimators, particularly when not all are unbiased, the choice isn’t straightforward. For example, we might have two estimators for the same population characteristic: one is unbiased but has high variance, while the other is biased but with lower variance. The choice depends on our requirements. In applied microeconomics and social sciences, we often opt for an unbiased estimator when estimation errors are not a major concern. This is because we assume that estimation errors, on average, cancel each other out. This assumption is based on the error term having an expected value of zero (<span class="math inline">\(\operatorname{E}[\epsilon] = 0\)</span>) and a variance of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Which estimator is preferred? Estimator A is unbiased with high variance, while Estimator B has smaller variance but is biased. In the figure below, you can see that from a random sample representing the population, you are more likely to find an estimate for <span class="math inline">\(\theta\)</span> that is closer to the real <span class="math inline">\(\theta\)</span> using Estimator B, even though it has some bias. We will demonstrate this in the next chapter with further simulation.</p>
<p><img src="05-Error_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>In cases where large errors are intolerable, an estimator with lower variance may be chosen, even if it introduces a small bias. For example, , in weather forecasting, slightly biased temperature predictions might be favored if they consistently deliver more reliable results than unbiased models, which may fluctuate wildly from day to day. This reliability is crucial for industries relying on stable weather predictions, such as agriculture or aviation, where planning based on inaccurate forecasts can lead to severe operational disruptions. In medical diagnostics, tests that are slightly biased but have lower variance are sometimes preferred, especially in preliminary screening contexts. A diagnostic test for a disease might be calibrated to have a slight bias towards false positives. This means it may indicate the disease is present when it is not, but ensures that almost all actual cases are detected. In these scenarios, the high cost of errors necessitates the use of estimators that minimize variance, even at the expense of some bias. In other words, selecting an estimator often hinges on the cost associated with an error relative to its size. This cost is quantified by a <em>loss function</em>. In economics, social and health sciences, a commonly used loss function is the mean square error (MSE).</p>
<p>The mean squared error (MSE) of an estimator <span class="math inline">\(\hat{\theta}\)</span> quantifies the average of the squares of the errors—that is, the average squared difference between the estimated values and the true value <span class="math inline">\(\theta\)</span>. It is formally defined as the expected value of the square of the difference between the estimator <span class="math inline">\(\hat{\theta}\)</span> and the true parameter <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
\operatorname{MSE}(\hat{\theta}) = \mathbb{E}\left[(\hat{\theta} - \theta)^2\right]
\]</span></p>
<p>This parameter <span class="math inline">\(\theta\)</span> could represent various statistical measures depending on the context, such as the mean or variance of a variable (or feature) <span class="math inline">\(\mu_x\)</span>, or a slope coefficient <span class="math inline">\(\beta\)</span> from ordinary least squares (OLS) regression.</p>
<p>In the realm of OLS regression, which is frequently encountered in econometrics and other disciplines, the MSE is crucial for estimating coefficients. Consider the simple linear regression model, <span class="math inline">\(y = \beta_0 + \beta_1 X + \epsilon\)</span>. Here, <span class="math inline">\(y\)</span> is the dependent variable, <span class="math inline">\(X\)</span> represents the independent variable(s), <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are coefficients to be estimated, and <span class="math inline">\(\epsilon\)</span> is the error term, typically assumed to have a mean of zero and constant variance, normally distributed (optional).</p>
<p>The goal in Ordinary Least Squares (OLS) regression is to minimize the Mean Squared Error (MSE), which for the residuals <span class="math inline">\(\epsilon_i\)</span> is given by:</p>
<p><span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (\epsilon_i)^2 = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
\]</span></p>
<p>where <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\)</span> represents the predicted value of <span class="math inline">\(y\)</span> based on the regression line. The coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated such that this MSE is minimized. It is important to note that in OLS, we technically minimize the Residual Sum of Squares,<span class="math inline">\(\text{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2\)</span>, which is the sum of the squared residuals; however, minimizing RSS is equivalent to minimizing MSE. Here, a residual is defined as the difference between the observed value and the predicted value, expressed as <span class="math inline">\(y_i - \hat{y}_i\)</span>.</p>
<p>MSE serves as a fundamental measure for comparing the efficiency of different estimators because it encapsulates both the variance of the estimator and any bias it might introduce. This dual consideration is critical because it addresses the trade-off between precision and accuracy, making MSE a comprehensive criterion for estimator comparison.</p>
<p>The MSE can be decomposed into variance and bias as follows:</p>
<p><span class="math display">\[
\text{MSE}(\hat{\theta}) = \mathbb{E}_{\hat{\theta}}\left[(\hat{\theta}-\theta)^2\right] = \left[\text{bias}(\hat{\theta})\right]^{2} + \text{Var}(\hat{\theta})
\]</span></p>
<p>For the error term in OLS regression, this formulation also applies:</p>
<p><span class="math display">\[
\text{MSE}(\hat{\epsilon}) = \mathbb{E}_{\hat{\epsilon}}\left[(\hat{\epsilon}-\epsilon)^2\right] = \left[\text{bias}(\hat{\epsilon})\right]^{2} + \text{Var}(\hat{\epsilon})
\]</span></p>
<p>where <span class="math inline">\(\hat{\epsilon}\)</span> represents the estimated error term and <span class="math inline">\(\epsilon\)</span> the true error term. Minimizing the MSE of the error term is essential for achieving the best model fit, striving for zero bias and minimum variance.</p>
<p>Moreover, the decomposition of the MSE for the coefficient <span class="math inline">\(\hat{\beta}_1\)</span> is:</p>
<p><span class="math display">\[
\text{MSE}(\hat{\beta}_1) = \mathbb{E}[(\hat{\beta}_1 - \beta_1)^2] = \text{Bias}^2(\hat{\beta}_1) + \text{Var}(\hat{\beta}_1)
\]</span></p>
<p>Here, an unbiased estimator with minimum variance is ideal, where the square root of the variance of a coefficient, known as the standard error, provides a measure of the estimator’s precision.</p>
<p>As we conclude this section, it is important to note the other usages of the term Mean Squared Error (MSE) in statistics.</p>
<p>In regression analysis, <em>The Mean Square Error</em> (MSE) may refer to the unbiased estimate of error variance, which is calculated as the residual sum of squares divided by the degrees of freedom. This usage differs from the broader definition previously discussed. Specifically, the unbiased estimate of the variance of the unobserved errors is obtained by dividing the sum of the squared residuals by the degrees of freedom, df = n - p - 1, where n is the number of observations in the sample, and p is the number of parameters estimated in the model, excluding the intercept. This formula provides an unbiased estimate of the variance of the unobserved errors, and it is commonly referred to as the mean squared error.</p>
<p>In the context of Analysis of Variance (ANOVA), which is a statistical method used to analyze differences among group means in a sample, <em>Mean Square Error (MSE)</em> has a specific usage and concept. The Error term in ANOVA represents the “variability within groups” or “unexplained random error.”The primary goal of ANOVA is to identify whether any significant differences exist between the means of three or more unrelated groups. The method divides the observed aggregate variability found within a data set into two parts: variability between groups and variability within groups. Sum of Squares Total (SST) measures the total variance in the data and is calculated as the sum of the squared differences from the overall mean. Sum of Squares Between (SSB) quantifies the variance caused by differences between group means, highlighting the impact of the independent variable on the dependent variable. It is calculated by summing the squared differences between each group mean and the grand mean (overall mean), each multiplied by the number of observations in that group. Sum of Squares Within (SSW), also known as the error term, measures the variance within each group and represents the sum of squares of deviations of each observation from their respective group mean.</p>
<p>These components are related through the formula: SST = SSB + SSW . From these sums of squares, ANOVA calculates the mean squares. The Mean Square Between (MSB) quantifies the average variance between the groups and is calculated as MSB = SSB/k-1 , where k is the number of groups. <em>The Mean Square Error</em> (MSE), also known as the Mean Square Within (MSW), measures the average the squares of the errors (the residuals) within the groups and is computed as MSE = SSW/n-k, where n is the total number of observations. MSE indicates the average variance within each group about their respective group means. A smaller MSE indicates that the data points within each group are closer to their group mean, suggesting less variability within the groups.The ratio of MSB to MSE forms the F-statistic, which is compared against a critical value from an F-distribution to determine the statistical significance of the observed differences among group means. A significant F-statistic indicates that the differences between the group means are statistically significant, suggesting that the independent variable has an effect on the dependent variable. <a href="http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf">Read</a> for more details.</p>
<p><strong>One random sample to population parameters</strong></p>
<p>Before we move on to the next section where we will discuss the Mean Square Prediction Error (MSPE), in this section we want to address a critical issue. In practice, we often have only one sample at our disposal, unlike the multiple random samples used in the simulation above or depicted in the figure. The figure illustrates estimators A and B, utilizing multiple sample-derived estimates to analyze the population parameter <span class="math inline">\(\theta\)</span>, including calculating the estimated mean, variance, distribution, and ultimately visualizing these estimators. This leads us to a pivotal question: how can we estimate a population parameter <span class="math inline">\(\theta\)</span> using only a single random sample?</p>
<p>The objective is to utilize the data within the sample to infer the value of a parameter in the population. “Inferring” involves deducing or concluding information from evidence and reasoning. Statistical inference encompasses the theory, methods, and practice of forming judgments about the parameters of a population and the reliability of statistical relationships, typically based on random sampling.(Wikipedia). In essence, statistical inference is the process of drawing conclusions from data obtained from a subset of a larger population. It’s important to note that no study can generalize universally. As an analyst, it’s your responsibility to clarify the applicability of your results for making inferences and where they might not. This requires a clear description of the sample’s characteristics when interpreting results and making inferences.</p>
<p>To begin, we must collect and verify a random sample from the population of interest. Randomness ensures that every member of the population has an equal chance of being selected, making the sample representative. From this single sample, we calculate sample statistics, such as the sample mean, variance, standard deviation, or regression coefficients. These serve as estimates for the corresponding population parameters.Through statistical inference, specifically through estimation and hypothesis testing, we use the parameters estimated from this random sample to make educated guesses about the population parameters.</p>
<p>A key aspect to consider is the asymptotic or large sample properties of the estimator. The estimator used should ideally exhibit consistency. Consistency is the asymptotic property of the estimator related to its ability to converge to the true population parameter as the sample size increases. For an estimator to be considered consistent, it must fulfill two key conditions: it must be unbiased (or its bias approaches zero as the sample size increases), and its variance must diminish to zero as the sample size grows. Demonstrating that an estimator is consistent involves showing that it converges in probability to the true parameter value as the sample size increases to infinity. This concept is indeed closely related to the Law of Large Numbers (LLN).</p>
<p>Consistency suggests that as the sample size grows, the distribution of an estimator becomes more focused around the true parameter value. However, this concept doesn’t provide any information about the distribution’s shape at a given sample size. To conduct interval estimation and hypothesis testing, we rely on the Central Limit Theorem (CLT) to approximate the estimator’s distribution, allowing for an assumption of an asymptotically normal distribution. The CLT provides a description of the sampling distribution: by giving us information about an estimator (in hypothetical repeated sampling), it decreases the uncertainty of the estimation since now we can calculate how close the statistic is to the parameter.</p>
<p>Next, interval estimation involves calculating a confidence interval that is likely to contain the population parameter. For instance, a 95% confidence interval for the population mean suggests that, if you were to take 100 different samples and compute 100 confidence intervals, about 95 of them would be expected to contain the actual population mean. This approach which is based on CLT allows us to infer population characteristics from a sample with a known level of confidence. We know that if the sample size is big enough (more than 30, for example), the sampling distribution would be normal according to <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">the Central Limit Theorem (CLT)</a>.</p>
<p>The Central Limit Theorem (CLT) is a foundational concept in statistics, explaining how the distribution of sample means becomes approximately normal as the sample size increases, regardless of the population’s distribution. This theorem applies when the random variables are independent and identically distributed, and it is most effective when the sample size is large. The CLT’s significance lies in its allowance for the use of normal distribution assumptions in statistical methods, even when the underlying population is not normally distributed. Regression analysis, especially ordinary least squares, often relies on the assumption that the error term has normal distribution. This assumption is justified by considering error term is actually the sum of many independent error terms. Even if these individual errors are not normally distributed, the CLT allows us to approximate the sum of error terms as a normal distribution. This approximation is a crucial aspect of statistical inference in regression analysis.</p>
<p>With this, we want to note that there are several common misconceptions about the CLT, as highlighted by various studies and even in some widely-used textbooks. These misconceptions include the belief that the theorem applies to any random sampling of variables. However, the CLT specifically relates to the means (or sums) of independent and identically distributed random variables obtained through repeated sampling. Another misconception is that the theorem guarantees the emergence of a normal distribution for large samples of any random variable. In reality, what the sampling does is asymptotically reproduce the properties of the population distribution, not necessarily lead to a normal distribution in all cases. This distinction is critical for accurately applying and interpreting the CLT in statistical analysis.</p>
<p>In other words, if the number of observations in each sample large enough, <span class="math inline">\(\bar{X} \sim N(\mu_x, \sigma^{2}_x/n)\)</span> or when population variance is not known <span class="math inline">\(\bar{X} \sim \mathcal{T}\left(\mu, S^{2}\right)\)</span> where <span class="math inline">\(S\)</span> is the standard deviation of the sample and <span class="math inline">\(\mathcal{T}\)</span> is the Student’s <span class="math inline">\(t\)</span>-distribution.</p>
<p>Why is this important? Because it works like a magic: with only one representative sample, we can <strong>generalize</strong> the results for the population. We will not cover the details of interval estimation here, but by knowing <span class="math inline">\(\bar{X}\)</span> and the sample variance <span class="math inline">\(S\)</span>, we can have the following interval for the <span class="math inline">\(\mu_{x}\)</span>:</p>
<p><span class="math display">\[
\left(\bar{x}-t^{*} \frac{s}{\sqrt{n}}, \bar{x}+t^{*} \frac{s}{\sqrt{n}}\right)
\]</span></p>
<p>where <span class="math inline">\(t^*\)</span>, the critical values in <span class="math inline">\(t\)</span>-distribution, are usually around 1.96 for samples more than 100 observations and for the 95% confidence level. This interval would be completely wrong or misleading if <span class="math inline">\(\mathbb{E}(\bar{X}) \neq \mu_x\)</span> and would be useless if it is very wide, which is caused by a large variance. That’s the reason why we don’t like large variances.</p>
<p>“Then, finally, here is how inference works, in one paragraph: we use sample statistics to estimate population parameters — i.e., the statistics we calculate based on random sample data act as statistical estimators for what we truly want to know, the unknown population parameters. We do that by the postulates of the Central Limit Theorem which describe the sampling distribution, the bridge between the statistics and the parameters. By the CLT, we have the sampling distribution as normal. Again, by the CLT, we can center the sampling distribution on the sample mean, and calculate the sampling distribution’s standard error using the sample standard deviation. By applying the properties of the normal probability distribution to the sampling distribution, we then produce population estimates. Ta-da!” <a href="https://pressbooks.bccampus.ca/simplestats/chapter/6-6-the-central-limit-theorem/">from CLT</a></p>
<p>In making these inferences, it’s crucial to consider the assumptions underlying the statistical methods used. Different methods may require certain conditions about the population from which the sample is drawn, such as assuming the population has a normal distribution or that observations within the sample are independent of each other. The accuracy and reliability of the inferences drawn from a sample significantly depend on how well these assumptions are met. By carefully considering these assumptions and applying appropriate statistical inference techniques, we can extend our findings from a single random sample to make broader conclusions about the entire population.</p>
<p><strong>Reminder:</strong></p>
<p>Assuming a true linear model <span class="math inline">\(y=X \beta+\varepsilon\)</span>, estimate <span class="math inline">\(\hat{\beta}\)</span> and prediction <span class="math inline">\(\hat{y}=X \hat{\beta}\)</span>. One can define, with <span class="math inline">\(\|\)</span>.<span class="math inline">\(\|\)</span> the mean square error norm for example:</p>
<ul>
<li><p>Estimation error: <span class="math inline">\(\|\beta-\hat{\beta}\|\)</span></p></li>
<li><p>Prediction error (residual): <span class="math inline">\(\|y-\hat{y}\|=\|X(\beta-\hat{\beta})\|\)</span> (note this definition omits the part related to the error term )</p></li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="error.html#cb46-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123456</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb46-2"><a href="error.html#cb46-2" tabindex="-1"></a></span>
<span id="cb46-3"><a href="error.html#cb46-3" tabindex="-1"></a><span class="co"># Generate integer x values within the desired range</span></span>
<span id="cb46-4"><a href="error.html#cb46-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">sample</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">25</span>, <span class="dv">20</span>, <span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb46-5"><a href="error.html#cb46-5" tabindex="-1"></a></span>
<span id="cb46-6"><a href="error.html#cb46-6" tabindex="-1"></a><span class="co"># Generate y values with a positive shift for all 21 x values</span></span>
<span id="cb46-7"><a href="error.html#cb46-7" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">50</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">21</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">30</span>)</span>
<span id="cb46-8"><a href="error.html#cb46-8" tabindex="-1"></a></span>
<span id="cb46-9"><a href="error.html#cb46-9" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb46-10"><a href="error.html#cb46-10" tabindex="-1"></a></span>
<span id="cb46-11"><a href="error.html#cb46-11" tabindex="-1"></a><span class="co"># Calculate predicted values</span></span>
<span id="cb46-12"><a href="error.html#cb46-12" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(model)</span>
<span id="cb46-13"><a href="error.html#cb46-13" tabindex="-1"></a></span>
<span id="cb46-14"><a href="error.html#cb46-14" tabindex="-1"></a><span class="co"># Adjust the y-limit for the plot</span></span>
<span id="cb46-15"><a href="error.html#cb46-15" tabindex="-1"></a>y_lim_upper <span class="ot">&lt;-</span> <span class="fu">max</span>(y, predicted) <span class="sc">+</span> <span class="dv">10</span></span>
<span id="cb46-16"><a href="error.html#cb46-16" tabindex="-1"></a>y_lim_lower <span class="ot">&lt;-</span> <span class="fu">min</span>(y, predicted) <span class="sc">-</span> <span class="dv">10</span></span>
<span id="cb46-17"><a href="error.html#cb46-17" tabindex="-1"></a></span>
<span id="cb46-18"><a href="error.html#cb46-18" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb46-19"><a href="error.html#cb46-19" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">25</span>), <span class="at">ylim=</span><span class="fu">c</span>(y_lim_lower, y_lim_upper), <span class="at">main=</span><span class="st">&#39;OLS&#39;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb46-20"><a href="error.html#cb46-20" tabindex="-1"></a><span class="fu">abline</span>(model, <span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb46-21"><a href="error.html#cb46-21" tabindex="-1"></a></span>
<span id="cb46-22"><a href="error.html#cb46-22" tabindex="-1"></a><span class="co"># Add segments from each data point to the regression line</span></span>
<span id="cb46-23"><a href="error.html#cb46-23" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(x)) {</span>
<span id="cb46-24"><a href="error.html#cb46-24" tabindex="-1"></a>  <span class="fu">segments</span>(x[i], y[i], x[i], predicted[i], <span class="at">col=</span><span class="st">&#39;blue&#39;</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb46-25"><a href="error.html#cb46-25" tabindex="-1"></a>}</span>
<span id="cb46-26"><a href="error.html#cb46-26" tabindex="-1"></a></span>
<span id="cb46-27"><a href="error.html#cb46-27" tabindex="-1"></a></span>
<span id="cb46-28"><a href="error.html#cb46-28" tabindex="-1"></a><span class="co"># Adding integer x-axis labels using the unique x values</span></span>
<span id="cb46-29"><a href="error.html#cb46-29" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at=</span><span class="fu">sort</span>(<span class="fu">unique</span>(x)), <span class="at">labels=</span><span class="fu">sort</span>(<span class="fu">unique</span>(x)))</span>
<span id="cb46-30"><a href="error.html#cb46-30" tabindex="-1"></a></span>
<span id="cb46-31"><a href="error.html#cb46-31" tabindex="-1"></a><span class="co"># Display y-values on each data point</span></span>
<span id="cb46-32"><a href="error.html#cb46-32" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(y)) {</span>
<span id="cb46-33"><a href="error.html#cb46-33" tabindex="-1"></a>  <span class="fu">text</span>(x[i], y[i], <span class="at">labels=</span><span class="fu">round</span>(y[i], <span class="dv">0</span>), <span class="at">pos=</span><span class="dv">3</span>, <span class="at">cex=</span><span class="fl">0.7</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">offset=</span><span class="fl">0.5</span>)</span>
<span id="cb46-34"><a href="error.html#cb46-34" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="05-Error_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Assuming a true linear model <span class="math inline">\(y=X \beta+\varepsilon\)</span>, we estimate <span class="math inline">\(\hat{\beta_{i}}\)</span>. The Gauss-Markov theorem states that if your linear regression model satisfies the first six classical assumptions, then ordinary least squares (OLS) regression produces unbiased estimates that have the smallest variance of all possible linear estimators,i.e. OLS is BLUE.</p>
<p>OLS Assumption 1: The regression model is linear in parameters (the coefficients) and correctly specified.</p>
<p>OLS Assumption 2: The errors have mean zero.</p>
<p>OLS Assumption 3: All independent variables (regressors) are uncorrelated with the error term.</p>
<p>OLS Assumption 4: The regressors in X must all be linearly independent.</p>
<p>OLS Assumption 5: The error term has a constant variance (no heteroscedasticity).</p>
<p>OLS Assumption 6: No independent variable is a perfect linear function of other explanatory variables (no Multicolinearlity</p>
<p>OLS Assumption 7: The error term is normally distributed (optional)</p>
</div>
<div id="prediction-error--mspe" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Prediction error- MSPE<a href="error.html#prediction-error--mspe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous section, we defined mean square error (MSE) which is used exclusively to describe an estimator’s performance measure, and then decomposed between its variance and bias. While some sources might use MSE interchangeably for both estimators and predictors, we make a clear distinction between these terms to prevent confusion. We prefer the term <strong>Mean Square Prediction Error</strong> (MSPE) in contexts specifically discussing prediction scenarios. We can define a predictor as a function mapping arbitrary inputs to a sample of values of some random variable. In this section, we aim to define the Mean Squared Error (MSE) specifically for prediction across various functions, thus use the term (MSPE). However, in this chapter, we assume different prediction functions to find the best predictor function using the given sample dataset. This involves calculating the Mean Squared Prediction Error (MSPE) for each assumed function using the sample data, and then selecting the function with the lowest in-sample MSPE.</p>
<p>Our objective is the prediction of an outcome <span class="math inline">\(Y\)</span>, which is typical in a supervised learning context where the outcome is known and is non-binary in a regression setup. We model the response variable <span class="math inline">\(Y\)</span> as a function of features <span class="math inline">\(X\)</span>, plus some random noise:
<span class="math display">\[
Y = f(X) + \varepsilon
\]</span></p>
<p>We have a sample set (training set) consisting of data points <span class="math inline">\(x_1, \dots, x_n\)</span> and corresponding real values <span class="math inline">\(y_i\)</span> for each point. The data is assumed to be generated by a true function <span class="math inline">\(f(x)\)</span> with added noise <span class="math inline">\(\varepsilon\)</span>, which has zero mean and a constant variance. Our goal is to find a predictive function <span class="math inline">\(\hat{f}(x)\)</span> that approximates <span class="math inline">\(f(x)\)</span> as closely as possible using a learning algorithm using the training dataset. But how do we define “close”? Commonly, this is done by minimizing the average squared error loss.</p>
<p>The loss function is <span class="math inline">\((Y - f(X))^2\)</span>, and the average squared loss function is the expected value of this loss, termed the Risk function:
<span class="math display">\[
\text{Risk function} = \operatorname{E}\left[(Y - f(X))^2\right]
\]</span>
Thus, our goal is to minimize the Risk function to “predict” <span class="math inline">\(Y\)</span> using <span class="math inline">\(X\)</span>. However, the true function <span class="math inline">\(f(X)\)</span> is unknown, so we aim to find a prediction function <span class="math inline">\(\hat{f}(X)\)</span>, which is an estimate of unknown <span class="math inline">\(f\)</span> using the data we have. This leads to an expected prediction error when predicting <span class="math inline">\(Y\)</span> using <span class="math inline">\(\hat{f}(X)\)</span>. Ultimately, our objective becomes minimizing the average square of this error, called as the <strong>Mean Square Prediction Error (MSPE)</strong>:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{E}\left[(Y - \hat{f}(X))^2\right]
\]</span>
The performance of this function is measured by how small the <strong>mean squared <em>prediction</em> error</strong> <span class="math inline">\((y - \hat{f}(x))^2\)</span> is, not only for the training data but also for new, unseen data points. This model allows us to apply various supervised learning algorithms to find a function <span class="math inline">\(\hat{f}\)</span> that generalizes well beyond the training data, with its expected error decomposable into specific components based on unseen data points. However, due to the noise in <span class="math inline">\(y_i\)</span>, there will always be some level of irreducible error in our predictions.</p>
<p>A good <span class="math inline">\(\hat{f}(X)\)</span> will exhibit a low MSPE. This error can be decomposed into two components: the reducible error (mean squared error), which is the expected squared error loss of estimating <span class="math inline">\(f(X)\)</span> using <span class="math inline">\(\hat{f}(X)\)</span> at a fixed point <span class="math inline">\(X\)</span>, and the irreducible error, essentially the variance of <span class="math inline">\(Y\)</span> given that <span class="math inline">\(X = x\)</span>, representing noise that we aim not to learn.</p>
<p>Reducible error for a given <span class="math inline">\(X = x\)</span> is:
<span class="math display">\[
\operatorname{MSE}(f(x), \hat{f}(x)) = \underbrace{(f(x) - \mathbb{E}[\hat{f}(x)])^2}_{\operatorname{bias}^2(\hat{f}(x))} + \underbrace{\mathbb{E}\left[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2\right]}_{\operatorname{var}(\hat{f}(x))}
\]</span></p>
<p>The Mean Square Prediction Error is:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{E}\left[(Y - \hat{f}(X))^2\right] = \operatorname{Bias}[\hat{f}(X)]^2 + \operatorname{Var}[\hat{f}(X)] + \sigma^2
\]</span>
where <span class="math inline">\(\sigma^2 = \mathbb{E}[\varepsilon^2]\)</span> represents the variance of the noise.</p>
<p>Moreover, the bias-squared and the variance of <span class="math inline">\(\hat{f}\)</span> is called <em>reducible error</em>. Hence, the MSPE can be written as</p>
<p><span class="math display">\[
\operatorname{MSPE}=\operatorname{Reducible~Error}+\operatorname{Irreducible~Error}
\]</span></p>
<p>We want to emphasize the difference between MSE and MSPE, and their decomposed forms in terms of their variances and biases. Even though the formulas for MSE for an estimator and MSE for a predictor are very similar, they serve distinct purposes. For MSE, bias and variance come from parameter estimation. For MSPE, bias and variance are derived from prediction functions. We try different prediction functions to find the best predictor function. In literature, finding an estimator is referred to as ‘Point Estimation,’ because <span class="math inline">\(\theta\)</span> is a point in a regular space. Conversely, determining the function <span class="math inline">\(f\)</span> is described as ‘Function Estimation,’ since <span class="math inline">\(f\)</span> represents a function within a functional space. A common source of confusion arises because MSE for both estimation and prediction is conceptually similar, leading to their interchangeable use in discussions about bias-variance decomposition, which we will discuss in the next chapter. The predictor with the smallest MSPE will be our choice among other alternative predictor functions. Yet, we have another concern that leads to over-fitting. We will discuss over-fitting in detail in chapter 7. A detailed decomposition of the MSPE can be found in the technical point section at the end of this chapter.</p>
<p>Our job is to pick the best predictor, i.e., a predictor that will have the minimum MSPE among alternatives. In a perfect setting, we want a prediction function with zero bias and low variance to achieve the minimum MSPE. However, this never happens. Unlike an estimator, we can accept some bias as long as the MSPE is lower. More specifically, we can allow a predictor to have a bias if it reduces the variance more than the bias itself increases it. We will provide an example in section 6.3.</p>
<p>Unlike estimations, this shows that, in predictions, we can achieve a reduction in MSPE by allowing a trade-off between variance and bias. We will discuss how we can achieve this in the next chapter. For instance, our predictor could be a constant, which, although it’s a biased predictor, has zero variance. Or our predictor could be the mean of <span class="math inline">\(X\)</span> as this predictor has zero bias but high variance. Or we could choose a predictor which has some bias and variance. We will show an example using these three predictors in the following simulation.</p>
<p>Let’s follow the same simulation example from previous section. Our task is now different. We want to predict the next persons years of schooling using the data we have. Let’s summarize some important facts about MSPE related to this simulation here:</p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(x_0\)</span> be the value we want to predict, and let <span class="math inline">\(\hat{f}\)</span> be the predictor, which could be <span class="math inline">\(\operatorname{E}(\bar{X})\)</span>, <span class="math inline">\(\operatorname{E}(\hat{X})\)</span>, <span class="math inline">\(\operatorname{E}(\tilde{X})\)</span> from section 5.1, or any other predictor.</p></li>
<li><p>We model <span class="math inline">\(x_0\)</span> as <span class="math inline">\(x_0 = \mu_x + \varepsilon_0\)</span>, where <span class="math inline">\(f = \mu_x\)</span> represents the systematic component of <span class="math inline">\(x_0\)</span>. Consequently, <span class="math inline">\(\operatorname{E}[x_0] = f\)</span>, ensuring that <span class="math inline">\(\operatorname{E}[\varepsilon_0] = 0\)</span> because the random error <span class="math inline">\(\varepsilon_0\)</span> has an expected value of zero.</p></li>
<li><p>Since <span class="math inline">\(f\)</span> is modeled as <span class="math inline">\(\mu_x\)</span>, and <span class="math inline">\(\mu_x\)</span> is a constant, the expected value of <span class="math inline">\(f\)</span> is <span class="math inline">\(f\)</span> itself: <span class="math inline">\(\operatorname{E}[f] = f\)</span> and specifically, <span class="math inline">\(\operatorname{E}[\mu_x] = \mu_x\)</span>.</p></li>
<li><p>The variance of <span class="math inline">\(x_0\)</span> is calculated as follows:
<span class="math display">\[
\operatorname{Var}[x_0] = \operatorname{E}\left[(x_0 - \operatorname{E}[x_0])^2\right] = \operatorname{E}\left[(x_0 - f)^2\right] = \operatorname{E}\left[(\mu_x + \varepsilon_0 - \mu_x)^2\right] = \operatorname{E}[\varepsilon_0^2] = \operatorname{Var}[\varepsilon_0] = \sigma^2.
\]</span>
This illustrates that the variance of <span class="math inline">\(x_0\)</span> is entirely due to the variance of <span class="math inline">\(\varepsilon_0\)</span>, given that <span class="math inline">\(\operatorname{E}[\varepsilon_0] = 0\)</span>.</p></li>
</ol>
<p>We want to <strong>predict</strong> the unobserved value of <span class="math inline">\(X\)</span> rather than to estimate <span class="math inline">\(\mu_x\)</span>. Therefore, we need a <strong>predictor</strong>, not an <strong>estimator</strong>.</p>
<p>To answer these questions, we need to compare MSPEs or their square roots (RMSPE) as well. Note that we use MSPE here because our example involves predicting a continuous outcome, not a classification problem. In classification scenarios, where the outcome is binary, the loss function has a different algebraic structure than MSPE. The performance evaluation metrics and methods for classification problems will be discussed in Chapter 21 later.</p>
<p>As we know that, most developed countries require to go to school between age 6 to 16 years old. As a first predictor, we may predict that the years of schooling for the next individual is 10 years. This is a very simple yet practical prediction function that may provide accurate predictions for some individuals. As a second predictor, we can use the average years of schooling in our data as a good predictor for the next individuals schooling level. Thus we have two different prediction functions. First one is a constant, 10, which has bias but zero variance. The other one is mean of our sample for each observation (average of each row), which has smaller bias and higher variance. For simplicity, we can use 1 sample which consist from 5000 individuals in this simulation.</p>
<p>The two predictors are <span class="math inline">\(\hat{f}_1 = 10\)</span> and <span class="math inline">\(\hat{f}_2 = \bar{X}\)</span>:</p>
<p>We will use the same example we worked with before. We sample from this “population” multiple times. Now the task is to use each sample and come up with a predictor (a prediction rule) to predict a number or multiple numbers drawn from the same population.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="error.html#cb47-1" tabindex="-1"></a><span class="co"># Here is our population</span></span>
<span id="cb47-2"><a href="error.html#cb47-2" tabindex="-1"></a>populationX <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">14</span>,<span class="dv">15</span>,<span class="dv">16</span>)</span>
<span id="cb47-3"><a href="error.html#cb47-3" tabindex="-1"></a></span>
<span id="cb47-4"><a href="error.html#cb47-4" tabindex="-1"></a></span>
<span id="cb47-5"><a href="error.html#cb47-5" tabindex="-1"></a><span class="co">#Let&#39;s have a containers to have repeated samples (2000)</span></span>
<span id="cb47-6"><a href="error.html#cb47-6" tabindex="-1"></a>Ms <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb47-7"><a href="error.html#cb47-7" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, Ms, <span class="dv">10</span>)</span>
<span id="cb47-8"><a href="error.html#cb47-8" tabindex="-1"></a><span class="fu">colnames</span>(samples) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;X1&quot;</span>, <span class="st">&quot;X2&quot;</span>, <span class="st">&quot;X3&quot;</span>, <span class="st">&quot;X4&quot;</span>, <span class="st">&quot;X5&quot;</span>, <span class="st">&quot;X6&quot;</span>, <span class="st">&quot;X7&quot;</span>, <span class="st">&quot;X8&quot;</span>, <span class="st">&quot;X9&quot;</span>, <span class="st">&quot;X10&quot;</span>)</span>
<span id="cb47-9"><a href="error.html#cb47-9" tabindex="-1"></a></span>
<span id="cb47-10"><a href="error.html#cb47-10" tabindex="-1"></a><span class="co"># Let&#39;s have samples (with replacement always)</span></span>
<span id="cb47-11"><a href="error.html#cb47-11" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb47-12"><a href="error.html#cb47-12" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(samples)) {</span>
<span id="cb47-13"><a href="error.html#cb47-13" tabindex="-1"></a>  samples[i,] <span class="ot">&lt;-</span> <span class="fu">sample</span>(populationX, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-14"><a href="error.html#cb47-14" tabindex="-1"></a>}</span>
<span id="cb47-15"><a href="error.html#cb47-15" tabindex="-1"></a><span class="fu">head</span>(samples)</span></code></pre></div>
<pre><code>##      X1 X2 X3 X4 X5 X6 X7 X8 X9 X10
## [1,] 15 15 11 14 11 10 10 14 11  13
## [2,] 12 14 14  9 10 11 16 13 11  11
## [3,]  9 12  9  9 13 11 16 10 15  10
## [4,]  9 14 11 12 14  9 11 15 13  12
## [5,] 15 16 10 13 15  9  9 10 15  11
## [6,] 12 13 15 13 11 16 14  9 10  13</code></pre>
<p>As you see, this is the same sample with the previous simulation. You can change the data either setting different values in the seed or changing the sammle size, Ms. Now, Let’s use our predictors and find MSPEs:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="error.html#cb49-1" tabindex="-1"></a><span class="co"># Container to record all predictions</span></span>
<span id="cb49-2"><a href="error.html#cb49-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, Ms, <span class="dv">2</span>)</span>
<span id="cb49-3"><a href="error.html#cb49-3" tabindex="-1"></a></span>
<span id="cb49-4"><a href="error.html#cb49-4" tabindex="-1"></a><span class="co"># fhat_1 = 10</span></span>
<span id="cb49-5"><a href="error.html#cb49-5" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Ms) {</span>
<span id="cb49-6"><a href="error.html#cb49-6" tabindex="-1"></a>  predictions[i,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb49-7"><a href="error.html#cb49-7" tabindex="-1"></a>}</span>
<span id="cb49-8"><a href="error.html#cb49-8" tabindex="-1"></a><span class="co"># fhat_2 - mean</span></span>
<span id="cb49-9"><a href="error.html#cb49-9" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Ms) {</span>
<span id="cb49-10"><a href="error.html#cb49-10" tabindex="-1"></a>  predictions[i,<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">sum</span>(samples[i,])<span class="sc">/</span><span class="fu">length</span>(samples[i,])</span>
<span id="cb49-11"><a href="error.html#cb49-11" tabindex="-1"></a>}</span>
<span id="cb49-12"><a href="error.html#cb49-12" tabindex="-1"></a><span class="fu">head</span>(predictions)</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]   10 12.4
## [2,]   10 12.1
## [3,]   10 11.4
## [4,]   10 12.0
## [5,]   10 12.3
## [6,]   10 12.6</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="error.html#cb51-1" tabindex="-1"></a><span class="co"># MSPE</span></span>
<span id="cb51-2"><a href="error.html#cb51-2" tabindex="-1"></a>MSPE <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, Ms, <span class="dv">2</span>)</span>
<span id="cb51-3"><a href="error.html#cb51-3" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Ms) {</span>
<span id="cb51-4"><a href="error.html#cb51-4" tabindex="-1"></a>  MSPE[i,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mean</span>((populationX<span class="sc">-</span>predictions[i,<span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb51-5"><a href="error.html#cb51-5" tabindex="-1"></a>  MSPE[i,<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mean</span>((populationX<span class="sc">-</span>predictions[i,<span class="dv">2</span>])<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb51-6"><a href="error.html#cb51-6" tabindex="-1"></a>}</span>
<span id="cb51-7"><a href="error.html#cb51-7" tabindex="-1"></a><span class="fu">head</span>(MSPE)</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,] 11.5 5.26
## [2,] 11.5 5.41
## [3,] 11.5 6.46
## [4,] 11.5 5.50
## [5,] 11.5 5.29
## [6,] 11.5 5.26</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="error.html#cb53-1" tabindex="-1"></a><span class="fu">colMeans</span>(MSPE)</span></code></pre></div>
<pre><code>## [1] 11.500000  5.788422</code></pre>
<p>The MSPE of the t <span class="math inline">\(\hat{f}_2\)</span> prediction function is the better as its MSPE is smaller than the other prediction function.</p>
<p>What makes a good predictor? Is being unbiased predictor one of the required property? Would being a biased estimator make it automatically a bad predictor? In predictions, we can have a reduction in MSPE by allowing a <strong>trade-off between variance and bias</strong>. We will discuss this trade-off in the next chapter. We will also show it by using the same simulation.</p>
</div>
<div id="technical-points-and-proofs" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Technical points and proofs<a href="error.html#technical-points-and-proofs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Unbiasedness of a parameter:</strong></p>
<p>To estimate an unknown population parameter, symbolized as <span class="math inline">\(\theta\)</span>, our data comes from a random sample. We refer to <span class="math inline">\(\hat{\theta}\)</span> as the estimator of <span class="math inline">\(\theta\)</span>. The first and most important criteria choosing the “best” estimator should be that the expected value, i.e., the mean, of all estimates obtained from various random samples, should be equal to the unknown population parameter,<span class="math inline">\(\theta\)</span>. An estimator that satisfies this condition is referred to as an unbiased estimator , i.e.,</p>
<p><span class="math display">\[
\operatorname{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta = 0 \quad \text{so} \quad \mathbb{E}[\hat{\theta}] = \theta
\]</span></p>
<p>While an unbiased estimator does not guarantee that the estimate from a particular sample will exactly match the population parameter, it implies that averaging the estimates from repeatedly drawn random samples, each calculated using the same estimator, will closely approximate the actual population parameter. It is important to remember that this concept is theoretical, as in practical scenarios we typically work with a single random sample and rely on asymptotic (large sample) properties.</p>
<p><strong>Unbiasedness of sample mean estimator:</strong></p>
<p>We want to estimate population mean of a variable (feature). Its common notation to use <span class="math inline">\(\mu_x\)</span> instead of <span class="math inline">\(\theta\)</span>, using a sample mean <span class="math inline">\(\bar{X}\)</span> notation for an estimator to estimate this population mean.</p>
<p>Let’s demonstrate the unbiasedness of the sample mean estimator, <span class="math inline">\(\mathbb{E}[\bar{X}]=\mu_x\)</span>. The sample mean <span class="math inline">\(\bar{X}\)</span> is calculated as the average of <span class="math inline">\(n\)</span> observations from a random sample. So
<span class="math display">\[
  \hat{\theta} = \bar{X} = \frac{1}{n} \sum_{i=1}^{n} x_{i}
\]</span>
The expected value of the sample mean is:</p>
<p><span class="math display">\[
\mathbb{E}[\bar{X}] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^{n} x_{i}\right] = \mathbb{E}\left[\frac{1}{n} (x_1 + x_2 + \ldots + x_n)\right]= \frac{1}{n} (\mathbb{E}[x_1] + \mathbb{E}[x_2] + \ldots + \mathbb{E}[x_n])
\]</span></p>
<p>Since the linearity of expectation allows the expectation operator to be distributed over addition.</p>
<p>Assuming each <span class="math inline">\(x_i\)</span> is an independent and identically distributed sample from a population with mean <span class="math inline">\(\mu_x\)</span>, the expectation of each <span class="math inline">\(x_i\)</span> is <span class="math inline">\(\mu_x\)</span>:</p>
<p><span class="math inline">\(\mathbb{E}[x_1] = \mathbb{E}[x_2] = \ldots = \mathbb{E}[x_n] = \mu_x\)</span></p>
<p>Therefore, the equation simplifies to:</p>
<p><span class="math display">\[
\mathbb{E}[\bar{X}]= \frac{1}{n} (\mathbb{E}[x_1] + \mathbb{E}[x_2] + \ldots + \mathbb{E}[x_n]) = \frac{1}{n} (n \mu_x) = \mu_x
\]</span></p>
<p>This shows that <span class="math inline">\(\bar{X}\)</span>, the sample mean, is an unbiased estimator of the population mean <span class="math inline">\(\mu_x\)</span>, as the expected value of <span class="math inline">\(\bar{X}\)</span> equals <span class="math inline">\(\mu_x\)</span>.</p>
<p><strong>The variance of the sampling distribution of sample means (sampling variance):</strong></p>
<p>The sampling distribution refers to the distribution of a parameter (like a mean, variance, or coefficient) across many samples drawn from a specific population. This distribution of outcomes from an estimator has a sampling mean (which is used to check unbiasedness) and a variance, known as the estimator’s sampling variance (which is used to check efficiency). The sampling variance of an estimator quantifies how much the estimates from different samples vary around the true population parameter. A smaller sampling variance indicates that the estimator is more precise and provides more consistent estimates across different samples.</p>
<p>The variance of the sample mean can be expressed using the definition of variance and the linearity of expectation:
<span class="math display">\[
\operatorname{Var}(\bar{X}) = \operatorname{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right)
\]</span></p>
<p>The variance of a constant times a random variable is the square of the constant times the variance of the random variable:
<span class="math display">\[
\operatorname{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right) = \frac{1}{n^2} \operatorname{Var}\left(\sum_{i=1}^n X_i\right)
\]</span></p>
<p>For independent random variables, the variance of their sum is the sum of their variances:
<span class="math display">\[
\operatorname{Var}\left(\sum_{i=1}^n X_i\right) = \operatorname{Var}(X_1) + \operatorname{Var}(X_2) + \ldots + \operatorname{Var}(X_n)
\]</span>
Since the <span class="math inline">\(x_i\)</span> are i.i.d. with variance <span class="math inline">\(\sigma_x^2\)</span>, we have:
<span class="math display">\[
\operatorname{Var}(X_i) = \sigma_x^2 \quad \text{for all } i
\]</span>
Thus:
<span class="math display">\[
\operatorname{Var}\left(\sum_{i=1}^n X_i\right) = \sigma_x^2 + \sigma_x^2 + \ldots + \sigma_x^2 = n \sigma_x^2
\]</span></p>
<p>Substitute back into the variance formula for <span class="math inline">\(\bar{X}\)</span>:
<span class="math display">\[
\operatorname{Var}(\bar{X}) = \frac{1}{n^2} \cdot n \sigma_x^2 = \frac{\sigma_x^2}{n}
\]</span></p>
<p>This derivation concludes that the variance of the sampling mean <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(\frac{\sigma_x^2}{n}\)</span>, highlighting how the variability of the sample mean decreases as the sample size <span class="math inline">\(n\)</span> increases.</p>
<p><strong>Unbiasedness of sample variance estimator:</strong></p>
<p>We aim to estimate the population variance of a variable (or feature). It is common to use the notation <span class="math inline">\(\sigma^2_x\)</span> for the population variance (instead of <span class="math inline">\(\theta\)</span> ), and <span class="math inline">\(\hat{\sigma_{X}}^2\)</span> as the notation for an estimator to estimate this population variance (instead of <span class="math inline">\(\hat{\theta}\)</span> ).</p>
<p>Let’s demonstrate the unbiasedness of the sample variance estimator, where <span class="math inline">\(\mathbb{E}[\hat{\sigma_{X}}^2]=\sigma_x^2\)</span>. The sample variance <span class="math inline">\(\hat{\sigma_{X}}^2\)</span> is calculated using the formula:</p>
<p><span class="math display">\[
\hat{\sigma_{X}}^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{X})^2
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the sample mean. This formula corrects for the bias in the straightforward estimator of variance by dividing by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>, accounting for the degrees of freedom lost in estimating <span class="math inline">\(\bar{X}\)</span> from the sample. The expected value of the sample variance will be shown to be:</p>
<p><span class="math display">\[
\mathbb{E}[\hat{\sigma_{X}}^2] = \mathbb{E}[\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{X})^2] = \frac{1}{n-1}\mathbb{E}[\sum_{i=1}^{n} (x_i - \bar{X})^2] = \frac{1}{n-1} \sum_{i=1}^{n} \mathbb{E}[(x_i - \bar{X})^2] \\
= \frac{1}{n-1} \sum_{i=1}^{n} \mathbb{E}[(x_i^2 - 2x_i\bar{X} + \bar{X}^2)] = \frac{1}{n-1} \sum_{i=1}^{n} (\mathbb{E}[x_i^2] - 2\mathbb{E}[x_i\bar{X}] + \mathbb{E}[\bar{X}^2]) \overset{?}{=} \sigma_x^2
\]</span></p>
<p>Let’s calculate each term in this part of the last equation (<span class="math inline">\(\mathbb{E}[x_i^2] - 2\mathbb{E}[x_i\bar{X}] + \mathbb{E}[\bar{X}^2]\)</span> ) separately:</p>
<p>Term 1: <span class="math inline">\(\mathbb{E}[x_i^2] = \sigma^2_x + \mu^2_x\)</span> since <span class="math inline">\(x_i\)</span> are i.i.d. with mean <span class="math inline">\(\mu_x\)</span> and variance <span class="math inline">\(\sigma^2_x\)</span>, using variance decomposition formula (see below).</p>
<p>Term 2: <span class="math inline">\(\mathbb{E}[x_i\bar{X}] = \mathbb{E}[x_i]\mathbb{E}[\bar{X}] = \mu^2_x\)</span> since <span class="math inline">\(\mathbb{E}[x_i]=\mu_x\)</span> by definition and <span class="math inline">\(\mathbb{E}[\bar{X}] = \mu_x\)</span> as shown above in unbiasness of mean.</p>
<p>Term 3: <span class="math inline">\(\mathbb{E}[\bar{X}^2] = \operatorname{Var}(\bar{X}) + \mathbb{E}[\bar{X}]^2 = \frac{\sigma^2_x}{n} + \mu^2_x\)</span>
since <span class="math inline">\(\mathbb{E}[\bar{X}] = \mu_x\)</span> and <span class="math inline">\(\operatorname{Var}(\bar{X})= \frac{\sigma^2_x}{n}\)</span> (see above), and using variance decomposition formula (see below).</p>
<p>Substituting these into the expectation of the squared differences gives:</p>
<p><span class="math inline">\(\mathbb{E}[x_i^2] - 2\mathbb{E}[x_i\bar{X}] + \mathbb{E}[\bar{X}^2] = (\sigma^2_x + \mu^2_x) - 2\mu^2_x + \left(\frac{\sigma^2_x}{n} + \mu^2_x\right) = \sigma^2_x - \frac{\sigma^2_x}{n}\)</span></p>
<p>Thus, the expected value of the sample variance is:</p>
<p><span class="math display">\[
\mathbb{E}[\sigma_{X}^2] = \frac{1}{n-1} \sum_{i=1}^{n} \mathbb{E}[(x_i - \bar{X})^2] = \frac{1}{n-1} n \left(\sigma^2_x - \frac{\sigma^2_x}{n}\right) = \sigma^2_x
\]</span></p>
<p>This proves that the sample variance formula is an unbiased estimator of the population variance <span class="math inline">\(\sigma^2_x\)</span>, as the expected value of the sample variance equals the population variance.</p>
<p><strong>Variance decomposition formula:</strong>
The variance of a random variable <span class="math inline">\(x\)</span> is defined as:
<span class="math display">\[
\operatorname{Var}(x) = \sigma_{X}^2 = \mathbb{E}[(x - \mu_x)^2] = \mathbb{E}[x^2 - 2x\mu_x + \mu_x^2] = \mathbb{E}[x^2] - 2\mu_x\mathbb{E}[x] + \mathbb{E}[\mu_x^2]
\]</span>
where <span class="math inline">\(\mu_x\)</span> is the expected value (mean) of <span class="math inline">\(x\)</span>. Since the linearity of expectation allows the expectation operator to be distributed over addition.</p>
<p>As <span class="math inline">\(\mathbb{E}[x] = \mu_x\)</span> and <span class="math inline">\(\mu_x\)</span> is a constant, the expectation of a constant is the constant itself, and the expectation of a constant squared is also the constant squared: <span class="math inline">\(\operatorname{Var}(x) = \mathbb{E}[x^2] - 2\mu_x^2 + \mu_x^2\)</span>
Thus, Variance decomposition formula is the following:
<span class="math display">\[
\operatorname{Var}(x) = \mathbb{E}[x^2] - \mu_x^2 \quad \text{or} \quad \operatorname{Var}(x) = \mathbb{E}[x^2] - \mathbb{E}[x^2]
\]</span></p>
<p>Rearranging to solve for <span class="math inline">\(\mathbb{E}[x^2]\)</span> (to use in term 1 and term 3 above), we find:
<span class="math display">\[
\mathbb{E}[x^2] = \operatorname{Var}(x) + \mu_x^2
\]</span></p>
<p>This equation demonstrates that the expected value of the square of the random variable <span class="math inline">\(x\)</span> is equal to the variance of <span class="math inline">\(x\)</span> plus the square of the mean of <span class="math inline">\(x\)</span>, expressed as:
<span class="math display">\[
\mathbb{E}[x_i^2] = \sigma^2_x + \mu_x^2
\]</span></p>
<p>This relationship is fundamental in statistical analysis, particularly in understanding how the variance and mean of a distribution contribute to its second moment.</p>
<p><strong>Proof of variance and bias of decomposition an estimator:</strong></p>
<p>The MSE of an estimator <span class="math inline">\(\hat{\theta}\)</span> with respect to an unknown parameter <span class="math inline">\(\theta\)</span> is defined as:
<span class="math display">\[
\operatorname{MSE}(\hat{\theta})=\mathrm{E}_\theta\left[(\hat{\theta}-\theta)^2\right]=\operatorname{Var}(\hat{\theta})+\operatorname{Bias}(\hat{\theta})^2
\]</span></p>
<p>The estimator <span class="math inline">\(\hat{\theta}\)</span> is derived as a sample statistic and is used to estimate some population parameter, then the expectation is with respect to the sampling distribution of the sample statistic.The MSE can be written as the sum of the variance of the estimator and the squared bias of the estimator.</p>
<p>The mean squared error of the estimator <span class="math inline">\(\hat{\theta}\)</span> is defined as the expected value of the square of the difference between <span class="math inline">\(\hat{\theta}\)</span> and the true parameter <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[
\operatorname{MSE}(\hat{\theta}) = \mathrm{E}\left[(\hat{\theta} - \theta)^2\right]
\]</span></p>
<p>In the next step, we rewrite the squared term by adding and subtracting the expected value of <span class="math inline">\(\hat{\theta}\)</span>, which helps in simplifying the analysis by separating the estimator’s variance from its bias.</p>
<p><span class="math display">\[
=\mathrm{E}\left[\left(\hat{\theta} - \mathrm{E}[\hat{\theta}] + \mathrm{E}[\hat{\theta}] - \theta\right)^2\right]
\]</span></p>
<p>We apply the square of a sum formula. We obtain expected value of an equation which has three parts: the variance of the estimator, the middle term, and the square of the bias as the third term.
<span class="math display">\[
=\mathrm{E}\left[\left(\hat{\theta} - \mathrm{E}[\hat{\theta}]\right)^2 + 2\left(\hat{\theta} - \mathrm{E}[\hat{\theta}]\right)\left(\mathrm{E}[\hat{\theta}] - \theta\right) + \left(\mathrm{E}[\hat{\theta}] - \theta\right)^2\right]
\]</span></p>
<p>Next, we separate outside expectation. The linearity of expectation allow us to handle each component of the expanded square separately.
<span class="math display">\[
=\underbrace{\mathrm{E}\left[\left(\hat{\theta} - \mathrm{E}[\hat{\theta}]\right)^2\right]}  + \underbrace{\mathrm{E}\left[2\left(\hat{\theta} - \mathrm{E}[\hat{\theta}]\right)\left(\mathrm{E}[\hat{\theta}] - \theta\right)\right]} +\underbrace{ \mathrm{E}\left[\left(\mathrm{E}[\hat{\theta}] - \theta\right)^2\right]}
\]</span></p>
<p>The initial term represents the variance of the estimator <span class="math inline">\(\hat{\theta}\)</span>. The middle term comprises two components. The first component is <span class="math inline">\([\hat{\theta} - \mathrm{E}[\hat{\theta}]]\)</span>, which indicates the deviation of <span class="math inline">\(\hat{\theta}\)</span> from its expected value. The second component is <span class="math inline">\(\mathrm{E}[\hat{\theta}] - \theta\)</span>, which is identical to the term that appears in the third term and represents the bias of the estimator <span class="math inline">\(\hat{\theta}\)</span>. Since this bias of an estimator is constant for any sample, it can be removed from the expectation operator in the middle term. Similarly, the initial expectation from the third term can be omitted, as the expected value of a constant squared is the constant itself.</p>
<p>We can simplify the expression by recognizing that the expected value of the deviation <span class="math inline">\(\hat{\theta} - \mathrm{E}[\hat{\theta}]\)</span> is zero, leading to the final form of the MSE. The middle term simplifies to
<span class="math inline">\(2\left(\mathrm{E}[\hat{\theta}] - \theta\right) \mathrm{E}\left[\hat{\theta} - \mathrm{E}[\hat{\theta}]\right] = 2\left(\mathrm{E}[\hat{\theta}] - \theta\right) \cdot 0 = 0\)</span></p>
<p>The final expression of the MSE is the sum of the variance of the estimator <span class="math inline">\(\hat{\theta}\)</span> and the square of the bias, highlighting the bias-variance tradeoff.</p>
<p><span class="math display">\[
=\mathrm{E}\left[\left(\hat{\theta} - \mathrm{E}[\hat{\theta}]\right)^2\right] + \left(\mathrm{E}[\hat{\theta}] - \theta\right)^2
\]</span></p>
<p>which is equal to
<span class="math display">\[
=\operatorname{Var}(\hat{\theta}) + \operatorname{Bias}(\hat{\theta})^2
\]</span></p>
<p><em>Concise proof</em> of the MSE decomposition can also be demonstrated using the well-known identity for any random variable <span class="math inline">\(X\)</span>, which states that:
<span class="math display">\[
\mathbb{E}\left(X^2\right) = \operatorname{Var}(X) + (\mathbb{E}(X))^2.
\]</span>
Applying this identity to the estimator <span class="math inline">\(\hat{\theta}\)</span> with respect to the true parameter <span class="math inline">\(\theta\)</span>, we set <span class="math inline">\(X = \hat{\theta} - \theta\)</span>. Then, the mean squared error (MSE) of <span class="math inline">\(\hat{\theta}\)</span> is given by:
<span class="math display">\[
\operatorname{MSE}(\hat{\theta}) = \mathbb{E}\left[(\hat{\theta} - \theta)^2\right].
\]</span>
Substituting <span class="math inline">\(X\)</span> into the identity, we have:
<span class="math display">\[
\begin{aligned}
\mathbb{E}\left[(\hat{\theta} - \theta)^2\right] &amp; = \operatorname{Var}(\hat{\theta} - \theta) + (\mathbb{E}[\hat{\theta} - \theta])^2 \\
&amp; = \operatorname{Var}(\hat{\theta}) + \operatorname{Bias}^2(\hat{\theta}),
\end{aligned}
\]</span>
where the variance of the estimator <span class="math inline">\(\operatorname{Var}(\hat{\theta})\)</span> comes from the fact that the variance is invariant to shifts by a constant (in this case, <span class="math inline">\(\theta\)</span>), and <span class="math inline">\(\operatorname{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta\)</span> by definition. Thus, the squared bias <span class="math inline">\(\operatorname{Bias}^2(\hat{\theta})\)</span> is the square of the expected deviation of <span class="math inline">\(\hat{\theta}\)</span> from <span class="math inline">\(\theta\)</span>. The final expression for the MSE shows that it is the sum of the variance of the estimator and the square of its bias.</p>
<p>In the case of unbiased estimators, the mean squared error (MSE) simplifies to the variance of the estimator. Given that our criterion is to select only unbiased estimators, where <span class="math inline">\(\mathbb{E}(\hat{\theta}) = \theta\)</span>, the MSE expression reduces to <span class="math inline">\(\mathbb{Var}(\hat{\theta})\)</span>. Consequently, evaluating the performance of alternative unbiased estimators by MSE effectively compares their variances, with the objective of selecting the estimator that offers the smallest variance. From our simulations in the previous section, consider the estimator <span class="math inline">\(\hat{\theta} = \bar{X}\)</span>, where <span class="math inline">\(\theta = \mu_x\)</span> is the parameter we aim to estimate. This setup confirms that <span class="math inline">\(\hat{\theta}\)</span> is indeed unbiased, as <span class="math inline">\(\mathbb{E}(\hat{\theta}) = \mu_x\)</span>, which aligns perfectly with our target <span class="math inline">\(\theta\)</span>. Thus, the efficiency of different unbiased estimators can be directly assessed by comparing their variances through MSE, guiding us toward the most precise estimator based on minimal variance.</p>
<p><strong>OLS Review:</strong></p>
<p><strong>OLS Regression Model</strong></p>
<p>Consider the simple linear regression model:
<span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i
\]</span>
where <span class="math inline">\(Y_i\)</span> is the dependent variable, <span class="math inline">\(X_i\)</span> is the independent variable, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are coefficients, and <span class="math inline">\(\epsilon_i\)</span> represents the <em>unknown</em> error term, assumed to have a mean of zero and constant variance.</p>
<p>Our objective is to find the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that minimize the Mean Squared Error (MSE), which is given by:
<span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2
\]</span>
where <span class="math inline">\(\hat{Y}_i = \hat{\beta_0} + \hat{\beta_1} X_i\)</span> is the predicted value of <span class="math inline">\(Y\)</span> based on the regression line. <span class="math inline">\(Y_i=\hat{Y}_i+\hat{\epsilon}_i\)</span> thus each value of <span class="math inline">\(Y_i\)</span> is divided into fitted value, <span class="math inline">\(\hat{Y}_i\)</span>, and residual, <span class="math inline">\(\hat{\epsilon}_i = Y_i - \hat{Y}_i\)</span>.</p>
<p>The coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated such that the Mean Squared Error (MSE) is minimized. To find an estimator for unkown <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, which minimize MSE, we take its partial derivatives with respect to <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, set them to zero, and solve for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. It is important to note that in Ordinary Least Squares (OLS), a more common explanation for finding the estimates of <span class="math inline">\(\beta_0\)</span> which is <span class="math inline">\(\hat{\beta_0}\)</span>and estimates of <span class="math inline">\(\beta_1\)</span> which is <span class="math inline">\(\hat{\beta_1}\)</span> involves the concept of a residual (or prediction error), defined as the difference between the observed value and the predicted value, expressed as <span class="math inline">\(Y_i - \hat{Y}_i\)</span>. We minimize the Residual Sum of Squares (RSS), given by
<span class="math display">\[
\text{RSS} = \sum_{i=1}^n (\hat{\epsilon}_i)^2= \sum_{i=1}^n (Y_i - \hat{Y}_i)^2,
\]</span>
which is the sum of the squared residuals. However, as can be easily seen from the equations, minimizing RSS is equivalent to minimizing MSE.</p>
<p>Taking the partial derivative of MSE with respect to <span class="math inline">\(\hat{\beta}_0\)</span>:
<span class="math display">\[
\frac{\partial}{\partial \hat{\beta}_0} \left(\frac{1}{n} \sum_{i=1}^n (Y_i - (\hat{\beta}_0 + \hat{\beta}_1 X_i))^2\right) = -\frac{2}{n} \sum_{i=1}^n (Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_i)
\]</span>
Setting this to zero gives:
<span class="math display">\[
\sum_{i=1}^n Y_i - n \hat{\beta}_0 - \hat{\beta}_1 \sum_{i=1}^n X_i = 0
\]</span>
<span class="math display">\[
n \hat{\beta}_0 = \sum_{i=1}^n Y_i - \hat{\beta}_1 \sum_{i=1}^n X_i
\]</span>
<span class="math display">\[
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}
\]</span>
where <span class="math inline">\(\bar{Y}\)</span> and <span class="math inline">\(\bar{X}\)</span> are the sample means of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> respectively.</p>
<p>Taking the partial derivative of MSE with respect to <span class="math inline">\(\hat{\beta}_1\)</span>:
<span class="math display">\[
\frac{\partial}{\partial \hat{\beta}_1} \left(\frac{1}{n} \sum_{i=1}^n (Y_i - (\hat{\beta}_0 + \hat{\beta}_1 X_i))^2\right) = -\frac{2}{n} \sum_{i=1}^n X_i(Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_i)
\]</span>
Setting this to zero gives:
<span class="math display">\[
\sum_{i=1}^n X_i Y_i - \hat{\beta}_0 \sum_{i=1}^n X_i - \hat{\beta}_1 \sum_{i=1}^n X_i^2 = 0
\]</span>
Substituting the expression for <span class="math inline">\(\hat{\beta}_0\)</span> we found earlier:
<span class="math display">\[
\sum_{i=1}^n X_i Y_i - (\bar{Y} - \hat{\beta}_1 \bar{X}) \sum_{i=1}^n X_i - \hat{\beta}_1 \sum_{i=1}^n X_i^2 = 0
\]</span>
<span class="math display">\[
\sum_{i=1}^n X_i Y_i - \bar{Y} \sum_{i=1}^n X_i + \hat{\beta}_1 \bar{X} \sum_{i=1}^n X_i - \hat{\beta}_1 \sum_{i=1}^n X_i^2 = 0
\]</span>
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n X_i Y_i - \bar{Y} \sum_{i=1}^n X_i}{\sum_{i=1}^n X_i^2 - \bar{X} \sum_{i=1}^n X_i}
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n X_i Y_i - n\bar{X}\bar{Y}}{\sum_{i=1}^n X_i^2 - n\bar{X}^2}
\]</span>
This formula gives <span class="math inline">\(\hat{\beta}_1\)</span> as the slope of the regression line, which quantifies the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
This formula also can be written as
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span></p>
<p>Note that: Expand the numerator and denominator of the alternative formula for <span class="math inline">\(\hat{\beta}_1\)</span> as follows to show they are equal with the initial formula for <span class="math inline">\(\hat{\beta}_1\)</span> :</p>
<p>Recognize that:
<span class="math display">\[
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \quad \text{and} \quad \bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i
\]</span></p>
<p><span class="math display">\[
\text{Numerator: } \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y}) = \sum_{i=1}^n (X_i Y_i - X_i \bar{Y} - \bar{X} Y_i + \bar{X} \bar{Y})
\]</span>
<span class="math display">\[
= \sum_{i=1}^n X_i Y_i - \bar{Y} \sum_{i=1}^n X_i - \bar{X} \sum_{i=1}^n Y_i + n \bar{X} \bar{Y}
\]</span>
<span class="math display">\[
= \sum_{i=1}^n X_i Y_i - n \bar{X} \bar{Y}
\]</span></p>
<p><span class="math display">\[
\text{Denominator: } \sum_{i=1}^n (X_i - \bar{X})^2 = \sum_{i=1}^n (X_i^2 - 2 X_i \bar{X} + \bar{X}^2)
\]</span>
<span class="math display">\[
= \sum_{i=1}^n X_i^2 - 2 \bar{X} \sum_{i=1}^n X_i + n \bar{X}^2
\]</span>
<span class="math display">\[
= \sum_{i=1}^n X_i^2 - n \bar{X}^2
\]</span></p>
<p>Therefore, we confirm both formulas are equivalent.</p>
<p><strong>Unbiasness of the OLS Estimator <span class="math inline">\(\hat{\beta}_1\)</span></strong></p>
<p>The OLS estimator <span class="math inline">\(\hat{\beta}_1\)</span> for a simple linear regression model where <span class="math inline">\(y = \beta_0 + \beta_1 X + \epsilon\)</span> is given by:
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
where <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span>. Let us analyze the expectation <span class="math inline">\(\mathbb{E}[\hat{\beta}_1]\)</span>.</p>
<p>Starting from the formula of <span class="math inline">\(\hat{\beta}_1\)</span>, replace <span class="math inline">\(Y_i\)</span> by its expression:
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
We take the expectation of <span class="math inline">\(\hat{\beta}_1\)</span>:
<span class="math display">\[
\mathbb{E}[\hat{\beta}_1] = \mathbb{E}\left[\frac{\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]
\]</span>
Applying the linearity of expectation and simplifying:
<span class="math display">\[
= \frac{\mathbb{E}\left[\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})\right]}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
<span class="math display">\[
= \frac{\sum_{i=1}^n \mathbb{E}[(X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})]}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
Since <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are constants and <span class="math inline">\(\epsilon_i\)</span> are independent of <span class="math inline">\(X_i\)</span> with zero mean, the expectations simplify:
<span class="math display">\[
= \frac{\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i - \beta_0 - \beta_1 \bar{X})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
<span class="math display">\[
= \frac{\beta_1 \sum_{i=1}^n (X_i - \bar{X})^2}{\sum_{i=1}^n (X_i - \bar{X})^2} = \beta_1
\]</span>
This shows that <span class="math inline">\(\mathbb{E}[\hat{\beta}_1] = \beta_1\)</span>, proving that <span class="math inline">\(\hat{\beta}_1\)</span> is an unbiased estimator of <span class="math inline">\(\beta_1\)</span>.</p>
<p><strong>Variance of the OLS Estimator <span class="math inline">\(\hat{\beta}_1\)</span></strong></p>
<p>Given the estimator <span class="math inline">\(\hat{\beta}_1\)</span> for a simple linear regression model:
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
we want to find the variance of <span class="math inline">\(\hat{\beta}_1\)</span>.</p>
<p>The variance of <span class="math inline">\(\hat{\beta}_1\)</span> is defined as:
<span class="math display">\[
\text{Var}(\hat{\beta}_1) = \mathbb{E}[(\hat{\beta}_1 - \mathbb{E}[\hat{\beta}_1])^2]
\]</span></p>
<p>Starting with the formula for <span class="math inline">\(\hat{\beta}_1\)</span>, we know from earlier analysis that <span class="math inline">\(\mathbb{E}[\hat{\beta}_1] = \beta_1\)</span>. Hence, we consider:
<span class="math display">\[
\hat{\beta}_1 - \mathbb{E}[\hat{\beta}_1] = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2} - \beta_1
\]</span>
Since <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span>, substituting <span class="math inline">\(Y_i\)</span> gives:
<span class="math display">\[
= \frac{\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2} - \beta_1
\]</span>
<span class="math display">\[
= \frac{\sum_{i=1}^n (X_i - \bar{X})\epsilon_i}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span></p>
<p>we square it:
<span class="math display">\[
\left(\frac{\sum_{i=1}^n (X_i - \bar{X})\epsilon_i}{\sum_{i=1}^n (X_i - \bar{X})^2}\right)^2 = \frac{\left(\sum_{i=1}^n (X_i - \bar{X})\epsilon_i\right)^2}{\left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^2}
\]</span></p>
<p>Now, taking the expectation of the squared term:
<span class="math display">\[
\mathbb{E}\left[\frac{\left(\sum_{i=1}^n (X_i - \bar{X})\epsilon_i\right)^2}{\left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^2}\right]
\]</span></p>
<p>Since the <span class="math inline">\(\epsilon_i\)</span> terms are independent and identically distributed (i.i.d.) with zero mean and variance <span class="math inline">\(\sigma^2\)</span>, we can expand and simplify the expectation of the numerator:
<span class="math display">\[
\mathbb{E}\left[\left(\sum_{i=1}^n (X_i - \bar{X})\epsilon_i\right)^2\right] = \mathbb{E}\left[\sum_{i=1}^n \sum_{j=1}^n (X_i - \bar{X})(X_j - \bar{X})\epsilon_i \epsilon_j\right]
\]</span>
<span class="math display">\[
= \sum_{i=1}^n \sum_{j=1}^n (X_i - \bar{X})(X_j - \bar{X}) \mathbb{E}[\epsilon_i \epsilon_j]
\]</span>
<span class="math display">\[
= \sum_{i=1}^n (X_i - \bar{X})^2 \mathbb{E}[\epsilon_i^2] = \sum_{i=1}^n (X_i - \bar{X})^2 \sigma^2
\]</span>
because <span class="math inline">\(\mathbb{E}[\epsilon_i \epsilon_j] = 0\)</span> for <span class="math inline">\(i \neq j\)</span> and <span class="math inline">\(\mathbb{E}[\epsilon_i^2] = \sigma^2\)</span>.</p>
<p>The denominator of our original expression remains constant since it does not involve <span class="math inline">\(\epsilon_i\)</span>. Therefore, we simplify the expectation as:
<span class="math display">\[
\frac{\sum_{i=1}^n (X_i - \bar{X})^2 \sigma^2}{\left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^2} = \sigma^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}
\]</span></p>
<p>This shows how the variance of <span class="math inline">\(\hat{\beta}_1\)</span> depends inversely on the sum of squared deviations from the mean of <span class="math inline">\(X\)</span>, and directly on the variance of the error terms, <span class="math inline">\(\sigma^2\)</span>.</p>
<p><strong>Estimating the Variance of the Error Term <span class="math inline">\(\sigma^2\)</span></strong></p>
<p>In the context of ordinary least squares (OLS) regression, the variance of the error terms, <span class="math inline">\(\sigma^2\)</span>, is unknown and must be estimated from the data. This estimate is typically obtained using the residual sum of squares (RSS) divided by the degrees of freedom, which in the simple linear regression model is <span class="math inline">\(n - 2\)</span> (subtracting the number of estimated parameters).</p>
<p>The residual for each observation is given by:
<span class="math display">\[
\epsilon_i = y_i - \hat{y}_i
\]</span>
where <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\)</span> are the predicted values. The RSS is then:
<span class="math display">\[
\text{RSS} = \sum_{i=1}^n \epsilon_i^2 = \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 X_i)^2
\]</span>
The estimator for <span class="math inline">\(\sigma^2\)</span> is:
<span class="math display">\[
\hat{\sigma}^2 = \frac{\text{RSS}}{n - 2}
\]</span>
This provides an unbiased estimate of the variance of the error terms.</p>
<p>The standard error (SE) of <span class="math inline">\(\hat{\beta}_1\)</span> is the square root of the variance of <span class="math inline">\(\hat{\beta}_1\)</span>, which we previously derived as:
<span class="math display">\[
\text{Var}(\hat{\beta}_1) = \sigma^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}
\]</span>
Substituting our estimate for <span class="math inline">\(\sigma^2\)</span>, we have:
<span class="math display">\[
\text{Var}(\hat{\beta}_1) = \hat{\sigma}^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}
\]</span>
and for standard error of <span class="math inline">\(\hat{\beta}_1\)</span>, we can use the formula:
<span class="math display">\[
\text{SE}(\hat{\beta}_1) = \sqrt{\hat{\sigma}^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}}
= \sqrt{\frac{\text{RSS}}{n - 2} \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}}
\]</span>
This standard error is crucial for constructing confidence intervals and conducting hypothesis tests about the slope <span class="math inline">\(\beta_1\)</span>.</p>
<p><strong>Bias-Variance Decomposition for <span class="math inline">\(\beta_1\)</span></strong></p>
<p>In a simple linear regression model <span class="math inline">\(y = \beta_0 + \beta_1 X + \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is the normally distributed error term with zero mean and variance <span class="math inline">\(\sigma^2\)</span>, we can analyze the estimator <span class="math inline">\(\hat{\beta}_1\)</span> for the coefficient <span class="math inline">\(\beta_1\)</span>.</p>
<p>The OLS estimator for <span class="math inline">\(\beta_1\)</span> is given by (as shown above):
<span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
\]</span>
where <span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\bar{Y}\)</span> are the sample means of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> respectively.</p>
<p>The expected value of <span class="math inline">\(\hat{\beta}_1\)</span> is:
<span class="math display">\[
\mathbb{E}[\hat{\beta}_1] = \mathbb{E}\left[\frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]
\]</span>
Since <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span>, we can substitute and simplify:
<span class="math display">\[
\mathbb{E}[\hat{\beta}_1] = \mathbb{E}\left[\frac{\sum_{i=1}^n (X_i - \bar{X})(\beta_0 + \beta_1 X_i + \epsilon_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}\right] = \beta_1
\]</span>
This shows that <span class="math inline">\(\hat{\beta}_1\)</span> is an <strong>unbiased</strong> estimator of <span class="math inline">\(\beta_1\)</span>.(Check below for detailed calculations)</p>
<p>The <em>variance</em> of <span class="math inline">\(\hat{\beta}_1\)</span> is given by:
<span class="math display">\[
\text{Var}(\hat{\beta}_1) = \mathbb{E}[(\hat{\beta}_1 - \mathbb{E}[\hat{\beta}_1])^2] = \sigma^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1} =\frac{ \sigma^2}{ \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)}
\]</span>
This equation highlights that the variance of <span class="math inline">\(\hat{\beta}_1\)</span> depends inversely on the variability of <span class="math inline">\(X\)</span>.</p>
<p>The Mean Squared Error (MSE) of <span class="math inline">\(\hat{\beta}_1\)</span> can be decomposed as follows:
<span class="math display">\[
\text{MSE}(\hat{\beta}_1) = \mathbb{E}[(\hat{\beta}_1 - \beta_1)^2] = \text{Bias}^2(\hat{\beta}_1) + \text{Var}(\hat{\beta}_1)
\]</span>
Given that <span class="math inline">\(\hat{\beta}_1\)</span> is unbiased:
<span class="math display">\[
\text{Bias}(\hat{\beta}_1) = \mathbb{E}[\hat{\beta}_1] - \beta_1 = 0
\]</span>
<span class="math display">\[
\text{MSE}(\hat{\beta}_1) = \text{Var}(\hat{\beta}_1) = \sigma^2 \left(\sum_{i=1}^n (X_i - \bar{X})^2\right)^{-1}
\]</span></p>
<p>This decomposition shows that the MSE of <span class="math inline">\(\hat{\beta}_1\)</span>, in this case, is entirely due to its variance, reflecting the uncertainty due to the variability of <span class="math inline">\(X\)</span> and the noise in the data.</p>
<p><strong>Proof of variance and bias of decomposition a prediction function (MSPE):</strong></p>
<p>We model the response variable <span class="math inline">\(Y\)</span> as a function of features <span class="math inline">\(X\)</span>, combined with some random noise:
<span class="math display">\[
Y = f(X) + \varepsilon
\]</span>
This formulation implies that to “predict” <span class="math inline">\(Y\)</span> using features <span class="math inline">\(X\)</span> means to find an approximation function <span class="math inline">\(\hat{f}\)</span> such that <span class="math inline">\(\hat{f}(X)\)</span> closely approximates <span class="math inline">\(Y\)</span>.</p>
<p>The objective in predictive modeling is to minimize the Mean Square Prediction Error (MSPE), which quantifies how well the prediction function performs. The MSPE is defined as:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{E}\left[(Y - \hat{f}(X))^{2}\right]
\]</span>
Given that <span class="math inline">\(Y\)</span> can be expressed as <span class="math inline">\(f(X) + \varepsilon\)</span>, we substitute <span class="math inline">\(Y\)</span> in the MSPE formula to more explicitly consider the effects of the model and the noise:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{E}\left[(f(X) + \varepsilon - \hat{f}(X))^{2}\right]
\]</span>
This representation allows us to decompose the error into parts directly attributable to the model’s approximation and the inherent noise in the data.</p>
<p>After now on, we will not use the subscript <span class="math inline">\(X\)</span> for the sake of simplicity.</p>
<p><span class="math display">\[
= \operatorname{E}\left[(f+\varepsilon-\hat{f})^{2}\right]
\]</span>
By adding and subtracting <span class="math inline">\(\operatorname{E}[\hat{f}(X)]\)</span>, the MSPE can be rewritten as:
<span class="math display">\[
= \operatorname{E}\left[(f+\varepsilon-\hat{f}+\operatorname{E}[\hat{f}]-\operatorname{E}[\hat{f}])^{2}\right]
\]</span>
We can rewrite the same equation as
<span class="math display">\[
= \operatorname{E}\left[(\underbrace{(f-\operatorname{E}[\hat{f}])}_{a}+\underbrace{\varepsilon}_{b}+\underbrace{(\operatorname{E}[\hat{f}]-\hat{f}}_{c}))^{2}\right]
\]</span></p>
<p>using <span class="math inline">\((a+b+c)^2=a^2+b^2+c^2+2ab+2bc+2ca\)</span>, we will obtain</p>
<p><span class="math display">\[
= \operatorname{E}\left[\underbrace{(f-\operatorname{E}[\hat{f}])^{2}}_{a^2} + \underbrace{\varepsilon^{2}}_{b^2} + \underbrace{(\operatorname{E}[\hat{f}]-\hat{f})^{2}}_{c^2} + \underbrace{2 (f-\operatorname{E}[\hat{f}]) \varepsilon}_{2ab} + \underbrace{2 \varepsilon(\operatorname{E}[\hat{f}]-\hat{f})}_{2bc} + \underbrace{2 (\operatorname{E}[\hat{f}]-\hat{f})(f-\operatorname{E}[\hat{f}])}_{2ca}\right]
\]</span></p>
<p>Using Linearity of Expectation we can distribute the expectation across all terms, and taking 2’s out as <span class="math inline">\(E(cX)=cE(X)\)</span> if c is constant, The MSPE can be decomposed into the following 6 terms:</p>
<p><span class="math display">\[
= \underbrace{\operatorname{E}\left[(f-\operatorname{E}[\hat{f}])^{2}\right]}_{1} + \underbrace{\operatorname{E}\left[\varepsilon^{2}\right]}_{2} + \underbrace{\operatorname{E}\left[(\operatorname{E}[\hat{f}]-\hat{f})^{2}\right]}_{3} +
\underbrace{2 \operatorname{E}[(f-\operatorname{E}[\hat{f}]) \varepsilon]}_{4} + \\
\underbrace{2 \operatorname{E}[\varepsilon(\operatorname{E}[\hat{f}]-\hat{f})]}_{5} +
\underbrace{2 \operatorname{E}[(\operatorname{E}[\hat{f}]-\hat{f})(f-\operatorname{E}[\hat{f}])]}_{6}
\]</span></p>
<p>The simplification of this expression involves the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>The first term, <span class="math inline">\(\operatorname{E}\left[(f-\operatorname{E}[\hat{f}])^{2}\right]\)</span>, simplifies to <span class="math inline">\((f-\operatorname{E}[\hat{f}])^{2}\)</span> is called bias(squared) since the expression <span class="math inline">\((f-\operatorname{E}[\hat{f}])\)</span> (also appears in 4^th and 6th term) is considered constant. This is due to <span class="math inline">\(f\)</span> being the fixed true value and <span class="math inline">\(\operatorname{E}[\hat{f}]\)</span> representing its expected estimate. Both values remain invariant across different samples or realizations of the data, resulting in a constant difference when subtracted.</p></li>
<li><p>The second term <span class="math inline">\(\operatorname{E}\left[\varepsilon^{2}\right]\)</span> is <span class="math inline">\(\sigma^{2}\)</span>, which is irreducible error or the variance of the noise.</p></li>
<li><p>The third term <span class="math inline">\(\operatorname{E}\left[(\operatorname{E}[\hat{f}]-\hat{f})^{2}\right]\)</span> is <span class="math inline">\((\operatorname{E}[\hat{f}]-\hat{f})^{2}\)</span> which is variance of predictor, because <span class="math inline">\((\operatorname{E}[\hat{f}]-\hat{f})^{2}\)</span> is a constant.</p></li>
<li><p>The fourth term <span class="math inline">\(2 \operatorname{E}[(f-\operatorname{E}[\hat{f}]) \varepsilon]\)</span> can be written as <span class="math inline">\(2(f-\operatorname{E}[\hat{f}]) \operatorname{E}[\varepsilon]\)</span> because <span class="math inline">\((f-\operatorname{E}[\hat{f}])^{2}\)</span> is a constant. As the expectation of <span class="math inline">\(\varepsilon\)</span> is zero, this term simplifies to zero.</p></li>
<li><p>The fifth term <span class="math inline">\(2 \operatorname{E}[\varepsilon(\operatorname{E}[\hat{f}]-\hat{f})]\)</span> can be written as <span class="math inline">\(2 \operatorname{E}[\varepsilon] \operatorname{E}[\operatorname{E}[\hat{f}]-\hat{f}]\)</span>. (Note that <span class="math inline">\(\varepsilon\)</span> and <span class="math inline">\(\hat{f}\)</span> are independent). SInce both the expectation of <span class="math inline">\(\varepsilon\)</span> and second component are zero, this term also simplifies to zero.</p></li>
<li><p>The sixth term <span class="math inline">\(2 \operatorname{E}[(\operatorname{E}[\hat{f}]-\hat{f})(f-\operatorname{E}[\hat{f}])]\)</span> also reduces to zero. Since <span class="math inline">\((f-\operatorname{E}[\hat{f}])^{2}\)</span> is constant, we can rewrite this term as <span class="math inline">\(2 (f-\operatorname{E}[\hat{f}]) \operatorname{E}[(\operatorname{E}[\hat{f}]-\hat{f})]\)</span>. Then, observing that <span class="math inline">\(\operatorname{E}[\hat{f}]\)</span> is the expected value of <span class="math inline">\(\hat{f}\)</span>, we recognize that <span class="math inline">\(\operatorname{E}[\operatorname{E}[\hat{f}]-\hat{f}] = \operatorname{E}[\hat{f}] - \operatorname{E}[\hat{f}] = 0\)</span>. Thus, the entire term simplifies to:
<span class="math inline">\(2 (f-\operatorname{E}[\hat{f}]) \cdot 0 = 0\)</span>
This result holds because the expectation of the deviation of <span class="math inline">\(\hat{f}\)</span> from its own expected value is zero, reflecting the property that the mean of deviations from the mean is always zero. Therefore, this term does not contribute to the MSPE.</p></li>
</ol>
<p>Thus, we obtain the final simplified expression for the MSPE as follows:
<span class="math display">\[
\operatorname{MSPE} = (f-\operatorname{E}[\hat{f}])^{2} + \operatorname{E}\left[\varepsilon^{2}\right] + \operatorname{E}\left[(\operatorname{E}[\hat{f}]-\hat{f})^{2}\right]
\]</span></p>
<p>This result highlights the components of MSPE:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{Bias}[\hat{f}]^2 + \operatorname{Var}[\hat{f}] + \sigma^2
\]</span>
where <span class="math inline">\(\sigma^2 = \operatorname{E}[\varepsilon^2]\)</span> represents the irreducible error or the variance of the noise, and the terms <span class="math inline">\(\operatorname{Bias}[\hat{f}]^2\)</span> and <span class="math inline">\(\operatorname{Var}[\hat{f}]\)</span> constitute the reducible error.</p>
<p>The MSPE is thus decomposed into:
<span class="math display">\[
\operatorname{MSPE} = \operatorname{Reducible~Error} + \operatorname{Irreducible~Error}
\]</span></p>
<p><strong>Another proof of bias-variance decomposition of MSPE</strong>
<a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" class="uri">https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff</a></p>
<p>We have a training set that includes data points and corresponding real values for each point. The data is assumed to be generated by a true function with added noise, which has zero mean and a specific variance. Our goal is to find a predictive function that approximates this true function as closely as possible using a learning algorithm and the training data. We evaluate the performance of this function by measuring how small the error is between the predicted values and the actual values, not only for the training data but also for new, unseen data points. However, due to the noise in the actual values, there will always be some level of irreducible error in our predictions. This approach allows us to use various supervised learning algorithms to find a function that generalizes well beyond the training data, with its expected error decompose into specific components based on unseen data points.</p>
<p>Suppose we have a training set consisting of a set of points <span class="math inline">\(x_1, \dots, x_n\)</span> and real values <span class="math inline">\(y_i\)</span> associated with each point <span class="math inline">\(x_i\)</span>. We assume that the data is generated by a function <span class="math inline">\(f(x)\)</span> such as <span class="math inline">\(y = f(x) + \varepsilon\)</span>, where the noise, <span class="math inline">\(\varepsilon\)</span>, has zero mean and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>We want to find a function <span class="math inline">\(\hat{f}(x; D)\)</span>, that approximates the true function <span class="math inline">\(f(x)\)</span> as well as possible, by means of some learning algorithm based on a training dataset (sample) <span class="math inline">\(D = \{(x_1, y_1), \dots, (x_n, y_n)\}\)</span>. We make “as well as possible” precise by measuring the mean squared error between <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{f}(x; D)\)</span>: we want <span class="math inline">\((y - \hat{f}(x; D))^2\)</span> to be minimal, both for <span class="math inline">\(x_1, \dots, x_n\)</span> and for points outside of our sample. Of course, we cannot hope to do so perfectly, since the <span class="math inline">\(y_i\)</span> contain noise <span class="math inline">\(\varepsilon\)</span>; this means we must be prepared to accept an irreducible error in any function we come up with.</p>
<p>Finding an <span class="math inline">\(\hat{f}\)</span> that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning. It turns out that whichever function <span class="math inline">\(\hat{f}\)</span> we select, we can decompose its expected error on an unseen sample <span class="math inline">\(x\)</span> (i.e., conditional to <span class="math inline">\(x\)</span>) as follows:</p>
<p>The derivation of the bias-variance decomposition for squared error proceeds as follows. For notational convenience, we abbreviate <span class="math inline">\(\hat{f} = f(x; D)\)</span> and we drop the <span class="math inline">\(D\)</span> subscript on our expectation operators.</p>
<p>Let us write the mean-squared error of our model:</p>
<p><span class="math display">\[
\mathrm{MSE} \triangleq \mathrm{E}\left[(y-\hat{f})^2\right]=\mathrm{E}\left[y^2-2 y \hat{f}+\hat{f}^2\right]=\mathrm{E}\left[y^2\right]-2 \mathrm{E}[y \hat{f}]+\mathrm{E}\left[\hat{f}^2\right]
\]</span></p>
<p>Firstly, since we model <span class="math inline">\(y=f+\varepsilon\)</span>, we show that
<span class="math display">\[
\begin{aligned}
\mathrm{E}\left[y^2\right] &amp; =\mathrm{E}\left[(f+\varepsilon)^2\right] \\
&amp; =\mathrm{E}\left[f^2\right]+2 \mathrm{E}[f \varepsilon]+\mathrm{E}\left[\varepsilon^2\right] &amp; &amp; \text{by linearity of $\mathrm{E}$}\\
&amp; =f^2+2 f \mathrm{E}[\varepsilon]+\mathrm{E}\left[\varepsilon^2\right]  &amp; &amp; \text{since $f$ does not depend on the data}\\
&amp; =f^2+2 f \cdot 0+\sigma^2 &amp; &amp; \text{since $\varepsilon$ has zero mean and variance $\sigma^2$}
\end{aligned}
\]</span></p>
<p>Secondly,
<span class="math display">\[
\begin{aligned}
\mathrm{E}[y \hat{f}] &amp; =\mathrm{E}[(f+\varepsilon) \hat{f}] &amp; &amp; \text{by linearity of $\mathrm{E}$}\\
&amp; =\mathrm{E}[f \hat{f}]+\mathrm{E}[\varepsilon \hat{f}] &amp; &amp; \text{since $\hat{f}$ and $\varepsilon$ are independent}\\
&amp; =\mathrm{E}[f \hat{f}]+\mathrm{E}[\varepsilon] \mathrm{E}[\hat{f}] &amp; &amp; \text{since $\mathrm{E}[\varepsilon]=0$ }\\
&amp; =f \mathrm{E}[\hat{f}]
\end{aligned}
\]</span>
Lastly,
<span class="math display">\[
\mathbb{E}[\hat{f}^2] = \text{Var}(\hat{f}) + \mathbb{E}[\hat{f}]^2\\
\text{since} \text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 \text{for any random variable $X$}.
\]</span></p>
<p>Eventually, we plug these 3 formulas in our previous derivation of MSE and thus show that:
<span class="math display">\[
\text{MSE} = f^2 + \sigma^2 - 2f\mathbb{E}[\hat{f}] + \text{Var}(\hat{f}) + \mathbb{E}[\hat{f}]^2
\]</span>
<span class="math display">\[
= (f - \mathbb{E}[\hat{f}])^2 + \sigma^2 + \text{Var}(\hat{f})
\]</span>
<span class="math display">\[
= \text{Bias}[\hat{f}]^2 + \sigma^2 + \text{Var}[\hat{f}]
\]</span>
Finally, MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over <span class="math inline">\(x \sim P\)</span>:
<span class="math display">\[
\text{MSE} = \mathbb{E}_x[\text{Bias}[\hat{f}(x; D)]^2 + \text{Var}[\hat{f}(x; D)] + \sigma^2]
\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bias-variance-trade-off.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mutluyuksel/machinemetrics/edit/master/05-Error.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["machinemetrics.pdf", "machinemetrics.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
