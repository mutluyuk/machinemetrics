<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 22 Time Series | MachineMetrics</title>
  <meta name="description" content="Chapter 22 Time Series | MachineMetrics" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 22 Time Series | MachineMetrics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/png/MachineMetrics.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 22 Time Series | MachineMetrics" />
  
  
  <meta name="twitter:image" content="/png/MachineMetrics.png" />

<meta name="author" content="Yigit Aydede and Mutlu Yuksel" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-2.html"/>
<link rel="next" href="forecast.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">.</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-book-is-different"><i class="fa fa-check"></i>Why this book is different?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-manuscript"><i class="fa fa-check"></i>Structure of Manuscript:</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-can-use-this-book"><i class="fa fa-check"></i>Who Can Use This Book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> INTRODUCTION:</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#prediction-vs.-estimation"><i class="fa fa-check"></i><b>1.1</b> Prediction vs. Estimation:</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#where-can-you-use-the-covered-topics-in-social-sciences"><i class="fa fa-check"></i><b>1.2</b> Where can you use the covered topics in Social Sciences?:</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#translation-of-concepts-different-terminology"><i class="fa fa-check"></i><b>1.3</b> Translation of Concepts: Different Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#is-machine-learning-better"><i class="fa fa-check"></i><b>1.4</b> Is Machine Learning Better?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html"><i class="fa fa-check"></i><b>2</b> Statistical Models and Simulations</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#distinguishing-between-statistical-modeling-and-machine-learning-in-data-analysis"><i class="fa fa-check"></i><b>2.1</b> Distinguishing Between Statistical Modeling and Machine Learning in Data Analysis</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#goals-and-objectives"><i class="fa fa-check"></i><b>2.1.1</b> Goals and Objectives</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#prediction-vs.-inference"><i class="fa fa-check"></i><b>2.1.2</b> Prediction vs. Inference</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#conclusion"><i class="fa fa-check"></i><b>2.1.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#parametric-and-nonparametric-models"><i class="fa fa-check"></i><b>2.2</b> Parametric and Nonparametric Models:</a></li>
<li class="chapter" data-level="2.3" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#predictive-vs.-causal-models"><i class="fa fa-check"></i><b>2.3</b> Predictive vs. Causal Models</a></li>
<li class="chapter" data-level="2.4" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#model-selection-and-approaches-in-data-modeling"><i class="fa fa-check"></i><b>2.4</b> Model Selection and Approaches in Data Modeling</a></li>
<li class="chapter" data-level="2.5" data-path="statistical-models-and-simulations.html"><a href="statistical-models-and-simulations.html#simulation"><i class="fa fa-check"></i><b>2.5</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>3</b> Counterfactual:</a>
<ul>
<li class="chapter" data-level="3.1" data-path="counterfactual.html"><a href="counterfactual.html#qualitative-and-quantitative-research-methods"><i class="fa fa-check"></i><b>3.1</b> Qualitative and Quantitative research methods:</a></li>
<li class="chapter" data-level="3.2" data-path="counterfactual.html"><a href="counterfactual.html#quantitative---research-methods"><i class="fa fa-check"></i><b>3.2</b> Quantitative - Research methods :</a></li>
<li class="chapter" data-level="3.3" data-path="counterfactual.html"><a href="counterfactual.html#data-and-visualization"><i class="fa fa-check"></i><b>3.3</b> Data and visualization</a></li>
<li class="chapter" data-level="3.4" data-path="counterfactual.html"><a href="counterfactual.html#correlation"><i class="fa fa-check"></i><b>3.4</b> Correlation</a></li>
<li class="chapter" data-level="3.5" data-path="counterfactual.html"><a href="counterfactual.html#effect-of-x-on-y-regression"><i class="fa fa-check"></i><b>3.5</b> Effect of X on Y / Regression</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="counterfactual.html"><a href="counterfactual.html#how-can-we-estimate-the-population-parameters-beta_0-and-beta_1"><i class="fa fa-check"></i><b>3.5.1</b> How can we estimate the population parameters, <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>?</a></li>
<li class="chapter" data-level="3.5.2" data-path="counterfactual.html"><a href="counterfactual.html#predicting-y"><i class="fa fa-check"></i><b>3.5.2</b> Predicting <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="counterfactual.html"><a href="counterfactual.html#mle"><i class="fa fa-check"></i><b>3.5.3</b> MLE</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="counterfactual.html"><a href="counterfactual.html#causal-effect"><i class="fa fa-check"></i><b>3.6</b> Causal Effect</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="counterfactual.html"><a href="counterfactual.html#average-treatment-effectate"><i class="fa fa-check"></i><b>3.6.1</b> Average Treatment Effect(ATE)</a></li>
<li class="chapter" data-level="3.6.2" data-path="counterfactual.html"><a href="counterfactual.html#additional-treatment-effects"><i class="fa fa-check"></i><b>3.6.2</b> Additional Treatment Effects</a></li>
<li class="chapter" data-level="3.6.3" data-path="counterfactual.html"><a href="counterfactual.html#selection-bias-and-heteregeneous-treatment-effect-bias"><i class="fa fa-check"></i><b>3.6.3</b> Selection Bias and Heteregeneous Treatment Effect Bias:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning.html"><a href="learning.html"><i class="fa fa-check"></i><b>4</b> Learning</a>
<ul>
<li class="chapter" data-level="" data-path="learning.html"><a href="learning.html#learning-systems"><i class="fa fa-check"></i>Learning Systems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>5</b> Error</a>
<ul>
<li class="chapter" data-level="5.1" data-path="error.html"><a href="error.html#estimation-error---mse"><i class="fa fa-check"></i><b>5.1</b> Estimation error - MSE</a></li>
<li class="chapter" data-level="5.2" data-path="error.html"><a href="error.html#prediction-error--mspe"><i class="fa fa-check"></i><b>5.2</b> Prediction error- MSPE</a></li>
<li class="chapter" data-level="5.3" data-path="error.html"><a href="error.html#technical-points-about-mse-and-mspe"><i class="fa fa-check"></i><b>5.3</b> Technical points about MSE and MSPE</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html"><i class="fa fa-check"></i><b>6</b> Bias-Variance Trade-off</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html#biased-estimator-as-a-predictor"><i class="fa fa-check"></i><b>6.1</b> Biased estimator as a predictor</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>7</b> Overfitting</a></li>
<li class="chapter" data-level="8" data-path="regression-v.s.-classification.html"><a href="regression-v.s.-classification.html"><i class="fa fa-check"></i><b>8</b> Regression v.s. Classification</a></li>
<li class="chapter" data-level="9" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html"><i class="fa fa-check"></i><b>9</b> Parametric Estimations - Basics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#parametric-estimations"><i class="fa fa-check"></i><b>9.1</b> Parametric Estimations</a></li>
<li class="chapter" data-level="9.2" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#lpm"><i class="fa fa-check"></i><b>9.2</b> LPM</a></li>
<li class="chapter" data-level="9.3" data-path="parametric-estimations---basics.html"><a href="parametric-estimations---basics.html#logistic-regression"><i class="fa fa-check"></i><b>9.3</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html"><i class="fa fa-check"></i><b>10</b> Nonparametric Estimations - Basics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#density-estimations"><i class="fa fa-check"></i><b>10.1</b> Density estimations</a></li>
<li class="chapter" data-level="10.2" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#kernel-regression"><i class="fa fa-check"></i><b>10.2</b> Kernel regression</a></li>
<li class="chapter" data-level="10.3" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#knn"><i class="fa fa-check"></i><b>10.3</b> Knn</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="nonparametric-estimations---basics.html"><a href="nonparametric-estimations---basics.html#adult-dataset"><i class="fa fa-check"></i><b>10.3.1</b> Adult dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html"><i class="fa fa-check"></i><b>11</b> Hyperparameter Tuning</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#training-and-validation"><i class="fa fa-check"></i><b>11.1</b> Training and Validation</a></li>
<li class="chapter" data-level="11.2" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#splitting-the-data-randomly"><i class="fa fa-check"></i><b>11.2</b> Splitting the data randomly</a></li>
<li class="chapter" data-level="11.3" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>11.3</b> k-fold cross validation</a></li>
<li class="chapter" data-level="11.4" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#grid-search"><i class="fa fa-check"></i><b>11.4</b> Grid Search</a></li>
<li class="chapter" data-level="11.5" data-path="hyperparameter-tuning.html"><a href="hyperparameter-tuning.html#cross-validated-grid-search"><i class="fa fa-check"></i><b>11.5</b> Cross-validated grid search</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html"><i class="fa fa-check"></i><b>12</b> Optimization Algorithms - Basics</a>
<ul>
<li class="chapter" data-level="12.1" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#brute-force-optimization"><i class="fa fa-check"></i><b>12.1</b> Brute-force optimization</a></li>
<li class="chapter" data-level="12.2" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#derivative-based-methods"><i class="fa fa-check"></i><b>12.2</b> Derivative-based methods</a></li>
<li class="chapter" data-level="12.3" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#ml-estimation-with-logistic-regression"><i class="fa fa-check"></i><b>12.3</b> ML Estimation with logistic regression</a></li>
<li class="chapter" data-level="12.4" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#gradient-descent-algorithm"><i class="fa fa-check"></i><b>12.4</b> Gradient Descent Algorithm</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#one-variable"><i class="fa fa-check"></i><b>12.4.1</b> One-variable</a></li>
<li class="chapter" data-level="12.4.2" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#adjustable-lr-and-sgd"><i class="fa fa-check"></i><b>12.4.2</b> Adjustable <code>lr</code> and SGD</a></li>
<li class="chapter" data-level="12.4.3" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#multivariable"><i class="fa fa-check"></i><b>12.4.3</b> Multivariable</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="optimization-algorithms---basics.html"><a href="optimization-algorithms---basics.html#optimization-with-r"><i class="fa fa-check"></i><b>12.5</b> Optimization with R</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="prediction-intervals.html"><a href="prediction-intervals.html"><i class="fa fa-check"></i><b>13</b> Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.1" data-path="prediction-intervals.html"><a href="prediction-intervals.html#prediction-interval-for-unbiased-ols-predictor"><i class="fa fa-check"></i><b>13.1</b> Prediction interval for unbiased OLS predictor</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>14</b> Interpretability</a>
<ul>
<li class="chapter" data-level="14.1" data-path="interpretability.html"><a href="interpretability.html#interpretable-vs-noninterpretable-models"><i class="fa fa-check"></i><b>14.1</b> Interpretable vs NonInterpretable Models</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="shrinkage-models.html"><a href="shrinkage-models.html"><i class="fa fa-check"></i><b>15</b> Shrinkage Models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="shrinkage-models.html"><a href="shrinkage-models.html#ridge"><i class="fa fa-check"></i><b>15.1</b> Ridge</a></li>
<li class="chapter" data-level="15.2" data-path="shrinkage-models.html"><a href="shrinkage-models.html#lasso"><i class="fa fa-check"></i><b>15.2</b> Lasso</a></li>
<li class="chapter" data-level="15.3" data-path="shrinkage-models.html"><a href="shrinkage-models.html#adaptive-lasso"><i class="fa fa-check"></i><b>15.3</b> Adaptive Lasso</a></li>
<li class="chapter" data-level="15.4" data-path="shrinkage-models.html"><a href="shrinkage-models.html#sparsity"><i class="fa fa-check"></i><b>15.4</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>16</b> Regression Trees</a>
<ul>
<li class="chapter" data-level="16.1" data-path="regression-trees.html"><a href="regression-trees.html#cart---classification-tree"><i class="fa fa-check"></i><b>16.1</b> CART - Classification Tree</a></li>
<li class="chapter" data-level="16.2" data-path="regression-trees.html"><a href="regression-trees.html#rpart---recursive-partitioning"><i class="fa fa-check"></i><b>16.2</b> <code>rpart</code> - Recursive Partitioning</a></li>
<li class="chapter" data-level="16.3" data-path="regression-trees.html"><a href="regression-trees.html#pruning"><i class="fa fa-check"></i><b>16.3</b> Pruning</a></li>
<li class="chapter" data-level="16.4" data-path="regression-trees.html"><a href="regression-trees.html#classification-with-titanic"><i class="fa fa-check"></i><b>16.4</b> Classification with Titanic</a></li>
<li class="chapter" data-level="16.5" data-path="regression-trees.html"><a href="regression-trees.html#regression-tree"><i class="fa fa-check"></i><b>16.5</b> Regression Tree</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>17</b> Ensemble Methods</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>17.1</b> Bagging</a></li>
<li class="chapter" data-level="17.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest"><i class="fa fa-check"></i><b>17.2</b> Random Forest</a></li>
<li class="chapter" data-level="17.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting"><i class="fa fa-check"></i><b>17.3</b> Boosting</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#sequential-ensemble-with-gbm"><i class="fa fa-check"></i><b>17.3.1</b> Sequential ensemble with <code>gbm</code></a></li>
<li class="chapter" data-level="17.3.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#adaboost"><i class="fa fa-check"></i><b>17.3.2</b> AdaBoost</a></li>
<li class="chapter" data-level="17.3.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#xgboost"><i class="fa fa-check"></i><b>17.3.3</b> XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#ensemble-applications"><i class="fa fa-check"></i><b>17.4</b> Ensemble Applications</a></li>
<li class="chapter" data-level="17.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification"><i class="fa fa-check"></i><b>17.5</b> Classification</a></li>
<li class="chapter" data-level="17.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#regression"><i class="fa fa-check"></i><b>17.6</b> Regression</a></li>
<li class="chapter" data-level="17.7" data-path="ensemble-methods.html"><a href="ensemble-methods.html#exploration"><i class="fa fa-check"></i><b>17.7</b> Exploration</a></li>
<li class="chapter" data-level="17.8" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-applications"><i class="fa fa-check"></i><b>17.8</b> Boosting Applications</a>
<ul>
<li class="chapter" data-level="17.8.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#regression-1"><i class="fa fa-check"></i><b>17.8.1</b> Regression</a></li>
<li class="chapter" data-level="17.8.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-search-with-parallel-processing"><i class="fa fa-check"></i><b>17.8.2</b> Random search with parallel processing</a></li>
<li class="chapter" data-level="17.8.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-vs.-others"><i class="fa fa-check"></i><b>17.8.3</b> Boosting vs. Others</a></li>
<li class="chapter" data-level="17.8.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification-1"><i class="fa fa-check"></i><b>17.8.4</b> Classification</a></li>
<li class="chapter" data-level="17.8.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#adaboost.m1"><i class="fa fa-check"></i><b>17.8.5</b> AdaBoost.M1</a></li>
<li class="chapter" data-level="17.8.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification-with-xgboost"><i class="fa fa-check"></i><b>17.8.6</b> Classification with XGBoost</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="causal-effect-1.html"><a href="causal-effect-1.html"><i class="fa fa-check"></i><b>18</b> Causal Effect</a>
<ul>
<li class="chapter" data-level="18.1" data-path="causal-effect-1.html"><a href="causal-effect-1.html#random-experiment"><i class="fa fa-check"></i><b>18.1</b> Random experiment</a></li>
<li class="chapter" data-level="18.2" data-path="causal-effect-1.html"><a href="causal-effect-1.html#iv"><i class="fa fa-check"></i><b>18.2</b> IV</a></li>
<li class="chapter" data-level="18.3" data-path="causal-effect-1.html"><a href="causal-effect-1.html#diffd"><i class="fa fa-check"></i><b>18.3</b> DiffD</a></li>
<li class="chapter" data-level="18.4" data-path="causal-effect-1.html"><a href="causal-effect-1.html#rd"><i class="fa fa-check"></i><b>18.4</b> RD</a></li>
<li class="chapter" data-level="18.5" data-path="causal-effect-1.html"><a href="causal-effect-1.html#synthetic-control"><i class="fa fa-check"></i><b>18.5</b> Synthetic control</a></li>
<li class="chapter" data-level="18.6" data-path="causal-effect-1.html"><a href="causal-effect-1.html#doubledebiased-lassomethods"><i class="fa fa-check"></i><b>18.6</b> Double/Debiased Lasso/Methods</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html"><i class="fa fa-check"></i><b>19</b> Heterogeneous Treatment Effects</a>
<ul>
<li class="chapter" data-level="19.1" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html#causal-tree"><i class="fa fa-check"></i><b>19.1</b> Causal Tree</a></li>
<li class="chapter" data-level="19.2" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html#causal-forest"><i class="fa fa-check"></i><b>19.2</b> Causal Forest</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html"><i class="fa fa-check"></i><b>20</b> Model selection and Sparsity</a>
<ul>
<li class="chapter" data-level="20.1" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#model-selection"><i class="fa fa-check"></i><b>20.1</b> Model selection</a></li>
<li class="chapter" data-level="20.2" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#dropping-a-variable-in-a-regression"><i class="fa fa-check"></i><b>20.2</b> Dropping a variable in a regression</a></li>
<li class="chapter" data-level="20.3" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#out-sample-prediction-accuracy"><i class="fa fa-check"></i><b>20.3</b> out-sample prediction accuracy</a></li>
<li class="chapter" data-level="20.4" data-path="model-selection-and-sparsity.html"><a href="model-selection-and-sparsity.html#sparsity-1"><i class="fa fa-check"></i><b>20.4</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="classification-2.html"><a href="classification-2.html"><i class="fa fa-check"></i><b>21</b> Classification</a>
<ul>
<li class="chapter" data-level="21.1" data-path="classification-2.html"><a href="classification-2.html#nonparametric-classifier---knn"><i class="fa fa-check"></i><b>21.1</b> Nonparametric Classifier - kNN</a></li>
<li class="chapter" data-level="21.2" data-path="classification-2.html"><a href="classification-2.html#mnist-dataset"><i class="fa fa-check"></i><b>21.2</b> <code>mnist</code> Dataset</a></li>
<li class="chapter" data-level="21.3" data-path="classification-2.html"><a href="classification-2.html#linear-classifiers-again"><i class="fa fa-check"></i><b>21.3</b> Linear classifiers (again)</a></li>
<li class="chapter" data-level="21.4" data-path="classification-2.html"><a href="classification-2.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>21.4</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="21.5" data-path="classification-2.html"><a href="classification-2.html#knn-with-caret"><i class="fa fa-check"></i><b>21.5</b> kNN with caret</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="classification-2.html"><a href="classification-2.html#mnist_27"><i class="fa fa-check"></i><b>21.5.1</b> <code>mnist_27</code></a></li>
<li class="chapter" data-level="21.5.2" data-path="classification-2.html"><a href="classification-2.html#adult-dataset-1"><i class="fa fa-check"></i><b>21.5.2</b> Adult dataset</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="classification-2.html"><a href="classification-2.html#tuning-in-classification"><i class="fa fa-check"></i><b>21.6</b> Tuning in Classification</a></li>
<li class="chapter" data-level="21.7" data-path="classification-2.html"><a href="classification-2.html#confusion-matrix"><i class="fa fa-check"></i><b>21.7</b> Confusion matrix</a></li>
<li class="chapter" data-level="21.8" data-path="classification-2.html"><a href="classification-2.html#performance-measures"><i class="fa fa-check"></i><b>21.8</b> Performance measures</a></li>
<li class="chapter" data-level="21.9" data-path="classification-2.html"><a href="classification-2.html#roc-curve"><i class="fa fa-check"></i><b>21.9</b> ROC Curve</a></li>
<li class="chapter" data-level="21.10" data-path="classification-2.html"><a href="classification-2.html#auc---area-under-the-curve"><i class="fa fa-check"></i><b>21.10</b> AUC - Area Under the Curve</a></li>
<li class="chapter" data-level="21.11" data-path="classification-2.html"><a href="classification-2.html#classification-example"><i class="fa fa-check"></i><b>21.11</b> Classification Example</a></li>
<li class="chapter" data-level="21.12" data-path="classification-2.html"><a href="classification-2.html#lpm-1"><i class="fa fa-check"></i><b>21.12</b> LPM</a></li>
<li class="chapter" data-level="21.13" data-path="classification-2.html"><a href="classification-2.html#logistic-regression-1"><i class="fa fa-check"></i><b>21.13</b> Logistic Regression</a></li>
<li class="chapter" data-level="21.14" data-path="classification-2.html"><a href="classification-2.html#knn-1"><i class="fa fa-check"></i><b>21.14</b> kNN</a>
<ul>
<li class="chapter" data-level="21.14.1" data-path="classification-2.html"><a href="classification-2.html#knn-10-fold-cv"><i class="fa fa-check"></i><b>21.14.1</b> kNN 10-fold CV</a></li>
<li class="chapter" data-level="21.14.2" data-path="classification-2.html"><a href="classification-2.html#knn-with-caret-1"><i class="fa fa-check"></i><b>21.14.2</b> kNN with <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>22</b> Time Series</a>
<ul>
<li class="chapter" data-level="22.1" data-path="time-series.html"><a href="time-series.html#arima-models"><i class="fa fa-check"></i><b>22.1</b> ARIMA models</a></li>
<li class="chapter" data-level="22.2" data-path="time-series.html"><a href="time-series.html#hyndman-khandakar-algorithm"><i class="fa fa-check"></i><b>22.2</b> Hyndman-Khandakar algorithm</a></li>
<li class="chapter" data-level="22.3" data-path="time-series.html"><a href="time-series.html#ts-plots"><i class="fa fa-check"></i><b>22.3</b> TS Plots</a></li>
<li class="chapter" data-level="22.4" data-path="time-series.html"><a href="time-series.html#box-cox-transformation"><i class="fa fa-check"></i><b>22.4</b> Box-Cox transformation</a></li>
<li class="chapter" data-level="22.5" data-path="time-series.html"><a href="time-series.html#stationarity"><i class="fa fa-check"></i><b>22.5</b> Stationarity</a></li>
<li class="chapter" data-level="22.6" data-path="time-series.html"><a href="time-series.html#modeling-arima"><i class="fa fa-check"></i><b>22.6</b> Modeling ARIMA</a></li>
<li class="chapter" data-level="22.7" data-path="time-series.html"><a href="time-series.html#grid-search-for-arima"><i class="fa fa-check"></i><b>22.7</b> Grid search for ARIMA</a></li>
<li class="chapter" data-level="22.8" data-path="time-series.html"><a href="time-series.html#hyperparameter-tuning-with-time-series-data"><i class="fa fa-check"></i><b>22.8</b> Hyperparameter tuning with time-series data:</a></li>
<li class="chapter" data-level="22.9" data-path="time-series.html"><a href="time-series.html#speed"><i class="fa fa-check"></i><b>22.9</b> Speed</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="forecast.html"><a href="forecast.html"><i class="fa fa-check"></i><b>23</b> Forecast</a>
<ul>
<li class="chapter" data-level="23.1" data-path="forecast.html"><a href="forecast.html#time-series-embedding"><i class="fa fa-check"></i><b>23.1</b> Time Series Embedding</a></li>
<li class="chapter" data-level="23.2" data-path="forecast.html"><a href="forecast.html#var-for-recursive-forecasting"><i class="fa fa-check"></i><b>23.2</b> VAR for Recursive Forecasting</a></li>
<li class="chapter" data-level="23.3" data-path="forecast.html"><a href="forecast.html#embedding-for-direct-forecast"><i class="fa fa-check"></i><b>23.3</b> Embedding for Direct Forecast</a></li>
<li class="chapter" data-level="23.4" data-path="forecast.html"><a href="forecast.html#random-forest-1"><i class="fa fa-check"></i><b>23.4</b> Random Forest</a></li>
<li class="chapter" data-level="23.5" data-path="forecast.html"><a href="forecast.html#univariate"><i class="fa fa-check"></i><b>23.5</b> Univariate</a></li>
<li class="chapter" data-level="23.6" data-path="forecast.html"><a href="forecast.html#multivariate"><i class="fa fa-check"></i><b>23.6</b> Multivariate</a></li>
<li class="chapter" data-level="23.7" data-path="forecast.html"><a href="forecast.html#rolling-and-expanding-windows"><i class="fa fa-check"></i><b>23.7</b> Rolling and expanding windows</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>24</b> Support Vector Machine</a>
<ul>
<li class="chapter" data-level="24.1" data-path="support-vector-machine.html"><a href="support-vector-machine.html#optimal-separating-classifier"><i class="fa fa-check"></i><b>24.1</b> Optimal Separating Classifier</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="support-vector-machine.html"><a href="support-vector-machine.html#the-margin"><i class="fa fa-check"></i><b>24.1.1</b> The Margin</a></li>
<li class="chapter" data-level="24.1.2" data-path="support-vector-machine.html"><a href="support-vector-machine.html#the-non-separable-case"><i class="fa fa-check"></i><b>24.1.2</b> The Non-Separable Case</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="support-vector-machine.html"><a href="support-vector-machine.html#nonlinear-boundary-with-kernels"><i class="fa fa-check"></i><b>24.2</b> Nonlinear Boundary with Kernels</a></li>
<li class="chapter" data-level="24.3" data-path="support-vector-machine.html"><a href="support-vector-machine.html#application-with-svm"><i class="fa fa-check"></i><b>24.3</b> Application with SVM</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>25</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="25.1" data-path="neural-networks.html"><a href="neural-networks.html#neural-network---the-idea"><i class="fa fa-check"></i><b>25.1</b> Neural Network - the idea</a></li>
<li class="chapter" data-level="25.2" data-path="neural-networks.html"><a href="neural-networks.html#backpropagation"><i class="fa fa-check"></i><b>25.2</b> Backpropagation</a></li>
<li class="chapter" data-level="25.3" data-path="neural-networks.html"><a href="neural-networks.html#neural-network---more-inputs"><i class="fa fa-check"></i><b>25.3</b> Neural Network - More inputs</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>26</b> Deep Learning</a></li>
<li class="chapter" data-level="27" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html"><i class="fa fa-check"></i><b>27</b> Graphical Network Analysis</a>
<ul>
<li class="chapter" data-level="27.1" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#fundementals"><i class="fa fa-check"></i><b>27.1</b> Fundementals</a></li>
<li class="chapter" data-level="27.2" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#covariance"><i class="fa fa-check"></i><b>27.2</b> Covariance</a></li>
<li class="chapter" data-level="27.3" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#correlation-1"><i class="fa fa-check"></i><b>27.3</b> Correlation</a></li>
<li class="chapter" data-level="27.4" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#precision-matrix"><i class="fa fa-check"></i><b>27.4</b> Precision Matrix</a></li>
<li class="chapter" data-level="27.5" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#semi-partial-correlation"><i class="fa fa-check"></i><b>27.5</b> Semi-partial Correlation</a></li>
<li class="chapter" data-level="27.6" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#regularized-covariance-matrix"><i class="fa fa-check"></i><b>27.6</b> Regularized Covariance Matrix</a></li>
<li class="chapter" data-level="27.7" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#multivariate-gaussian-distribution"><i class="fa fa-check"></i><b>27.7</b> Multivariate Gaussian Distribution</a></li>
<li class="chapter" data-level="27.8" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#high-dimensional-data"><i class="fa fa-check"></i><b>27.8</b> High-dimensional data</a></li>
<li class="chapter" data-level="27.9" data-path="graphical-network-analysis.html"><a href="graphical-network-analysis.html#ridge-ell_2-and-glasso-ell_1"><i class="fa fa-check"></i><b>27.9</b> Ridge (<span class="math inline">\(\ell_{2}\)</span>) and glasso (<span class="math inline">\(\ell_{1}\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="decompositions.html"><a href="decompositions.html"><i class="fa fa-check"></i><b>28</b> Decompositions</a>
<ul>
<li class="chapter" data-level="28.1" data-path="decompositions.html"><a href="decompositions.html#matrix-decomposition"><i class="fa fa-check"></i><b>28.1</b> Matrix Decomposition</a></li>
<li class="chapter" data-level="28.2" data-path="decompositions.html"><a href="decompositions.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>28.2</b> Eigenvectors and eigenvalues</a></li>
<li class="chapter" data-level="28.3" data-path="decompositions.html"><a href="decompositions.html#singular-value-decomposition"><i class="fa fa-check"></i><b>28.3</b> Singular Value Decomposition</a></li>
<li class="chapter" data-level="28.4" data-path="decompositions.html"><a href="decompositions.html#rankr-approximations"><i class="fa fa-check"></i><b>28.4</b> Rank(r) Approximations</a></li>
<li class="chapter" data-level="28.5" data-path="decompositions.html"><a href="decompositions.html#moore-penrose-inverse"><i class="fa fa-check"></i><b>28.5</b> Moore-Penrose inverse</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="pca-principle-component-analysis.html"><a href="pca-principle-component-analysis.html"><i class="fa fa-check"></i><b>29</b> PCA (Principle Component Analysis)</a>
<ul>
<li class="chapter" data-level="29.1" data-path="pca-principle-component-analysis.html"><a href="pca-principle-component-analysis.html#factor-analysis"><i class="fa fa-check"></i><b>29.1</b> Factor Analysis</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>30</b> Smoothing</a>
<ul>
<li class="chapter" data-level="30.1" data-path="smoothing.html"><a href="smoothing.html#using-bins"><i class="fa fa-check"></i><b>30.1</b> Using bins</a></li>
<li class="chapter" data-level="30.2" data-path="smoothing.html"><a href="smoothing.html#kernel-smoothing"><i class="fa fa-check"></i><b>30.2</b> Kernel smoothing</a></li>
<li class="chapter" data-level="30.3" data-path="smoothing.html"><a href="smoothing.html#locally-weighted-regression-loess"><i class="fa fa-check"></i><b>30.3</b> Locally weighted regression <code>loess()</code></a></li>
<li class="chapter" data-level="30.4" data-path="smoothing.html"><a href="smoothing.html#smooth-spline-regression"><i class="fa fa-check"></i><b>30.4</b> Smooth Spline Regression</a></li>
<li class="chapter" data-level="30.5" data-path="smoothing.html"><a href="smoothing.html#multivariate-loess"><i class="fa fa-check"></i><b>30.5</b> Multivariate Loess</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="imbalanced-data.html"><a href="imbalanced-data.html"><i class="fa fa-check"></i><b>31</b> Imbalanced Data</a>
<ul>
<li class="chapter" data-level="31.1" data-path="imbalanced-data.html"><a href="imbalanced-data.html#smote"><i class="fa fa-check"></i><b>31.1</b> <code>SMOTE</code></a></li>
<li class="chapter" data-level="31.2" data-path="imbalanced-data.html"><a href="imbalanced-data.html#fraud-detection"><i class="fa fa-check"></i><b>31.2</b> Fraud detection</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="text-analysis.html"><a href="text-analysis.html"><i class="fa fa-check"></i><b>32</b> Text Analysis</a></li>
<li class="chapter" data-level="33" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html"><i class="fa fa-check"></i><b>33</b> Other Nonparametric Estimation methods</a>
<ul>
<li class="chapter" data-level="33.1" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#other-nonparametric-estimation-methods-1"><i class="fa fa-check"></i><b>33.1</b> Other Nonparametric Estimation methods</a></li>
<li class="chapter" data-level="33.2" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#regression-splines"><i class="fa fa-check"></i><b>33.2</b> Regression splines</a></li>
<li class="chapter" data-level="33.3" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#mars"><i class="fa fa-check"></i><b>33.3</b> MARS</a></li>
<li class="chapter" data-level="33.4" data-path="other-nonparametric-estimation-methods.html"><a href="other-nonparametric-estimation-methods.html#gam"><i class="fa fa-check"></i><b>33.4</b> GAM</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/mutluyuk/machinemetrics" target="blank">2023 Initial Draft</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MachineMetrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="time-series" class="section level1 hasAnchor" number="22">
<h1><span class="header-section-number">Chapter 22</span> Time Series<a href="time-series.html#time-series" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>(PART) Time Series {.unnumbered}</p>
<p>Forecasting {.unnumbered}</p>
<p>Time series forecasting is a task that involves using a model to predict future values of a time series based on its past values. The data consists of sequences of values that are recorded at regular intervals over a period of time, such as daily stock prices or monthly weather data. Time series forecasting can be approached using a variety of machine learning techniques, including linear regression, decision trees, and neural networks.</p>
<p>One key difference between time series forecasting and other types of machine learning tasks is the presence of temporal dependencies in the data. In time series data, the value at a particular time point is often influenced by the values that came before it, which means that the order in which the data points are presented is important. This can make time series forecasting more challenging, as the model must take into account the relationships between past and future values in order to make accurate predictions.</p>
<p>One of the most accessible and comprehensive source on forecasting using R is <a href="https://otexts.com/fpp3/">Forecasting: Principles and Practice</a> (FPP3) by Rob J Hyndman and George Athanasopoulos. The book now has the <span class="math inline">\(3^{rd}\)</span> edition that uses the <code>tsibble</code> and <code>fable</code> packages rather than the <code>forecast</code> package. This brings a better integration to the tidyverse collection of packages. A move from FPP2 to FPP3 brings a move from <code>forecast</code> to <code>fable</code>. The main difference is that <code>fable</code> is designed for <code>tsibble</code> objects and <code>forecast</code> is designed for <code>ts</code> objects <a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.</p>
<p>In this section, we will use the <code>tsibble</code> and <code>fable</code> packages along with the <code>fpp3</code> package and cover five main topics: applications with ARIMA models, grid search for ARIMA, time series embedding, forecasting with random forests, and artificial neural network applications, RNN and LSTM. The time-series analysis and forecasting is a very deep and complex subject, which is beyond the scope of this book to cover in detail. FPP3 is free and very accessible even for those without a strong background on time-series forecasting. Therefore, this section assumes that some major concepts, like stationarity, time series decomposition, and exponential smoothing, are already understood by further readings of FPP3.</p>
<div id="arima-models" class="section level2 hasAnchor" number="22.1">
<h2><span class="header-section-number">22.1</span> ARIMA models<a href="time-series.html#arima-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>ARIMA (Autoregressive Integrated Moving Average) is a main statistical model for time series forecasting. It is a linear parametric model that can be used to analyze and forecast data that exhibit temporal dependencies, such as seasonality and autocorrelation. The model is comprised of three components:</p>
<ul>
<li>Autoregressive (AR) component, which models the dependencies between the current value and the past values in the data.</li>
<li>Integrated (I) component, which refers to the degree of differencing that is applied to the time series data. The degree of differencing is the number of times that the data is differenced in order to make it stationary. The stationarity means that the mean, variance, and covariance are constant over time.</li>
<li>Moving average (MA) component, which models the dependencies between the current and the past forecast errors. The MA component of an ARIMA model is used to capture the short-term fluctuations in data that are not captured by the AR component. For example, if the time series data exhibits random noise or sudden spikes, the MA component can help to smooth out these fluctuations and improve the forecast accuracy.</li>
</ul>
<p>The ARIMA model can be written as ARIMA(p,d,q), where p is the order of the autoregressive component, d is the degree of differencing, and q is the order of the moving average component. The values of p, d, and q are chosen based on the characteristics of the time series data to achieve maximum forecasting accuracy. To use the ARIMA model, the time series data must first be preprocessed to remove any trend and seasonality, and to ensure that the data is stationary. The model is then fit to the preprocessed data, and forecasts are generated based on the fitted model.</p>
<p>The mathematical foundation of the ARIMA model is based on the concept of autoregressive (AR) and moving average (MA) processes. An autoregressive process is a type of stochastic process in which the current value of a time series depends on a linear combination of past values of the series. An autoregressive process can be represented mathematically as:</p>
<p><span class="math display">\[
X_{t} = c + \sum_{i=1}^{p}(\phi_{i}  X_{t-i}) + \epsilon_{t},
\]</span></p>
<p>where <span class="math inline">\(X_{t}\)</span> is the value of the time series at time <span class="math inline">\(t\)</span>, <span class="math inline">\(c\)</span> is a constant, <span class="math inline">\(\phi_{i}\)</span> is the autoregressive coefficient for lag <span class="math inline">\(i\)</span>, and <span class="math inline">\(\epsilon_{t}\)</span> is white noise (a sequence of random variables with a mean of zero and a constant variance).</p>
<p>A moving average process is a type of stochastic process in which the current value of a time series depends on a linear combination of past errors or residuals (the difference between the actual value and the forecasted value). A moving average process can be represented mathematically as:</p>
<p><span class="math display">\[
X_{t} = c + \sum_{i=1}^{q}(\theta_{i}  \epsilon_{t-i}) + \epsilon_{t},
\]</span></p>
<p>where <span class="math inline">\(\theta_{i}\)</span> is the moving average coefficient for lag <span class="math inline">\(i\)</span>, and <span class="math inline">\(\epsilon_{t}\)</span> is again white noise.</p>
<p>The ARIMA model, which is a combination of autoregressive and moving average processes, can be represented mathematically as:</p>
<p><span class="math display">\[
X_{t} = c + \sum_{i=1}^{p}(\phi_{i}  X_{t-i}) + \sum_{i=1}^{q}(\theta_{i}  \epsilon_{t-i}) + \epsilon_{t}
\]</span></p>
<p>It is possible to write any stationary <span class="math inline">\(\operatorname{AR}(p)\)</span> model as an MA(<span class="math inline">\(\infty\)</span>) model by using repeated substitution. Here is the example for an <span class="math inline">\(\mathrm{AR}(1)\)</span> model without a constant:</p>
<p><span class="math display">\[
X_{t} = \phi_{1} X_{t-1} + \epsilon_{t} ~~~ \text{and} ~~~ X_{t-1} = \phi_{1} X_{t-2} + \epsilon_{t-1}\\
X_{t}=\phi_1\left(\phi_1 X_{t-2}+\epsilon_{t-1}\right)+\epsilon_t\\
=\phi_1^2 X_{t-2}+\phi_1 \epsilon_{t-1}+\epsilon_t\\
=\phi_1^3 X_{t-3}+\phi_1^2 \epsilon_{t-2}+\phi_1 \epsilon_{t-1}+\epsilon_t\\
\vdots
\]</span></p>
<p>With <span class="math inline">\(-1&lt;\phi_1&lt;1\)</span>, the value of <span class="math inline">\(\phi_1^k\)</span> will get smaller as <span class="math inline">\(k\)</span> gets bigger. Therefore, <span class="math inline">\(\mathrm{AR}(1)\)</span> becomes an MA <span class="math inline">\((\infty)\)</span> process:</p>
<p><span class="math display">\[
X_t=\epsilon_t+\phi_1 \epsilon_{t-1}+\phi_1^2 \epsilon_{t-2}+\phi_1^3 \epsilon_{t-3}+\cdots
\]</span> The parameters of the ARIMA model (<span class="math inline">\(c\)</span>, <span class="math inline">\(\phi_{i}\)</span>, <span class="math inline">\(\theta_{i}\)</span>) are estimated using maximum likelihood estimation (MLE), which involves finding the values of the parameters that maximize the likelihood of the observed data given the model. Once the model has been fit to the data, it can be used to make point forecasts (predictions for a specific time point) or interval forecasts (predictions with a range of possible values).</p>
<p>Some common methods for selecting p and q include in the ARIMA(p,d,q):</p>
<ul>
<li>Autocorrelation function (ACF) plot, which shows the correlations between the time series data and lagged versions of itself. A high positive autocorrelation at a lag of p suggests that p may be a good value for p in ARIMA(p,d,q).</li>
<li>Partial autocorrelation function (PACF) plot, which shows the correlations between the time series data and lagged versions of itself, after accounting for the correlations at all lower lags. A high positive autocorrelation at a lag of q suggests the value for q in ARIMA(p,d,q).</li>
<li>There are several statistical measures that can be used to compare the goodness of fit of different ARIMA models, such as Akaike’s Information Criterion (AIC) and the Bayesian Information Criterion (BIC). These measures can be used to select the model with the lowest value, which is generally considered to be the best model.</li>
</ul>
<p>It is important to note that determining the values of p and q is an iterative process, and we may need to try different values and evaluate the results in order to find the best fit for our data.</p>
</div>
<div id="hyndman-khandakar-algorithm" class="section level2 hasAnchor" number="22.2">
<h2><span class="header-section-number">22.2</span> Hyndman-Khandakar algorithm<a href="time-series.html#hyndman-khandakar-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The Hyndman-Khandakar algorithm (<a href="https://www.jstatsoft.org/article/view/v027i03">Hyndman &amp; Khandakar</a>, 2008) combines several steps for modeling (and estimation) of the ARIMA model: unit root tests, minimization of the AICc, and MLE to obtain an ARIMA model. The arguments to <code>ARIMA()</code> in the <code>fable</code> package provide for many variations for modeling ARIMA. The modeling procedure to a set of (non-seasonal) time series data for ARIMA is defined in FPP3 as follows:</p>
<ol style="list-style-type: decimal">
<li>Plot the data to identify any outliers.</li>
<li>If the data shows variation that increases or decreases with the level of the series, transform the data (Box-Cox transformation) to stabilize the variance.</li>
<li>Check if the data are non-stationary. And, make them stationary, if they are not.</li>
<li>Start with an ARIMA <span class="math inline">\((p, d, 0)\)</span> or ARIMA <span class="math inline">\((0, d, q)\)</span> depending of what ACF/PACF indicates.</li>
<li>Try your chosen model(s), and use the AICc to search for a better model.</li>
</ol>
<p>However, after step 5, the residuals from the chosen model are supposed to be white noise. Otherwise, the model has to be modified. Once the residuals look like white noise, the ARIMA model is ready for forecasting.</p>
<p>We will show all these steps by using the epidemic curve of COVID-19 in Toronto covering 266 days between the March <span class="math inline">\(1^{st}\)</span> and the November <span class="math inline">\(21^{st}\)</span> of 2020. An epidemic curve (or epi curve) is a visual display of the onset of illness among cases associated with an outbreak. The data contain the first wave and the first part of the second wave. It is from <a href="https://data.ontario.ca/en/dataset?groups=2019-novel-coronavirus#byPHU">Ontario Data Catalogue</a> sorted by <code>Episode Date</code>, which is the date when the first symptoms were started. Our data set also contains the mobility data is from Facebook, <code>all_day_bing_tiles_visited_relative_change</code>, which reflects positive or negative changes in movement relative to baseline.</p>
</div>
<div id="ts-plots" class="section level2 hasAnchor" number="22.3">
<h2><span class="header-section-number">22.3</span> TS Plots<a href="time-series.html#ts-plots" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s first load the data and convert it to <code>tsibble</code>.</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="time-series.html#cb649-1" tabindex="-1"></a><span class="fu">library</span>(tsibble)</span>
<span id="cb649-2"><a href="time-series.html#cb649-2" tabindex="-1"></a><span class="fu">library</span>(fpp3)</span>
<span id="cb649-3"><a href="time-series.html#cb649-3" tabindex="-1"></a></span>
<span id="cb649-4"><a href="time-series.html#cb649-4" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;dftoronto.RData&quot;</span>)</span>
<span id="cb649-5"><a href="time-series.html#cb649-5" tabindex="-1"></a>day <span class="ot">&lt;-</span> <span class="fu">seq.Date</span>(</span>
<span id="cb649-6"><a href="time-series.html#cb649-6" tabindex="-1"></a>  <span class="at">from =</span> <span class="fu">as.Date</span>(<span class="st">&quot;2020/03/01&quot;</span>),</span>
<span id="cb649-7"><a href="time-series.html#cb649-7" tabindex="-1"></a>  <span class="at">to =</span> <span class="fu">as.Date</span>(<span class="st">&quot;2020/11/21&quot;</span>),</span>
<span id="cb649-8"><a href="time-series.html#cb649-8" tabindex="-1"></a>  <span class="at">by =</span> <span class="dv">1</span></span>
<span id="cb649-9"><a href="time-series.html#cb649-9" tabindex="-1"></a>)</span>
<span id="cb649-10"><a href="time-series.html#cb649-10" tabindex="-1"></a></span>
<span id="cb649-11"><a href="time-series.html#cb649-11" tabindex="-1"></a>tdata <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Day =</span> day,</span>
<span id="cb649-12"><a href="time-series.html#cb649-12" tabindex="-1"></a>                <span class="at">mob =</span> data<span class="sc">$</span>mob,</span>
<span id="cb649-13"><a href="time-series.html#cb649-13" tabindex="-1"></a>                <span class="at">cases =</span> data<span class="sc">$</span>cases)</span>
<span id="cb649-14"><a href="time-series.html#cb649-14" tabindex="-1"></a></span>
<span id="cb649-15"><a href="time-series.html#cb649-15" tabindex="-1"></a>toronto <span class="ot">&lt;-</span> tdata <span class="sc">%&gt;%</span></span>
<span id="cb649-16"><a href="time-series.html#cb649-16" tabindex="-1"></a>  <span class="fu">as_tsibble</span>(<span class="at">index =</span> Day)</span>
<span id="cb649-17"><a href="time-series.html#cb649-17" tabindex="-1"></a></span>
<span id="cb649-18"><a href="time-series.html#cb649-18" tabindex="-1"></a>toronto</span></code></pre></div>
<pre><code>## # A tsibble: 266 x 3 [1D]
##    Day             mob cases
##    &lt;date&gt;        &lt;dbl&gt; &lt;dbl&gt;
##  1 2020-03-01 -0.0172      4
##  2 2020-03-02 -0.0320      6
##  3 2020-03-03 -0.0119     10
##  4 2020-03-04  0.0186      7
##  5 2020-03-05  0.0223      7
##  6 2020-03-06 -0.00626    10
##  7 2020-03-07  0.0261      8
##  8 2020-03-08  0.0273     10
##  9 2020-03-09 -0.0158     18
## 10 2020-03-10 -0.0521     29
## # ℹ 256 more rows</code></pre>
<p>Note the <code>[1D]</code> in the header indicating daily data. Dealing with daily and sub-daily data with <code>ts</code> class is not an easy process. The <code>tsibble</code> class handles such data with no problem. More details on <code>tsibbles</code> can be found at <a href="https://robjhyndman.com/hyndsight/tsibbles/">Tidy time series data using tsibbles</a>.</p>
<p>Although there are better plotting option cosmetically, we will stick to what <code>fpp3</code> simply offers:</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="time-series.html#cb651-1" tabindex="-1"></a>a <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>(mob, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb651-2"><a href="time-series.html#cb651-2" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb651-3"><a href="time-series.html#cb651-3" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Mobility Index&quot;</span>,</span>
<span id="cb651-4"><a href="time-series.html#cb651-4" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Toronto 2020&quot;</span>,</span>
<span id="cb651-5"><a href="time-series.html#cb651-5" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Days&quot;</span>,</span>
<span id="cb651-6"><a href="time-series.html#cb651-6" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Index&quot;</span></span>
<span id="cb651-7"><a href="time-series.html#cb651-7" tabindex="-1"></a>  )</span>
<span id="cb651-8"><a href="time-series.html#cb651-8" tabindex="-1"></a>b <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>(cases, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb651-9"><a href="time-series.html#cb651-9" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb651-10"><a href="time-series.html#cb651-10" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Covid-19 Cases&quot;</span>,</span>
<span id="cb651-11"><a href="time-series.html#cb651-11" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Toronto 2020&quot;</span>,</span>
<span id="cb651-12"><a href="time-series.html#cb651-12" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Days&quot;</span>,</span>
<span id="cb651-13"><a href="time-series.html#cb651-13" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Cases&quot;</span></span>
<span id="cb651-14"><a href="time-series.html#cb651-14" tabindex="-1"></a>  )</span>
<span id="cb651-15"><a href="time-series.html#cb651-15" tabindex="-1"></a></span>
<span id="cb651-16"><a href="time-series.html#cb651-16" tabindex="-1"></a><span class="fu">require</span>(gridExtra)</span>
<span id="cb651-17"><a href="time-series.html#cb651-17" tabindex="-1"></a><span class="fu">grid.arrange</span>(b, a, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar2-1.png" width="672" /></p>
</div>
<div id="box-cox-transformation" class="section level2 hasAnchor" number="22.4">
<h2><span class="header-section-number">22.4</span> Box-Cox transformation<a href="time-series.html#box-cox-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We would like to make the size of the variation about the same across the whole series. A proper variance-stabilizing transformation makes the forecasting model simpler and better. For example, Proietti and Lutkepohl (2012) find that the Box–Cox transformation produces forecasts which are significantly better than the untransformed data at the one-step-ahead horizon (See <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169207012000830">Does the Box–Cox transformation help in forecasting macroeconomic time series?</a>).</p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="time-series.html#cb652-1" tabindex="-1"></a>lmbd <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span></span>
<span id="cb652-2"><a href="time-series.html#cb652-2" tabindex="-1"></a>  <span class="fu">features</span>(cases, <span class="at">features =</span> guerrero) <span class="sc">%&gt;%</span></span>
<span id="cb652-3"><a href="time-series.html#cb652-3" tabindex="-1"></a>  <span class="fu">pull</span>(lambda_guerrero)</span>
<span id="cb652-4"><a href="time-series.html#cb652-4" tabindex="-1"></a></span>
<span id="cb652-5"><a href="time-series.html#cb652-5" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb652-6"><a href="time-series.html#cb652-6" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="fu">box_cox</span>(cases, <span class="at">lambda =</span> lmbd), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb652-7"><a href="time-series.html#cb652-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb652-8"><a href="time-series.html#cb652-8" tabindex="-1"></a>       <span class="at">title =</span> latex2exp<span class="sc">::</span><span class="fu">TeX</span>(<span class="fu">paste0</span>(</span>
<span id="cb652-9"><a href="time-series.html#cb652-9" tabindex="-1"></a>         <span class="st">&quot;Cases - Transformed with $</span><span class="sc">\\</span><span class="st">lambda$ = &quot;</span>,</span>
<span id="cb652-10"><a href="time-series.html#cb652-10" tabindex="-1"></a>         <span class="fu">round</span>(lmbd, <span class="dv">2</span>)</span>
<span id="cb652-11"><a href="time-series.html#cb652-11" tabindex="-1"></a>       )))</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar3-1.png" width="672" /></p>
<p>The option <code>guerrero</code> computes the optimal <span class="math inline">\(\lambda\)</span> value for a Box-Cox transformation using the <a href="https://onlinelibrary.wiley.com/doi/10.1002/for.3980120104">Guerrero</a> method.</p>
<p>Note that, since the number of tests performed in a given day changes the numbers of cases, we should use “positivity rates”, which is the percentage of positive results in all COVID-19 tests given any day, instead of case numbers. We ignore this problem for now.</p>
</div>
<div id="stationarity" class="section level2 hasAnchor" number="22.5">
<h2><span class="header-section-number">22.5</span> Stationarity<a href="time-series.html#stationarity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A time series is called stationary if a shift in time does not cause a change in the shape of the distribution: the mean, variance, and covariance. Stationarity is an important assumption in many time series forecasting methods, because non-stationary data have statistical properties that change over time making the current patterns and trends ungeneralizable for the future.</p>
<p>There are several tests that can be used to determine whether a time series is stationary or not, including the Dickey-Fuller and KPSS (Kwiatkowski-Phillips-Schmidt-Shin) tests. If a time series is found to be non-stationary, it may be necessary to transform the data in some way before applying a forecasting method in order to obtain reliable forecasts. The main method is differencing, which involves taking the difference between consecutive values in the series.</p>
<p>Let’s first formally test all these series and see what we get:</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="time-series.html#cb653-1" tabindex="-1"></a><span class="co"># number of first differences</span></span>
<span id="cb653-2"><a href="time-series.html#cb653-2" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb653-3"><a href="time-series.html#cb653-3" tabindex="-1"></a>  <span class="fu">features</span>(cases, unitroot_ndiffs)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 0</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="time-series.html#cb655-1" tabindex="-1"></a><span class="co"># Formal KPSS test on level</span></span>
<span id="cb655-2"><a href="time-series.html#cb655-2" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb655-3"><a href="time-series.html#cb655-3" tabindex="-1"></a>  <span class="fu">features</span>(cases, unitroot_kpss)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 0</code></pre>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="time-series.html#cb657-1" tabindex="-1"></a><span class="co"># Formal KPSS test on the first difference</span></span>
<span id="cb657-2"><a href="time-series.html#cb657-2" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb657-3"><a href="time-series.html#cb657-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diffcases =</span> <span class="fu">difference</span>(cases)) <span class="sc">%&gt;%</span></span>
<span id="cb657-4"><a href="time-series.html#cb657-4" tabindex="-1"></a>  <span class="fu">features</span>(diffcases, unitroot_kpss)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 0</code></pre>
<p>It seems that the first difference can make the <code>cases</code> series stationary. The null in this test suggests that the series are stationary, and the p-value indicates that the null is rejected. So, it seems that the test after first differencing gives us a green light! However, ACF’s are telling us that seasonal differencing would be needed:</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="time-series.html#cb659-1" tabindex="-1"></a>level <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">ACF</span>(cases) <span class="sc">%&gt;%</span></span>
<span id="cb659-2"><a href="time-series.html#cb659-2" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Covid-19 Cases&quot;</span>)</span>
<span id="cb659-3"><a href="time-series.html#cb659-3" tabindex="-1"></a></span>
<span id="cb659-4"><a href="time-series.html#cb659-4" tabindex="-1"></a>fdiff <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">ACF</span>(<span class="fu">difference</span>(cases)) <span class="sc">%&gt;%</span></span>
<span id="cb659-5"><a href="time-series.html#cb659-5" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;First-difference&quot;</span>)</span>
<span id="cb659-6"><a href="time-series.html#cb659-6" tabindex="-1"></a></span>
<span id="cb659-7"><a href="time-series.html#cb659-7" tabindex="-1"></a>diffbc <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">ACF</span>(<span class="fu">difference</span>(<span class="fu">box_cox</span>(cases, lmbd))) <span class="sc">%&gt;%</span></span>
<span id="cb659-8"><a href="time-series.html#cb659-8" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;First-difference Box-Cox&quot;</span>)</span>
<span id="cb659-9"><a href="time-series.html#cb659-9" tabindex="-1"></a></span>
<span id="cb659-10"><a href="time-series.html#cb659-10" tabindex="-1"></a>ddiff <span class="ot">&lt;-</span></span>
<span id="cb659-11"><a href="time-series.html#cb659-11" tabindex="-1"></a>  toronto <span class="sc">%&gt;%</span> <span class="fu">ACF</span>(<span class="fu">difference</span>(<span class="fu">difference</span>(<span class="fu">box_cox</span>(cases, lmbd)))) <span class="sc">%&gt;%</span></span>
<span id="cb659-12"><a href="time-series.html#cb659-12" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Double-difference Box-Cox&quot;</span>)</span>
<span id="cb659-13"><a href="time-series.html#cb659-13" tabindex="-1"></a></span>
<span id="cb659-14"><a href="time-series.html#cb659-14" tabindex="-1"></a><span class="fu">require</span>(gridExtra)</span>
<span id="cb659-15"><a href="time-series.html#cb659-15" tabindex="-1"></a><span class="fu">grid.arrange</span>(level, fdiff, diffbc, ddiff, <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar5-1.png" width="672" /></p>
<p>From ACF’s, there seems to be a weekly seasonal pattern at 7, 14, and 21, which are Sundays. We know that reported Covid-19 cases on Sundays tend to be lower than the rest of the week at least during the first wave.</p>
<p>We can also test if we need seasonal differencing:</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="time-series.html#cb660-1" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb660-2"><a href="time-series.html#cb660-2" tabindex="-1"></a>  <span class="fu">features</span>(cases, unitroot_nsdiffs)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   nsdiffs
##     &lt;int&gt;
## 1       0</code></pre>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="time-series.html#cb662-1" tabindex="-1"></a><span class="co"># with Box-Cox</span></span>
<span id="cb662-2"><a href="time-series.html#cb662-2" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb662-3"><a href="time-series.html#cb662-3" tabindex="-1"></a>  <span class="fu">features</span>(<span class="fu">box_cox</span>(cases, lmbd), unitroot_nsdiffs)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   nsdiffs
##     &lt;int&gt;
## 1       0</code></pre>
<p>The feature <code>unitroot_nsdiffs</code> returns 0 for both original and transformed series indicating no seasonal difference is required. We will stick to this “advice” because of two reasons. First, an unnecessary differencing would create more problems than a solution. Second, we can also modify ARIMA to incorporate seasonalllty in the data, which we will see shortly.</p>
<p>Yet, out of curiosity, let’s remove the “seemingly” weekly seasonality and see what happens to ACF’s. Since, the order of differencing is not important, we first applied the seasonal differencing then applied the first difference:</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="time-series.html#cb664-1" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb664-2"><a href="time-series.html#cb664-2" tabindex="-1"></a>  <span class="fu">gg_tsdisplay</span>(<span class="fu">difference</span>(<span class="fu">box_cox</span>(cases, lmbd), <span class="dv">7</span>) <span class="sc">%&gt;%</span> <span class="fu">difference</span>(),</span>
<span id="cb664-3"><a href="time-series.html#cb664-3" tabindex="-1"></a>               <span class="at">plot_type =</span> <span class="st">&#39;partial&#39;</span>,</span>
<span id="cb664-4"><a href="time-series.html#cb664-4" tabindex="-1"></a>               <span class="at">lag =</span> <span class="dv">36</span>) <span class="sc">+</span></span>
<span id="cb664-5"><a href="time-series.html#cb664-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Seasonal &amp; first differenced&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar7-1.png" width="672" /></p>
<p>We can calculate the strength of the trend (T) and seasonality (S) in the time series, <span class="math inline">\(y_t=T_t+S_t+R_t\)</span>, by</p>
<p><span class="math display">\[
F_{Trend}=\max \left(0,1-\frac{\operatorname{Var}\left(R_t\right)}{\operatorname{Var}\left(T_t+R_t\right)}\right),\\
F_{Seasonality}=\max \left(0,1-\frac{\operatorname{Var}\left(R_t\right)}{\operatorname{Var}\left(S_t+R_t\right)}\right),
\]</span></p>
<p>where <span class="math inline">\(R_t\)</span> is the remainder component:</p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="time-series.html#cb665-1" tabindex="-1"></a>t <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> <span class="fu">features</span>(cases, feat_stl)</span>
<span id="cb665-2"><a href="time-series.html#cb665-2" tabindex="-1"></a><span class="fu">t</span>(t[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span></code></pre></div>
<pre><code>##                             [,1]
## trend_strength         0.9843102
## seasonal_strength_week 0.5142436</code></pre>
<p>Relative to <span class="math inline">\(F_{Trend}\)</span>, the seasonality is not robust in the data. So, our decision is to go with a simple first-differencing with Box-Cox transformation. However, we will look at the final predictive performance if the transformation provides any benefit.</p>
</div>
<div id="modeling-arima" class="section level2 hasAnchor" number="22.6">
<h2><span class="header-section-number">22.6</span> Modeling ARIMA<a href="time-series.html#modeling-arima" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In his post, <a href="https://robjhyndman.com/hyndsight/forecasting-covid19/#how-can-we-forecast-covid-19">Forecasting COVID-19</a>, Rob J Hyndman makes the following comment in March 2020:</p>
<blockquote>
<p>(…) the COVID-19 pandemic, it is easy to see why forecasting its effect is difficult. While we have a good understanding of how it works in terms of person-to-person infections, we have limited and misleading data. The current numbers of confirmed cases are known to be vastly underestimated due to the limited testing available. There are almost certainly many more cases of COVID-19 that have not been diagnosed than those that have. Also, the level of under-estimation varies enormously between countries. In a country like South Korea with a lot of testing, the numbers of confirmed cases are going to be closer to the numbers of actual cases than in the US where there has been much less testing. So we simply cannot easily model the spread of the pandemic using the data that is available.</p>
</blockquote>
<blockquote>
<p>The second problem is that the forecasts of COVID-19 can affect the thing we are trying to forecast because governments are reacting, some better than others. A simple model using the available data will be misleading unless it can incorporate the various steps being taken to slow transmission.</p>
</blockquote>
<blockquote>
<p>In summary, fitting simple models to the available data is pointless, misleading and dangerous.</p>
</blockquote>
<p>With our selection of the data, we do not intent to create another debate on forecasting COVID-19. There are hundreds of different forecasting models currently operational in a hub, <a href="https://covid19forecasthub.org">The COVID-19 Forecast Hub</a>, that can be used live. We will start with an automated algorithm <code>ARIMA()</code> that will allow a seasonal parameters:</p>
<p><span class="math display">\[
\text { ARIMA }(p, d, q) \times(P, D, Q) S
\]</span></p>
<p>The first term is the non-seasonal part of ARIMA with <span class="math inline">\(p=\)</span> AR order, <span class="math inline">\(d=\)</span> non-seasonal differencing, <span class="math inline">\(q=\)</span> MA order. The secon term is seasonal part of the model with <span class="math inline">\(P=\)</span> seasonal AR order, <span class="math inline">\(D=\)</span> seasonal differencing, <span class="math inline">\(Q\)</span> = seasonal MA order, and <span class="math inline">\(S=\)</span> seasonal pattern, which defines the number of time periods until the pattern repeats again.</p>
<p>In our case, low values tend always to occur in some particular days, Sundays. Therefore, we may think that <span class="math inline">\(\mathrm{S}=7\)</span> is the span of the periodic seasonal behavior in our data. We can think of a seasonal first order autoregressive model, AR(1), would use <span class="math inline">\(X_{t-7}\)</span> to predict <span class="math inline">\(X_t\)</span>. Likewise, a seasonal second order autoregressive model would use <span class="math inline">\(X_{t-7}\)</span> and <span class="math inline">\(X_{t-14}\)</span> to predict <span class="math inline">\(X_t\)</span>. A seasonal first order MA(1) model would use <span class="math inline">\(\epsilon_{t-7}\)</span> as a predictor. A seasonal second order MA(2) model would use <span class="math inline">\(\epsilon_{t-7}\)</span> and <span class="math inline">\(\epsilon_{t-14}\)</span>.</p>
<p>Let’s use our data first-differenced and transformed:</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="time-series.html#cb667-1" tabindex="-1"></a>toronto <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span> </span>
<span id="cb667-2"><a href="time-series.html#cb667-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">boxcases =</span> <span class="fu">box_cox</span>(cases, <span class="at">lambda =</span> lmbd))</span>
<span id="cb667-3"><a href="time-series.html#cb667-3" tabindex="-1"></a></span>
<span id="cb667-4"><a href="time-series.html#cb667-4" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb667-5"><a href="time-series.html#cb667-5" tabindex="-1"></a>  <span class="fu">gg_tsdisplay</span>(<span class="fu">difference</span>(boxcases), <span class="at">plot_type=</span><span class="st">&#39;partial&#39;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar9-1.png" width="672" /></p>
<p>We look at the spikes and decays in ACF and PACF: a exponential decay in ACF is observed at seasonal spikes of 7, 14, and 21 as well as two spikes at 7 and 14 in PACF indicate seasonal AR(2). We will also add non-seasonal AR(2) due to 2 spikes in PACF at days 1 and 2. Here are our initial models:</p>
<p><span class="math display">\[
\operatorname{ARIMA}(2,1,0)(2,1,0)_{7}\\
\operatorname{ARIMA}(0,1,2)(0,1,3)_{7}
\]</span></p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="time-series.html#cb668-1" tabindex="-1"></a>covfit <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span></span>
<span id="cb668-2"><a href="time-series.html#cb668-2" tabindex="-1"></a>  <span class="fu">model</span>(</span>
<span id="cb668-3"><a href="time-series.html#cb668-3" tabindex="-1"></a>    <span class="at">AR2 =</span> <span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="fu">pdq</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="sc">+</span> <span class="fu">PDQ</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>)),</span>
<span id="cb668-4"><a href="time-series.html#cb668-4" tabindex="-1"></a>    <span class="at">MA3 =</span> <span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="fu">pdq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">PDQ</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>)),</span>
<span id="cb668-5"><a href="time-series.html#cb668-5" tabindex="-1"></a>    <span class="at">auto =</span> <span class="fu">ARIMA</span>(boxcases, <span class="at">stepwise =</span> <span class="cn">FALSE</span>, <span class="at">approx =</span> <span class="cn">FALSE</span>)</span>
<span id="cb668-6"><a href="time-series.html#cb668-6" tabindex="-1"></a>  )</span>
<span id="cb668-7"><a href="time-series.html#cb668-7" tabindex="-1"></a></span>
<span id="cb668-8"><a href="time-series.html#cb668-8" tabindex="-1"></a><span class="fu">t</span>(<span class="fu">cbind</span>(</span>
<span id="cb668-9"><a href="time-series.html#cb668-9" tabindex="-1"></a>  <span class="st">&quot;AR2&quot;</span> <span class="ot">=</span> covfit<span class="sc">$</span>AR2,</span>
<span id="cb668-10"><a href="time-series.html#cb668-10" tabindex="-1"></a>  <span class="st">&quot;MA3&quot;</span> <span class="ot">=</span> covfit<span class="sc">$</span>MA3,</span>
<span id="cb668-11"><a href="time-series.html#cb668-11" tabindex="-1"></a>  <span class="st">&quot;auto&quot;</span> <span class="ot">=</span> covfit<span class="sc">$</span>auto</span>
<span id="cb668-12"><a href="time-series.html#cb668-12" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##      [,1]                  
## AR2  ARIMA(2,1,0)(3,1,0)[7]
## MA3  ARIMA(0,1,2)(0,1,3)[7]
## auto NULL model</code></pre>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="time-series.html#cb670-1" tabindex="-1"></a><span class="fu">glance</span>(covfit) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(AICc) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(.model<span class="sc">:</span>BIC)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 6
##   .model sigma2 log_lik   AIC  AICc   BIC
##   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 MA3     0.468   -277.  567.  567.  588.
## 2 AR2     0.534   -285.  582.  583.  604.</code></pre>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="time-series.html#cb672-1" tabindex="-1"></a>covfit <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(MA3) <span class="sc">%&gt;%</span> <span class="fu">report</span>()</span></code></pre></div>
<pre><code>## Series: boxcases 
## Model: ARIMA(0,1,2)(0,1,3)[7] 
## 
## Coefficients:
##           ma1     ma2     sma1     sma2     sma3
##       -0.4340  0.1330  -0.8617  -0.0573  -0.0809
## s.e.   0.0648  0.0612   0.0827   0.0733   0.0600
## 
## sigma^2 estimated as 0.4684:  log likelihood=-277.29
## AIC=566.58   AICc=566.92   BIC=587.9</code></pre>
<p>The <code>ARIMA()</code> function uses <code>unitroot_nsdiffs()</code> to determine <span class="math inline">\(D\)</span> when it is not specified. Earlier, we run this function that suggested no seasonal differencing.</p>
<p>All other parameters are determined by minimizing the AICc (Akaike’s Information Criterion with a correction for finite sample sizes), which is similar to Akaike’s Information Criterion (AIC), but it includes a correction factor to account for the fact that the sample size may be small relative to the number of parameters in the model. This correction helps to reduce the bias in the AIC estimate and make it more accurate for small sample sizes. When the sample size is large, AIC and AICc are nearly equivalent and either one can be used.</p>
<p>Although AICc values across the models are not comparable (for “auto”, as it has no seasonal differencing), it seems that our manually constructed ARIMA, <span class="math inline">\(\operatorname{ARIMA}(0,1,2)(0,1,3)_{7}\)</span> could also be an option. This brings the possibility of a grid search to our attention.</p>
<p>Before that, however, let’s check their residuals:</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="time-series.html#cb674-1" tabindex="-1"></a><span class="fu">rbind</span>(</span>
<span id="cb674-2"><a href="time-series.html#cb674-2" tabindex="-1"></a>  <span class="fu">augment</span>(covfit) <span class="sc">%&gt;%</span></span>
<span id="cb674-3"><a href="time-series.html#cb674-3" tabindex="-1"></a>    <span class="fu">filter</span>(.model <span class="sc">==</span> <span class="st">&quot;auto&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-4"><a href="time-series.html#cb674-4" tabindex="-1"></a>    <span class="fu">features</span>(.innov, ljung_box, <span class="at">lag =</span> <span class="dv">24</span>, <span class="at">dof =</span> <span class="dv">5</span>),</span>
<span id="cb674-5"><a href="time-series.html#cb674-5" tabindex="-1"></a>  <span class="fu">augment</span>(covfit) <span class="sc">%&gt;%</span></span>
<span id="cb674-6"><a href="time-series.html#cb674-6" tabindex="-1"></a>    <span class="fu">filter</span>(.model <span class="sc">==</span> <span class="st">&quot;MA3&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-7"><a href="time-series.html#cb674-7" tabindex="-1"></a>    <span class="fu">features</span>(.innov, ljung_box, <span class="at">lag =</span> <span class="dv">24</span>, <span class="at">dof =</span> <span class="dv">5</span>),</span>
<span id="cb674-8"><a href="time-series.html#cb674-8" tabindex="-1"></a>  <span class="fu">augment</span>(covfit) <span class="sc">%&gt;%</span></span>
<span id="cb674-9"><a href="time-series.html#cb674-9" tabindex="-1"></a>    <span class="fu">filter</span>(.model <span class="sc">==</span> <span class="st">&quot;AR2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-10"><a href="time-series.html#cb674-10" tabindex="-1"></a>    <span class="fu">features</span>(.innov, ljung_box, <span class="at">lag =</span> <span class="dv">24</span>, <span class="at">dof =</span> <span class="dv">5</span>)</span>
<span id="cb674-11"><a href="time-series.html#cb674-11" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .model lb_stat lb_pvalue
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 auto      NA     NA     
## 2 MA3       27.3    0.0971
## 3 AR2       21.1    0.331</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="time-series.html#cb676-1" tabindex="-1"></a>covfit <span class="sc">%&gt;%</span>dplyr<span class="sc">::</span><span class="fu">select</span>(MA3) <span class="sc">%&gt;%</span> <span class="fu">gg_tsresiduals</span>(<span class="at">lag=</span><span class="dv">36</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar12-1.png" width="672" /></p>
<p>There are several significant spikes in the ACF. But, the model passes the Ljung-Box test at the 5 percent significance level.</p>
<p>Meanwhile, a model without white noise errors can still be used for forecasting, but the prediction intervals may not be accurate due to the correlated residuals. Sometimes, we cannot find a model that passes this test. In practice, we may have to look at the tradeoff between prediction accuracy and reliable confidence intervals. If the difference is too high, we may chose the best model with the highest prediction accuracy.</p>
<p>Before looking at a cross-validation approach for model selection in ARIMA modeling, let use our model to predict a week ahead (2020-11-22 to 2020-11-28):</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="time-series.html#cb677-1" tabindex="-1"></a>fc <span class="ot">&lt;-</span> covfit <span class="sc">%&gt;%</span></span>
<span id="cb677-2"><a href="time-series.html#cb677-2" tabindex="-1"></a>  <span class="fu">forecast</span>(<span class="at">h =</span> <span class="dv">7</span>)</span>
<span id="cb677-3"><a href="time-series.html#cb677-3" tabindex="-1"></a>fc</span></code></pre></div>
<pre><code>## # A fable: 21 x 4 [1D]
## # Key:     .model [3]
##    .model Day           boxcases .mean
##    &lt;chr&gt;  &lt;date&gt;          &lt;dist&gt; &lt;dbl&gt;
##  1 AR2    2020-11-22 N(12, 0.53)  12.1
##  2 AR2    2020-11-23 N(13, 0.68)  13.3
##  3 AR2    2020-11-24 N(13, 0.87)  12.8
##  4 AR2    2020-11-25  N(13, 1.1)  12.8
##  5 AR2    2020-11-26  N(12, 1.3)  12.2
##  6 AR2    2020-11-27  N(12, 1.5)  12.3
##  7 AR2    2020-11-28  N(12, 1.7)  11.5
##  8 MA3    2020-11-22 N(12, 0.48)  12.4
##  9 MA3    2020-11-23 N(13, 0.63)  13.2
## 10 MA3    2020-11-24 N(13, 0.87)  13.1
## # ℹ 11 more rows</code></pre>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="time-series.html#cb679-1" tabindex="-1"></a>fc <span class="sc">%&gt;%</span></span>
<span id="cb679-2"><a href="time-series.html#cb679-2" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto, <span class="at">level =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb679-3"><a href="time-series.html#cb679-3" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Days&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Transformed Cases with Box-Cox&quot;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar14-1.png" width="672" /></p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="time-series.html#cb680-1" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">forecast</span>(covfit, <span class="at">h =</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-2"><a href="time-series.html#cb680-2" tabindex="-1"></a>  <span class="fu">filter</span>(.model <span class="sc">==</span> <span class="st">&#39;auto&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-3"><a href="time-series.html#cb680-3" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto) <span class="sc">+</span></span>
<span id="cb680-4"><a href="time-series.html#cb680-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;COVID-19 Forecasting - Auto&quot;</span>,</span>
<span id="cb680-5"><a href="time-series.html#cb680-5" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Box-Cox Tranformed Cases&quot;</span>)</span>
<span id="cb680-6"><a href="time-series.html#cb680-6" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">forecast</span>(covfit, <span class="at">h =</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-7"><a href="time-series.html#cb680-7" tabindex="-1"></a>  <span class="fu">filter</span>(.model <span class="sc">==</span> <span class="st">&#39;MA3&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-8"><a href="time-series.html#cb680-8" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto) <span class="sc">+</span></span>
<span id="cb680-9"><a href="time-series.html#cb680-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;COVID-19 Forecasting - MA3&quot;</span>,</span>
<span id="cb680-10"><a href="time-series.html#cb680-10" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Box-Cox Transformed Cases&quot;</span>)</span>
<span id="cb680-11"><a href="time-series.html#cb680-11" tabindex="-1"></a></span>
<span id="cb680-12"><a href="time-series.html#cb680-12" tabindex="-1"></a><span class="fu">require</span>(gridExtra)</span>
<span id="cb680-13"><a href="time-series.html#cb680-13" tabindex="-1"></a><span class="fu">grid.arrange</span>(a, b, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar14-2.png" width="672" /></p>
<p>We have predicted values for coming 7 days but we do not have realized values. Hence, we cannot compare these models in terms of their accuracy. We can look at the forecast accuracy of these models by using a training set containing all data up to 2020-11-14. When we forecast the remaining seven days in the data, we can calculate the prediction accuracy.</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb681-1"><a href="time-series.html#cb681-1" tabindex="-1"></a>train <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span></span>
<span id="cb681-2"><a href="time-series.html#cb681-2" tabindex="-1"></a>  <span class="fu">filter_index</span>( <span class="sc">~</span> <span class="st">&quot;2020-11-14&quot;</span>)</span>
<span id="cb681-3"><a href="time-series.html#cb681-3" tabindex="-1"></a></span>
<span id="cb681-4"><a href="time-series.html#cb681-4" tabindex="-1"></a>fit <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span></span>
<span id="cb681-5"><a href="time-series.html#cb681-5" tabindex="-1"></a>  <span class="fu">model</span>(</span>
<span id="cb681-6"><a href="time-series.html#cb681-6" tabindex="-1"></a>    <span class="at">AR2 =</span> <span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="fu">pdq</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="sc">+</span> <span class="fu">PDQ</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>)),</span>
<span id="cb681-7"><a href="time-series.html#cb681-7" tabindex="-1"></a>    <span class="at">MA3 =</span> <span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="fu">pdq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">PDQ</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>)),</span>
<span id="cb681-8"><a href="time-series.html#cb681-8" tabindex="-1"></a>    <span class="at">auto =</span> <span class="fu">ARIMA</span>(boxcases, <span class="at">stepwise =</span> <span class="cn">FALSE</span>, <span class="at">approx =</span> <span class="cn">FALSE</span>)</span>
<span id="cb681-9"><a href="time-series.html#cb681-9" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb681-10"><a href="time-series.html#cb681-10" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mixed =</span> (auto <span class="sc">+</span> AR2 <span class="sc">+</span> MA3) <span class="sc">/</span> <span class="dv">3</span>)</span></code></pre></div>
<p>Although mixing several different ARIMA models does not make sense, we can have an ensemble forecast mixing several different time series models in addition ARIMA modeling. A nice discussion can be found in this <a href="https://stackoverflow.com/questions/70183054/time-series-forecasting-using-fable-in-r-determining-most-optimum-combination-o">post</a> at Stackoverflow.</p>
<p>And, now the accuracy measures:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="time-series.html#cb682-1" tabindex="-1"></a>fc <span class="ot">&lt;-</span> fit <span class="sc">%&gt;%</span> <span class="fu">forecast</span>(<span class="at">h =</span> <span class="dv">7</span>)</span>
<span id="cb682-2"><a href="time-series.html#cb682-2" tabindex="-1"></a>fc <span class="sc">%&gt;%</span></span>
<span id="cb682-3"><a href="time-series.html#cb682-3" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto, <span class="at">level =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar16-1.png" width="672" /></p>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="time-series.html#cb683-1" tabindex="-1"></a><span class="fu">accuracy</span>(fc, toronto)</span></code></pre></div>
<pre><code>## # A tibble: 4 × 10
##   .model .type     ME   RMSE    MAE   MPE  MAPE   MASE  RMSSE   ACF1
##   &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 AR2    Test   -1.57   1.88   1.57 -11.6  11.6   1.35   1.30  0.359
## 2 MA3    Test   -1.61   1.91   1.61 -11.9  11.9   1.38   1.32  0.501
## 3 auto   Test  NaN    NaN    NaN    NaN   NaN   NaN    NaN    NA    
## 4 mixed  Test  NaN    NaN    NaN    NaN   NaN   NaN    NaN    NA</code></pre>
<p>In all measures, the model “auto” (ARIMA with the Hyndman-Khandakar algorithm) is better than others.</p>
<p>Finally, it is always good to check ARIMA (or any time series forecasting) against the base benchmark.</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="time-series.html#cb685-1" tabindex="-1"></a>bfit <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span></span>
<span id="cb685-2"><a href="time-series.html#cb685-2" tabindex="-1"></a>  <span class="fu">model</span>(<span class="at">ave =</span> <span class="fu">MEAN</span>(boxcases),</span>
<span id="cb685-3"><a href="time-series.html#cb685-3" tabindex="-1"></a>        <span class="at">lm =</span> <span class="fu">TSLM</span>(boxcases <span class="sc">~</span> <span class="fu">trend</span>() <span class="sc">+</span> <span class="fu">season</span>()))</span>
<span id="cb685-4"><a href="time-series.html#cb685-4" tabindex="-1"></a></span>
<span id="cb685-5"><a href="time-series.html#cb685-5" tabindex="-1"></a>bfc <span class="ot">&lt;-</span> bfit <span class="sc">%&gt;%</span> <span class="fu">forecast</span>(<span class="at">h =</span> <span class="dv">7</span>)</span>
<span id="cb685-6"><a href="time-series.html#cb685-6" tabindex="-1"></a></span>
<span id="cb685-7"><a href="time-series.html#cb685-7" tabindex="-1"></a>bfc <span class="sc">%&gt;%</span></span>
<span id="cb685-8"><a href="time-series.html#cb685-8" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto, <span class="at">level =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ar17-1.png" width="672" /></p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="time-series.html#cb686-1" tabindex="-1"></a><span class="fu">accuracy</span>(bfc, toronto)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 10
##   .model .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1
##   &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 ave    Test   4.59  4.72  4.59  31.8  31.8  3.94  3.26 0.507
## 2 lm     Test   2.07  2.32  2.07  14.1  14.1  1.77  1.60 0.516</code></pre>
<p>The results shows our ARIMA model is doing much better job relative to a time-series linear model or a simple average.</p>
<p>As we discussed earlier in this book, there are basically two ways to select a best fitting predictive model: <strong>ex-post</strong> and <strong>ex-ante</strong> tools to penalize the overfitting. With AIC (Akaike Information Criterion) and BIC (Bayesian Information Criteria) measures, we can indirectly estimate the test (out-of-sample) error by making an adjustment to the training (in-sample) error to account for the bias due to overfitting. Therefore, these methods are ex-post tools to penalize the overfitting. The Hyndman-Khandakar algorithm uses this ex-post approach by selecting the best predictive ARIMA model with minimum AICc among alternatives.</p>
<p>We can directly estimate the test error (out-sample) and choose the model that minimizes it. Instead of selecting a model with AICc, we can do it by tuning the parameters of ARIMA with a cross-validation approach so that the tuned model achieves the highest predictive accuracy.</p>
</div>
<div id="grid-search-for-arima" class="section level2 hasAnchor" number="22.7">
<h2><span class="header-section-number">22.7</span> Grid search for ARIMA<a href="time-series.html#grid-search-for-arima" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before we apply a cross validation approach to choose the model that has the minimum test error (out-sample), we would like to do a grid search for a seasonal ARIMA with <span class="math inline">\(d=1\)</span>, <span class="math inline">\(D=1\)</span>, and <span class="math inline">\(S=7\)</span>. We will report two outcomes: AICc and RMSE (root mean squared error).</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="time-series.html#cb688-1" tabindex="-1"></a><span class="co">#In-sample grid-search</span></span>
<span id="cb688-2"><a href="time-series.html#cb688-2" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb688-3"><a href="time-series.html#cb688-3" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb688-4"><a href="time-series.html#cb688-4" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb688-5"><a href="time-series.html#cb688-5" tabindex="-1"></a>Q <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">2</span></span>
<span id="cb688-6"><a href="time-series.html#cb688-6" tabindex="-1"></a></span>
<span id="cb688-7"><a href="time-series.html#cb688-7" tabindex="-1"></a>comb <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">expand.grid</span>(p, q, P, Q))</span>
<span id="cb688-8"><a href="time-series.html#cb688-8" tabindex="-1"></a></span>
<span id="cb688-9"><a href="time-series.html#cb688-9" tabindex="-1"></a><span class="co"># We remove the unstable grids</span></span>
<span id="cb688-10"><a href="time-series.html#cb688-10" tabindex="-1"></a>comb <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(comb[<span class="sc">-</span><span class="dv">1</span>,])</span>
<span id="cb688-11"><a href="time-series.html#cb688-11" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">which</span>(comb<span class="sc">$</span>Var1 <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> comb<span class="sc">$</span>Var2 <span class="sc">==</span> <span class="dv">0</span>, <span class="at">arr.ind =</span> <span class="cn">TRUE</span>)</span>
<span id="cb688-12"><a href="time-series.html#cb688-12" tabindex="-1"></a>comb <span class="ot">&lt;-</span> comb[<span class="sc">-</span>ind,]</span>
<span id="cb688-13"><a href="time-series.html#cb688-13" tabindex="-1"></a><span class="fu">row.names</span>(comb) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb688-14"><a href="time-series.html#cb688-14" tabindex="-1"></a><span class="fu">colnames</span>(comb) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;q&quot;</span>, <span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>)</span>
<span id="cb688-15"><a href="time-series.html#cb688-15" tabindex="-1"></a></span>
<span id="cb688-16"><a href="time-series.html#cb688-16" tabindex="-1"></a>aicc <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb688-17"><a href="time-series.html#cb688-17" tabindex="-1"></a>RMSE <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb688-18"><a href="time-series.html#cb688-18" tabindex="-1"></a></span>
<span id="cb688-19"><a href="time-series.html#cb688-19" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(comb)) {</span>
<span id="cb688-20"><a href="time-series.html#cb688-20" tabindex="-1"></a>  <span class="fu">tryCatch</span>({</span>
<span id="cb688-21"><a href="time-series.html#cb688-21" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span></span>
<span id="cb688-22"><a href="time-series.html#cb688-22" tabindex="-1"></a>      <span class="fu">model</span>(<span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> <span class="fu">pdq</span>(comb[k, <span class="dv">1</span>], <span class="dv">1</span>, comb[k, <span class="dv">2</span>])</span>
<span id="cb688-23"><a href="time-series.html#cb688-23" tabindex="-1"></a>                  <span class="sc">+</span> <span class="fu">PDQ</span>(comb[k, <span class="dv">3</span>], <span class="dv">1</span>, comb[k, <span class="dv">4</span>])))</span>
<span id="cb688-24"><a href="time-series.html#cb688-24" tabindex="-1"></a>    wtf <span class="ot">&lt;-</span> fit <span class="sc">%&gt;%</span> glance</span>
<span id="cb688-25"><a href="time-series.html#cb688-25" tabindex="-1"></a>    res <span class="ot">&lt;-</span> fit <span class="sc">%&gt;%</span> <span class="fu">residuals</span>()</span>
<span id="cb688-26"><a href="time-series.html#cb688-26" tabindex="-1"></a>    aicc[k] <span class="ot">&lt;-</span> wtf<span class="sc">$</span>AICc</span>
<span id="cb688-27"><a href="time-series.html#cb688-27" tabindex="-1"></a>    RMSE[k] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((res<span class="sc">$</span>.resid) <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb688-28"><a href="time-series.html#cb688-28" tabindex="-1"></a>  }, <span class="at">error =</span> <span class="cf">function</span>(e) {</span>
<span id="cb688-29"><a href="time-series.html#cb688-29" tabindex="-1"></a>  })</span>
<span id="cb688-30"><a href="time-series.html#cb688-30" tabindex="-1"></a>}</span>
<span id="cb688-31"><a href="time-series.html#cb688-31" tabindex="-1"></a></span>
<span id="cb688-32"><a href="time-series.html#cb688-32" tabindex="-1"></a><span class="fu">cbind</span>(comb[<span class="fu">which.min</span>(aicc), ], <span class="st">&quot;AICc&quot;</span> <span class="ot">=</span> <span class="fu">min</span>(aicc, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##    p q P Q     AICc
## 75 3 3 0 1 558.7746</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="time-series.html#cb690-1" tabindex="-1"></a><span class="fu">cbind</span>(comb[<span class="fu">which.min</span>(RMSE), ], <span class="st">&quot;RMSE&quot;</span> <span class="ot">=</span> <span class="fu">min</span>(RMSE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##     p q P Q      RMSE
## 120 3 3 3 1 0.6478857</code></pre>
<p>Although we set the ARIMA without a constant, we could extend the grid with a constant. We can also add a line (<code>ljung_box</code>) that extracts and reports the Ljung-Box test for each model. We can then select the one that has a minimum AICc and passes the test.</p>
<p>We may not need this grid search as the Hyndman-Khandakar algorithm for automatic ARIMA modelling is able to do it for us very effectively (except for the Ljung-Box test for each model). We should note that the Hyndman-Khandakar algorithm selects the best ARIMA model for forecasting with the minimum AICc. In practice, we can apply a similar grid search with cross validation for selecting the best model that has the minimum out-of-sample prediction error without checking if it passes the Ljung-Box test or not. Here is a simple example:</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="time-series.html#cb692-1" tabindex="-1"></a><span class="co">#In-sample grid-search</span></span>
<span id="cb692-2"><a href="time-series.html#cb692-2" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb692-3"><a href="time-series.html#cb692-3" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb692-4"><a href="time-series.html#cb692-4" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb692-5"><a href="time-series.html#cb692-5" tabindex="-1"></a>Q <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">2</span></span>
<span id="cb692-6"><a href="time-series.html#cb692-6" tabindex="-1"></a></span>
<span id="cb692-7"><a href="time-series.html#cb692-7" tabindex="-1"></a>comb <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">expand.grid</span>(p, q, P, Q))</span>
<span id="cb692-8"><a href="time-series.html#cb692-8" tabindex="-1"></a></span>
<span id="cb692-9"><a href="time-series.html#cb692-9" tabindex="-1"></a><span class="co"># We remove the unstable grids</span></span>
<span id="cb692-10"><a href="time-series.html#cb692-10" tabindex="-1"></a>comb <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(comb[<span class="sc">-</span><span class="dv">1</span>,])</span>
<span id="cb692-11"><a href="time-series.html#cb692-11" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">which</span>(comb<span class="sc">$</span>Var1 <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> comb<span class="sc">$</span>Var2 <span class="sc">==</span> <span class="dv">0</span>, <span class="at">arr.ind =</span> <span class="cn">TRUE</span>)</span>
<span id="cb692-12"><a href="time-series.html#cb692-12" tabindex="-1"></a>comb <span class="ot">&lt;-</span> comb[<span class="sc">-</span>ind, ]</span>
<span id="cb692-13"><a href="time-series.html#cb692-13" tabindex="-1"></a><span class="fu">row.names</span>(comb) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb692-14"><a href="time-series.html#cb692-14" tabindex="-1"></a><span class="fu">colnames</span>(comb) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;q&quot;</span>, <span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>)</span>
<span id="cb692-15"><a href="time-series.html#cb692-15" tabindex="-1"></a></span>
<span id="cb692-16"><a href="time-series.html#cb692-16" tabindex="-1"></a>train <span class="ot">&lt;-</span> toronto <span class="sc">%&gt;%</span></span>
<span id="cb692-17"><a href="time-series.html#cb692-17" tabindex="-1"></a>  <span class="fu">filter_index</span>( <span class="sc">~</span> <span class="st">&quot;2020-11-14&quot;</span>)</span>
<span id="cb692-18"><a href="time-series.html#cb692-18" tabindex="-1"></a></span>
<span id="cb692-19"><a href="time-series.html#cb692-19" tabindex="-1"></a>RMSE <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb692-20"><a href="time-series.html#cb692-20" tabindex="-1"></a></span>
<span id="cb692-21"><a href="time-series.html#cb692-21" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(comb)) {</span>
<span id="cb692-22"><a href="time-series.html#cb692-22" tabindex="-1"></a>  <span class="fu">tryCatch</span>({</span>
<span id="cb692-23"><a href="time-series.html#cb692-23" tabindex="-1"></a>    amk <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span></span>
<span id="cb692-24"><a href="time-series.html#cb692-24" tabindex="-1"></a>      <span class="fu">model</span>(<span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> <span class="fu">pdq</span>(comb[k, <span class="dv">1</span>], <span class="dv">1</span>, comb[k, <span class="dv">2</span>])</span>
<span id="cb692-25"><a href="time-series.html#cb692-25" tabindex="-1"></a>                  <span class="sc">+</span> <span class="fu">PDQ</span>(comb[k, <span class="dv">3</span>], <span class="dv">1</span>, comb[k, <span class="dv">4</span>]))) <span class="sc">%&gt;%</span></span>
<span id="cb692-26"><a href="time-series.html#cb692-26" tabindex="-1"></a>      <span class="fu">forecast</span>(<span class="at">h =</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-27"><a href="time-series.html#cb692-27" tabindex="-1"></a>      <span class="fu">accuracy</span>(toronto)</span>
<span id="cb692-28"><a href="time-series.html#cb692-28" tabindex="-1"></a>    RMSE[k] <span class="ot">&lt;-</span> amk<span class="sc">$</span>RMSE</span>
<span id="cb692-29"><a href="time-series.html#cb692-29" tabindex="-1"></a>  }, <span class="at">error =</span> <span class="cf">function</span>(e) {</span>
<span id="cb692-30"><a href="time-series.html#cb692-30" tabindex="-1"></a>  })</span>
<span id="cb692-31"><a href="time-series.html#cb692-31" tabindex="-1"></a>}</span>
<span id="cb692-32"><a href="time-series.html#cb692-32" tabindex="-1"></a></span>
<span id="cb692-33"><a href="time-series.html#cb692-33" tabindex="-1"></a><span class="fu">cbind</span>(comb[<span class="fu">which.min</span>(RMSE), ], <span class="st">&quot;RMSE&quot;</span> <span class="ot">=</span> <span class="fu">min</span>(RMSE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##    p q P Q      RMSE
## 12 0 3 0 0 0.7937723</code></pre>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="time-series.html#cb694-1" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">which.min</span>(RMSE)</span>
<span id="cb694-2"><a href="time-series.html#cb694-2" tabindex="-1"></a>toronto <span class="sc">%&gt;%</span></span>
<span id="cb694-3"><a href="time-series.html#cb694-3" tabindex="-1"></a>  <span class="fu">model</span>(<span class="fu">ARIMA</span>(boxcases <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> <span class="fu">pdq</span>(comb[g, <span class="dv">1</span>], <span class="dv">1</span>, comb[g, <span class="dv">2</span>])</span>
<span id="cb694-4"><a href="time-series.html#cb694-4" tabindex="-1"></a>              <span class="sc">+</span> <span class="fu">PDQ</span>(comb[g, <span class="dv">3</span>], <span class="dv">1</span>, comb[g, <span class="dv">4</span>]))) <span class="sc">%&gt;%</span></span>
<span id="cb694-5"><a href="time-series.html#cb694-5" tabindex="-1"></a>  <span class="fu">forecast</span>(<span class="at">h =</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span></span>
<span id="cb694-6"><a href="time-series.html#cb694-6" tabindex="-1"></a>  <span class="fu">autoplot</span>(toronto, <span class="at">level =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/ag3-1.png" width="672" /></p>
<p>We will not apply h-step-ahead rolling-window cross-validations for ARIMA, which can be found in the post, <a href="https://robjhyndman.com/hyndsight/tscv-fable/">Time series cross-validation using fable</a>, by Hyndman (2021). However, when we have multiple competing models, we may not want to compare their predictive accuracy by looking at their error rates using only few out-of-sample observations. If we use rolling windows or continuously expanding windows, we can effectively create a large number of days tested within the data.</p>
</div>
<div id="hyperparameter-tuning-with-time-series-data" class="section level2 hasAnchor" number="22.8">
<h2><span class="header-section-number">22.8</span> Hyperparameter tuning with time-series data:<a href="time-series.html#hyperparameter-tuning-with-time-series-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While we have a dedicated section (Section VII) on forecasting with times series data, we will complete this chapter by looking at the fundamental differences between time-series and cross-sectional in terms of grid search.</p>
<p>We will use the <code>EuStockMarkets</code> data set pre-loaded in R. The data contains the daily closing prices of major European stock indices: Germany DAX (Ibis), Switzerland SMI, France CAC, and UK FTSE. The data are sampled in business time, i.e., weekends and holidays are omitted. We will focus on the FTSE. Below, the data and its plot:</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="time-series.html#cb695-1" tabindex="-1"></a><span class="co">#Data</span></span>
<span id="cb695-2"><a href="time-series.html#cb695-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(EuStockMarkets)</span>
<span id="cb695-3"><a href="time-series.html#cb695-3" tabindex="-1"></a>day_index <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(data), <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb695-4"><a href="time-series.html#cb695-4" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data, day_index)</span>
<span id="cb695-5"><a href="time-series.html#cb695-5" tabindex="-1"></a><span class="fu">head</span>(data)</span></code></pre></div>
<pre><code>##       DAX    SMI    CAC   FTSE day_index
## 1 1628.75 1678.1 1772.8 2443.6         1
## 2 1613.63 1688.5 1750.5 2460.2         2
## 3 1606.51 1678.6 1718.0 2448.2         3
## 4 1621.04 1684.1 1708.1 2470.4         4
## 5 1618.16 1686.6 1723.1 2484.7         5
## 6 1610.61 1671.6 1714.3 2466.8         6</code></pre>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="time-series.html#cb697-1" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb697-2"><a href="time-series.html#cb697-2" tabindex="-1"></a>  data<span class="sc">$</span>day_index,</span>
<span id="cb697-3"><a href="time-series.html#cb697-3" tabindex="-1"></a>  data<span class="sc">$</span>FTSE,</span>
<span id="cb697-4"><a href="time-series.html#cb697-4" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>,</span>
<span id="cb697-5"><a href="time-series.html#cb697-5" tabindex="-1"></a>  <span class="at">cex.main =</span> <span class="fl">0.80</span>,</span>
<span id="cb697-6"><a href="time-series.html#cb697-6" tabindex="-1"></a>  <span class="at">cex.axis =</span> <span class="fl">0.75</span>,</span>
<span id="cb697-7"><a href="time-series.html#cb697-7" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span></span>
<span id="cb697-8"><a href="time-series.html#cb697-8" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/hy16-1.png" width="672" /></p>
<p>We can use smoothing methods to detect trends in the presence of noisy data especially in cases where the shape of the trend is unknown. A decomposition would show the components of the data: trend, seasonal fluctuations, and the noise, which is <strong>unpredictable</strong> and remainder of after the trend (and seasonality) is removed Here is an illustration for the FTSE with additive decomposition:</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="time-series.html#cb698-1" tabindex="-1"></a>tsd <span class="ot">&lt;-</span> EuStockMarkets</span>
<span id="cb698-2"><a href="time-series.html#cb698-2" tabindex="-1"></a>dctsd <span class="ot">&lt;-</span> <span class="fu">decompose</span>(tsd[, <span class="dv">4</span>])</span>
<span id="cb698-3"><a href="time-series.html#cb698-3" tabindex="-1"></a><span class="fu">plot</span>(dctsd, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/hy17-1.png" width="672" /></p>
<p>Separating the trend from the noise will enable us to predict the future values better. Having learnt how to model a learning algorithm, we can also train <code>loess()</code> to extract the trend in FTSE. Several smoothing lines are illustrated below to visualize the differences:</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="time-series.html#cb699-1" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb699-2"><a href="time-series.html#cb699-2" tabindex="-1"></a>  data<span class="sc">$</span>day_index,</span>
<span id="cb699-3"><a href="time-series.html#cb699-3" tabindex="-1"></a>  data<span class="sc">$</span>FTSE,</span>
<span id="cb699-4"><a href="time-series.html#cb699-4" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb699-5"><a href="time-series.html#cb699-5" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb699-6"><a href="time-series.html#cb699-6" tabindex="-1"></a>  <span class="at">cex.main =</span> <span class="fl">0.80</span>,</span>
<span id="cb699-7"><a href="time-series.html#cb699-7" tabindex="-1"></a>  <span class="at">cex.axis =</span> <span class="fl">0.75</span>,</span>
<span id="cb699-8"><a href="time-series.html#cb699-8" tabindex="-1"></a>  <span class="at">lwd =</span> <span class="dv">2</span></span>
<span id="cb699-9"><a href="time-series.html#cb699-9" tabindex="-1"></a>)</span>
<span id="cb699-10"><a href="time-series.html#cb699-10" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>day_index,  </span>
<span id="cb699-11"><a href="time-series.html#cb699-11" tabindex="-1"></a>      <span class="fu">predict</span>(<span class="fu">lm</span>(FTSE <span class="sc">~</span> day_index, data)), <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;green&quot;</span>)</span>
<span id="cb699-12"><a href="time-series.html#cb699-12" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>day_index,</span>
<span id="cb699-13"><a href="time-series.html#cb699-13" tabindex="-1"></a>      <span class="fu">predict</span>(<span class="fu">loess</span>(</span>
<span id="cb699-14"><a href="time-series.html#cb699-14" tabindex="-1"></a>        data<span class="sc">$</span>FTSE <span class="sc">~</span> data<span class="sc">$</span>day_index, <span class="at">degree =</span> <span class="dv">1</span>, <span class="at">span =</span> <span class="fl">0.01</span></span>
<span id="cb699-15"><a href="time-series.html#cb699-15" tabindex="-1"></a>      )),</span>
<span id="cb699-16"><a href="time-series.html#cb699-16" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb699-17"><a href="time-series.html#cb699-17" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb699-18"><a href="time-series.html#cb699-18" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>day_index,</span>
<span id="cb699-19"><a href="time-series.html#cb699-19" tabindex="-1"></a>      <span class="fu">predict</span>(<span class="fu">loess</span>(</span>
<span id="cb699-20"><a href="time-series.html#cb699-20" tabindex="-1"></a>        data<span class="sc">$</span>FTSE <span class="sc">~</span> data<span class="sc">$</span>day_index, <span class="at">degree =</span> <span class="dv">1</span>, <span class="at">span =</span> <span class="fl">0.1</span></span>
<span id="cb699-21"><a href="time-series.html#cb699-21" tabindex="-1"></a>      )),</span>
<span id="cb699-22"><a href="time-series.html#cb699-22" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb699-23"><a href="time-series.html#cb699-23" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb699-24"><a href="time-series.html#cb699-24" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>day_index,</span>
<span id="cb699-25"><a href="time-series.html#cb699-25" tabindex="-1"></a>      <span class="fu">predict</span>(<span class="fu">loess</span>(</span>
<span id="cb699-26"><a href="time-series.html#cb699-26" tabindex="-1"></a>        data<span class="sc">$</span>FTSE <span class="sc">~</span> data<span class="sc">$</span>day_index, <span class="at">degree =</span> <span class="dv">1</span>, <span class="at">span =</span> <span class="fl">0.9</span></span>
<span id="cb699-27"><a href="time-series.html#cb699-27" tabindex="-1"></a>      )),</span>
<span id="cb699-28"><a href="time-series.html#cb699-28" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb699-29"><a href="time-series.html#cb699-29" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;yellow&quot;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/hy18-1.png" width="672" /></p>
<p>It seems that a linear trend is not appropriate as it underfits to predict. Although a smoothing method like <code>loess()</code> would be a good choice, but which <code>loess()</code> would be a good fit? One way of validating time series data is to keep the time order in the data when we use k-fold cross validation so that in each fold the training data takes place before the test data.</p>
<p>This type of cross validation is called as <strong>h-step-ahead rolling cross-validation</strong>. (There is also a method called as <strong>sliding-window-cross-validation</strong>). Below we can see an illustration of this kind of cross validation:</p>
<p><img src="png/TScv.png" width="130%" height="130%" /></p>
<p>We are going to split the data without a random shuffle:</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="time-series.html#cb700-1" tabindex="-1"></a>span <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.05</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.05</span>) </span>
<span id="cb700-2"><a href="time-series.html#cb700-2" tabindex="-1"></a><span class="co"># *****h-step-rolling-CV********</span></span>
<span id="cb700-3"><a href="time-series.html#cb700-3" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb700-4"><a href="time-series.html#cb700-4" tabindex="-1"></a>opt <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb700-5"><a href="time-series.html#cb700-5" tabindex="-1"></a><span class="co">#CV loop</span></span>
<span id="cb700-6"><a href="time-series.html#cb700-6" tabindex="-1"></a>nvalid <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">nrow</span>(data) <span class="sc">/</span> h)</span>
<span id="cb700-7"><a href="time-series.html#cb700-7" tabindex="-1"></a><span class="co">#This gives the 10 cutoff points in rows</span></span>
<span id="cb700-8"><a href="time-series.html#cb700-8" tabindex="-1"></a>cut <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>)</span>
<span id="cb700-9"><a href="time-series.html#cb700-9" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>h) {</span>
<span id="cb700-10"><a href="time-series.html#cb700-10" tabindex="-1"></a>  cut <span class="ot">&lt;-</span> <span class="fu">c</span>(cut, nvalid <span class="sc">*</span> j)</span>
<span id="cb700-11"><a href="time-series.html#cb700-11" tabindex="-1"></a>}</span>
<span id="cb700-12"><a href="time-series.html#cb700-12" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>h) {</span>
<span id="cb700-13"><a href="time-series.html#cb700-13" tabindex="-1"></a>  <span class="cf">if</span> (i <span class="sc">&lt;</span> h) {</span>
<span id="cb700-14"><a href="time-series.html#cb700-14" tabindex="-1"></a>    train <span class="ot">&lt;-</span> data[(cut[<span class="dv">1</span>]<span class="sc">:</span>cut[i <span class="sc">+</span> <span class="dv">1</span>]),]</span>
<span id="cb700-15"><a href="time-series.html#cb700-15" tabindex="-1"></a>  } <span class="cf">else</span>{</span>
<span id="cb700-16"><a href="time-series.html#cb700-16" tabindex="-1"></a>    train <span class="ot">&lt;-</span> data[cut[<span class="dv">1</span>]<span class="sc">:</span>cut[i],]</span>
<span id="cb700-17"><a href="time-series.html#cb700-17" tabindex="-1"></a>  }</span>
<span id="cb700-18"><a href="time-series.html#cb700-18" tabindex="-1"></a>  <span class="cf">if</span> (i <span class="sc">+</span> <span class="dv">2</span> <span class="sc">&lt;</span> h)</span>
<span id="cb700-19"><a href="time-series.html#cb700-19" tabindex="-1"></a>    valid <span class="ot">&lt;-</span> data[(cut[i <span class="sc">+</span> <span class="dv">1</span>]<span class="sc">:</span>cut[i <span class="sc">+</span> <span class="dv">2</span>]),]</span>
<span id="cb700-20"><a href="time-series.html#cb700-20" tabindex="-1"></a>  </span>
<span id="cb700-21"><a href="time-series.html#cb700-21" tabindex="-1"></a>  RMSPE <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>), <span class="fu">length</span>(span)) <span class="co">#Matrix to store RMSPE</span></span>
<span id="cb700-22"><a href="time-series.html#cb700-22" tabindex="-1"></a>  </span>
<span id="cb700-23"><a href="time-series.html#cb700-23" tabindex="-1"></a>  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(span)) {</span>
<span id="cb700-24"><a href="time-series.html#cb700-24" tabindex="-1"></a>    model <span class="ot">&lt;-</span></span>
<span id="cb700-25"><a href="time-series.html#cb700-25" tabindex="-1"></a>      <span class="fu">loess</span>(</span>
<span id="cb700-26"><a href="time-series.html#cb700-26" tabindex="-1"></a>        FTSE <span class="sc">~</span> day_index,</span>
<span id="cb700-27"><a href="time-series.html#cb700-27" tabindex="-1"></a>        <span class="at">control =</span> <span class="fu">loess.control</span>(<span class="at">surface =</span> <span class="st">&quot;direct&quot;</span>),</span>
<span id="cb700-28"><a href="time-series.html#cb700-28" tabindex="-1"></a>        <span class="at">degree =</span> <span class="dv">2</span>,</span>
<span id="cb700-29"><a href="time-series.html#cb700-29" tabindex="-1"></a>        <span class="at">span =</span> span[s],</span>
<span id="cb700-30"><a href="time-series.html#cb700-30" tabindex="-1"></a>        <span class="at">data =</span> train</span>
<span id="cb700-31"><a href="time-series.html#cb700-31" tabindex="-1"></a>      )</span>
<span id="cb700-32"><a href="time-series.html#cb700-32" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, valid<span class="sc">$</span>day_index)</span>
<span id="cb700-33"><a href="time-series.html#cb700-33" tabindex="-1"></a>    RMSPE[s] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((valid<span class="sc">$</span>FTSE <span class="sc">-</span> fit) <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb700-34"><a href="time-series.html#cb700-34" tabindex="-1"></a>  }</span>
<span id="cb700-35"><a href="time-series.html#cb700-35" tabindex="-1"></a>  opt[i] <span class="ot">&lt;-</span> <span class="fu">which</span>(RMSPE <span class="sc">==</span> <span class="fu">min</span>(RMSPE), <span class="at">arr.ind =</span> <span class="cn">TRUE</span>)</span>
<span id="cb700-36"><a href="time-series.html#cb700-36" tabindex="-1"></a>}</span>
<span id="cb700-37"><a href="time-series.html#cb700-37" tabindex="-1"></a><span class="co">#Hyperparameters</span></span>
<span id="cb700-38"><a href="time-series.html#cb700-38" tabindex="-1"></a>opt_span <span class="ot">&lt;-</span> <span class="fu">mean</span>(span[opt])</span>
<span id="cb700-39"><a href="time-series.html#cb700-39" tabindex="-1"></a>opt_span</span></code></pre></div>
<pre><code>## [1] 0.43</code></pre>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="time-series.html#cb702-1" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb702-2"><a href="time-series.html#cb702-2" tabindex="-1"></a>  data<span class="sc">$</span>day_index,</span>
<span id="cb702-3"><a href="time-series.html#cb702-3" tabindex="-1"></a>  data<span class="sc">$</span>FTSE,</span>
<span id="cb702-4"><a href="time-series.html#cb702-4" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb702-5"><a href="time-series.html#cb702-5" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>,</span>
<span id="cb702-6"><a href="time-series.html#cb702-6" tabindex="-1"></a>  <span class="at">cex.main =</span> <span class="fl">0.80</span>,</span>
<span id="cb702-7"><a href="time-series.html#cb702-7" tabindex="-1"></a>  <span class="at">cex.axis =</span> <span class="fl">0.75</span></span>
<span id="cb702-8"><a href="time-series.html#cb702-8" tabindex="-1"></a>)</span>
<span id="cb702-9"><a href="time-series.html#cb702-9" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>day_index,</span>
<span id="cb702-10"><a href="time-series.html#cb702-10" tabindex="-1"></a>      <span class="fu">predict</span>(<span class="fu">loess</span>(</span>
<span id="cb702-11"><a href="time-series.html#cb702-11" tabindex="-1"></a>        data<span class="sc">$</span>FTSE <span class="sc">~</span> data<span class="sc">$</span>day_index,</span>
<span id="cb702-12"><a href="time-series.html#cb702-12" tabindex="-1"></a>        <span class="at">degree =</span> <span class="dv">2</span>, <span class="at">span =</span> opt_span</span>
<span id="cb702-13"><a href="time-series.html#cb702-13" tabindex="-1"></a>      )),</span>
<span id="cb702-14"><a href="time-series.html#cb702-14" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb702-15"><a href="time-series.html#cb702-15" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="22-TimeSeries_files/figure-html/hy20-1.png" width="672" /></p>
<p>Note that we did not start this algorithm with the initial split for testing. For the full train-validate-test routine the initial split has to be added into this cross-validation script.</p>
<p>Moreover, we started the validation after the first 10% split. We can also decide on this starting point. For example, we can change the code and decide to train the model after 30% training set. That flexibility is specially important if we apply <strong>Day Forward-Chaining Nested Cross-Validation</strong>, which is the same method but <em>rolling windows</em> are the days. The following figure helps demonstrate this method:</p>
<p><img src="png/grid4.png" width="130%" height="130%" /></p>
<p>Although it is designed for a day-chained cross validation, we can replace <em>days</em> with weeks, months or 21-day windows. In fact, our algorithm that uses 10% splits can be considered a <strong>10% Split Forward-Chaining Nested Cross-Validation</strong>. We will see multiple applications with special methods unique to time series data in Section VII.</p>
</div>
<div id="speed" class="section level2 hasAnchor" number="22.9">
<h2><span class="header-section-number">22.9</span> Speed<a href="time-series.html#speed" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before concluding this section, notice that as the sample size rises, the learning algorithms take longer to complete, specially for cross sectional data. That’s why there are some other cross-validation methods that use only a subsample randomly selected from the original sample to speed up the validation and the test procedures. You can think how slow the conventional cross validation would be if the dataset has 1-2 million observations, for example.</p>
<p>There are some methods to accelerate the training process. One method is to increase the delta (the increments) in our grid and identify the range of hyperparameters where the RMSPE becomes the lowest. Then we reshape our grid with finer increments targeting that specific range.</p>
<p>Another method is called a random grid search. In this method, instead of the exhaustive enumeration of all combinations of hyperparameters, we select them randomly. This can be found in <a href="https://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf">Random Search for Hyper-Parameter Optimization</a> by James Bergstra and
Yoshua Bengio <span class="citation">(<a href="#ref-Berg_2012"><strong>Berg_2012?</strong></a>)</span>.</p>
<p>To accelerate the grid search, we can also use parallel processing so that each loop will be assigned to a separate core in capable computers. We will see several application using these options later in the book. Both methods are covered in Chapter 14.</p>
<p>Finally, we did not use functions in our algorithms. We should create functions for each major process in algorithms and compile them in one clean “source” script.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>There is a paper, &lt;<a href="https://robjhyndman.com/publications/tsibble/" class="uri">https://robjhyndman.com/publications/tsibble/</a>), by Wang et al. (2020) describing <code>tsibble</code> and the package in more details<a href="time-series.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="forecast.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mutluyuk/machinemetrics/edit/master/22-TimeSeries.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["machinemetrics.pdf", "machinemetrics.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
